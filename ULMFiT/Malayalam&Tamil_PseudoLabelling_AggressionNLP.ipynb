{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malayalam&Tamil_PseudoLabelling AggressionNLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeOfcNmWoXVX"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmVdECMZhXM5"
      },
      "source": [
        "cols=['data','label','index']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh0WiAcPqlj8"
      },
      "source": [
        " # Malayalam Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeR7l5C8gVUM"
      },
      "source": [
        "mal_train = pd.read_csv('/content/drive/MyDrive/mal_full_offensive_train.csv',sep='\\t',names=cols)\n",
        "mal_dev= pd.read_csv('/content/drive/MyDrive/mal_full_offensive_dev.csv',sep='\\t',names=cols)\n",
        "mal_test = pd.read_csv('/content/drive/MyDrive/mal_full_offensive_test.csv',sep='\\t',names=['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "126ray1WgfTb"
      },
      "source": [
        "mal_train = mal_train[['data','label']]\n",
        "mal_dev = mal_dev[['data','label']]\n",
        "mal_test = mal_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lARPtI7bicjB",
        "outputId": "e0f06b46-1f03-47d4-bea7-c5d00d8f4727"
      },
      "source": [
        "mal_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0  പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...  Not_offensive\n",
              "1  ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...  Not_offensive\n",
              "2  ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...  Not_offensive\n",
              "3          Sushin syam  Shaiju khalid  Midhun manual  Not_offensive\n",
              "4                          J A K E S.   B EJ O Y !!!  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0c5F_sZghiY",
        "outputId": "bbad6893-fabe-4c25-ae75-c7d6999a50fa"
      },
      "source": [
        "mal_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16010 entries, 0 to 16009\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    16010 non-null  object\n",
            " 1   label   16010 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 250.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzAypPcVPzri",
        "outputId": "73c7387f-f2ac-4d8b-ac74-cb6336685257"
      },
      "source": [
        "mal_train[mal_train['label']=='not-malayalam']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Semma voice.  ..Iam Tamil Nadu</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Mere naam ka kachra karo sab mil k</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>I am waiting for kappan Moganla and Surya</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>MALAYALAM DJ REMIX NEW NON STOP EVERGREENSONGS...</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>Thrissur pooram trailer  hidden details</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15957</th>\n",
              "      <td>poli...but felt like a mix of korean serial ki...</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15980</th>\n",
              "      <td>Tamil film Pizza de oru style</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15986</th>\n",
              "      <td>Iam tamil but i love malayalam</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>All india lalettan fans  Hit like</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16008</th>\n",
              "      <td>Like from Madurai (Tamil nadu) ....</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1287 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    data          label\n",
              "25                        Semma voice.  ..Iam Tamil Nadu  not-malayalam\n",
              "47                    Mere naam ka kachra karo sab mil k  not-malayalam\n",
              "74             I am waiting for kappan Moganla and Surya  not-malayalam\n",
              "89     MALAYALAM DJ REMIX NEW NON STOP EVERGREENSONGS...  not-malayalam\n",
              "108              Thrissur pooram trailer  hidden details  not-malayalam\n",
              "...                                                  ...            ...\n",
              "15957  poli...but felt like a mix of korean serial ki...  not-malayalam\n",
              "15980                      Tamil film Pizza de oru style  not-malayalam\n",
              "15986                     Iam tamil but i love malayalam  not-malayalam\n",
              "15997                  All india lalettan fans  Hit like  not-malayalam\n",
              "16008                Like from Madurai (Tamil nadu) ....  not-malayalam\n",
              "\n",
              "[1287 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA9uGUi4gjZm",
        "outputId": "4176ed42-84f9-4f4f-d4cf-2ab97110df2c"
      },
      "source": [
        "mal_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           14153\n",
              "not-malayalam                            1287\n",
              "Offensive_Targeted_Insult_Individual      239\n",
              "Offensive_Untargetede                     191\n",
              "Offensive_Targeted_Insult_Group           140\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "civzfUfPipDL",
        "outputId": "6242d0a4-5e51-4910-e893-fefe6436266a"
      },
      "source": [
        "print(len(mal_train))\n",
        "mal_train = mal_train.drop_duplicates()\n",
        "print(len(mal_train))\n",
        "mal_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16010\n",
            "11695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           10382\n",
              "not-malayalam                             882\n",
              "Offensive_Targeted_Insult_Individual      171\n",
              "Offensive_Untargetede                     154\n",
              "Offensive_Targeted_Insult_Group           106\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns6NoLoRkH-L",
        "outputId": "e85cab2d-5c4c-4707-a1ef-271d2a474b25"
      },
      "source": [
        "mal_train['token_length'] = [len(x.split(\" \")) for x in mal_train.data]\n",
        "print(max(mal_train.token_length))\n",
        "print(min(mal_train.token_length))\n",
        "print(sum(mal_train.token_length)/len(mal_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224\n",
            "1\n",
            "9.707396323215049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkeFX9h8qrUL"
      },
      "source": [
        " # Tamil Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0596OJtkZh_"
      },
      "source": [
        "tamil_train = pd.read_csv('/content/drive/MyDrive/tamil_offensive_full_train.csv',sep='\\t',names=cols)\n",
        "tamil_dev= pd.read_csv('/content/drive/MyDrive/tamil_offensive_full_dev.csv',sep='\\t',names=cols)\n",
        "tamil_test = pd.read_csv('/content/drive/MyDrive/tamil_offensive_full_test.csv',sep='\\t',names=['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDRlZgMSpyB2"
      },
      "source": [
        "tamil_train = tamil_train[['data','label']]\n",
        "tamil_dev = tamil_dev[['data','label']]\n",
        "tamil_test = tamil_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj30bqBPqAL_",
        "outputId": "8df18dc9-b0b1-433f-82e8-eab298314d53"
      },
      "source": [
        "tamil_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0                  movie vara level la Erika poguthu  Not_offensive\n",
              "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n",
              "2          Padam nalla comedy padama irukum polaye..  Not_offensive\n",
              "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n",
              "4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1VOpZPRqJLD",
        "outputId": "cbdda776-d0df-48c8-a4fd-a0fd70c4325f"
      },
      "source": [
        "tamil_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35139 entries, 0 to 35138\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    35139 non-null  object\n",
            " 1   label   35139 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 549.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR_fnvcnqKxx",
        "outputId": "eaf8f3d2-04cc-405a-b7d5-0ff0f536f110"
      },
      "source": [
        "tamil_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           25425\n",
              "Offensive_Untargetede                    2906\n",
              "Offensive_Targeted_Insult_Group          2557\n",
              "Offensive_Targeted_Insult_Individual     2343\n",
              "not-Tamil                                1454\n",
              "Offensive_Targeted_Insult_Other           454\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEIb6xtbqQpX",
        "outputId": "22f33c4f-c1cd-4eb7-b6bf-f3e40b79a845"
      },
      "source": [
        "print(len(tamil_train))\n",
        "tamil_train = tamil_train.drop_duplicates()\n",
        "print(len(tamil_train))\n",
        "tamil_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35139\n",
            "34898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           25215\n",
              "Offensive_Untargetede                    2894\n",
              "Offensive_Targeted_Insult_Group          2550\n",
              "Offensive_Targeted_Insult_Individual     2338\n",
              "not-Tamil                                1447\n",
              "Offensive_Targeted_Insult_Other           454\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFMUBqX-qT92",
        "outputId": "73277108-7791-41b3-d2f6-672a7280eac2"
      },
      "source": [
        "tamil_train['token_length'] = [len(x.split(\" \")) for x in tamil_train.data]\n",
        "print(max(tamil_train.token_length))\n",
        "print(min(tamil_train.token_length))\n",
        "print(sum(tamil_train.token_length)/len(tamil_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152\n",
            "1\n",
            "10.86618144306264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyIq8yVorLSn"
      },
      "source": [
        "# Kannada data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXGbeChFqWc5"
      },
      "source": [
        "kannada_train = pd.read_csv('/content/drive/MyDrive/kannada_offensive_train.csv',sep='\\t',names=cols)\n",
        "kannada_dev= pd.read_csv('/content/drive/MyDrive/kannada_offensive_dev.csv',sep='\\t',names=cols)\n",
        "kannada_test = pd.read_csv('/content/drive/MyDrive/kannada_offensive_test.csv',sep='\\t',names=['data'])\n",
        "kannada_train = kannada_train[['data','label']]\n",
        "kannada_dev = kannada_dev[['data','label']]\n",
        "kannada_test = kannada_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcktB08pquQV",
        "outputId": "75efe5d6-92fd-46b4-a6a0-e4e738524d9d"
      },
      "source": [
        "kannada_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tik tok alli jagala madtidralla adra baggenu o...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anyone from kerala here</td>\n",
              "      <td>not-Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie rerelease madi plss</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amazon prime alli bittidira....yella manele no...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Guru sure news nanu tik tok dawn lod madeda ya...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0  Tik tok alli jagala madtidralla adra baggenu o...  Not_offensive\n",
              "1                            Anyone from kerala here    not-Kannada\n",
              "2                          Movie rerelease madi plss  Not_offensive\n",
              "3  Amazon prime alli bittidira....yella manele no...  Not_offensive\n",
              "4  Guru sure news nanu tik tok dawn lod madeda ya...  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR7FQUZgq8TJ",
        "outputId": "6f15e8f6-389f-495a-cda7-0ea1daf5db13"
      },
      "source": [
        "kannada_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6217 entries, 0 to 6216\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    6217 non-null   object\n",
            " 1   label   6217 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 97.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-IXQZ3kq-M-",
        "outputId": "f7fc7f9c-0c53-44ce-b455-572dd7bd6836"
      },
      "source": [
        "print(len(kannada_train))\n",
        "kannada_train = kannada_train.drop_duplicates()\n",
        "print(len(kannada_train))\n",
        "kannada_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6217\n",
            "5936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           3382\n",
              "not-Kannada                             1407\n",
              "Offensive_Targeted_Insult_Individual     486\n",
              "Offensive_Targeted_Insult_Group          327\n",
              "Offensive_Untargetede                    212\n",
              "Offensive_Targeted_Insult_Other          122\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sydvTcZ7rAzc",
        "outputId": "528102de-958e-4cae-f5bb-caf4988eea05"
      },
      "source": [
        "kannada_train['token_length'] = [len(x.split(\" \")) for x in kannada_train.data]\n",
        "print(max(kannada_train.token_length))\n",
        "print(min(kannada_train.token_length))\n",
        "print(sum(kannada_train.token_length)/len(kannada_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n",
            "1\n",
            "8.141677897574125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSCgUvtCuENc"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XElKehJjrGiz",
        "outputId": "709a00f8-10d9-4013-d7b5-9ce62eb228cf"
      },
      "source": [
        "!pip install indic-nlp-library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.19.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Installing collected packages: morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ctdevt8AzIl",
        "outputId": "d2e574d2-1726-4124-87c2-25dc47ac9a7e"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 41.40 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSE_pcYviHoc"
      },
      "source": [
        "INDIC_NLP_RESOURCES=r\"/content/indic_nlp_resources\"\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkKukZJkBaIF"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHCiLp9r9Oay"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YneaCz4whVT0",
        "outputId": "66305f8a-8919-41ed-943a-e11f44a5f3a2"
      },
      "source": [
        "mal_lines = []\n",
        "for i in mal_train['data']:\n",
        "  mal_lines.append(i)\n",
        "len(mal_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2k0-lmBuIFG"
      },
      "source": [
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "\n",
        "# input_text=\"പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്തം രാജവയത് അല്ല\"\n",
        "# remove_nuktas=False\n",
        "factory=IndicNormalizerFactory()\n",
        "normalizer=factory.get_normalizer(\"ml\")\n",
        "\n",
        "# %%time\n",
        "nor_mal_lines = []\n",
        "for i in range(len(mal_lines)):\n",
        "  nor_mal_line = normalizer.normalize(mal_lines[i])\n",
        "  nor_mal_lines.append(nor_mal_line)\n",
        "# new_mal_lines "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDZWW-d8uqmD",
        "outputId": "1887b1ed-3051-49b6-ab4f-de37e3ab6225"
      },
      "source": [
        "len(nor_mal_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1TWLIlU-6lM"
      },
      "source": [
        "Tokenization word level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL5h8qy52UUD"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "tokenized_mal_lines = []\n",
        "for i in range(len(mal_lines)):\n",
        "  tokenized_mal_line = indic_tokenize.trivial_tokenize(nor_mal_lines[i])\n",
        "  tokenized_mal_lines.append(tokenized_mal_line)\n",
        "# tokenized_mal_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkotkbN75aTV",
        "outputId": "1a37fe4b-e5ac-469b-fe61-971b335652f5"
      },
      "source": [
        "tokenized_mal_lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ആരണ്ട',\n",
              " 'ആരണ്ട',\n",
              " 'തലുണ്ടാകാണാ',\n",
              " 'ആരണ്ട',\n",
              " 'ഞാൻ',\n",
              " 'ആണ്ട',\n",
              " 'ഞാൻ',\n",
              " 'ആണ്ട',\n",
              " 'ഞാൻ',\n",
              " 'Royal',\n",
              " 'Mech',\n",
              " 'ആടാ',\n",
              " 'ആരണ്ട',\n",
              " 'ആരണ്ട',\n",
              " 'മീശ',\n",
              " 'പിരിക്കുന്ന',\n",
              " 'ആരണ്ട',\n",
              " 'ഞാൻ',\n",
              " 'ആണ്ട',\n",
              " 'ഞാൻ',\n",
              " 'ആണ്ട',\n",
              " 'ഞാൻ',\n",
              " 'royal',\n",
              " 'Mech',\n",
              " 'ആടാ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTZdMa7S7THG",
        "outputId": "a39f356a-000d-4191-994e-9e4e5621cb78"
      },
      "source": [
        "mal_lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്ട ഞാൻ Royal Mech ആടാ  ആരണ്ട ആരണ്ട മീശ പിരിക്കുന്ന ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്ട ഞാൻ royal Mech ആടാ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNJ589jE_3l4",
        "outputId": "f039dd7a-656c-4dfa-9847-3a1f2ba68df3"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "transliterated_mal_lines = []\n",
        "flags=[]\n",
        "for i in range(len(mal_lines)):\n",
        "  transliterated_mal_line = ItransTransliterator.from_itrans(mal_lines[i],'ml')\n",
        "  if(transliterated_mal_line == mal_lines[i]):\n",
        "    flag=1\n",
        "  else:\n",
        "    flag=0\n",
        "  flags.append(flag)\n",
        "  transliterated_mal_lines.append(transliterated_mal_line)\n",
        "transliterated_mal_lines[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'പലദേശം\\u0d64 പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്തം രാജവയത് അല്ല'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4i9ECuUAa0r",
        "outputId": "eada95f8-3050-46b1-a69b-f2128fb86eec"
      },
      "source": [
        "print('native malayalam sentences: ',sum(flags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "native malayalam sentences:  1298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3GVT_UHDUX3",
        "outputId": "8453beba-0d43-4803-be4c-7aae3588ba4e"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "en_transliterated_mal_lines = []\n",
        "flags=[]\n",
        "for i in range(len(mal_lines)):\n",
        "  en_transliterated_mal_line = ItransTransliterator.to_itrans(mal_lines[i],'ml')\n",
        "  if(en_transliterated_mal_line == mal_lines[i]):\n",
        "    flag=1\n",
        "  else:\n",
        "    flag=0\n",
        "  flags.append(flag)\n",
        "  en_transliterated_mal_lines.append(en_transliterated_mal_line)\n",
        "en_transliterated_mal_lines[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'paladesha.m. pala bhaaSha .ore .oru raajaav  allaat.e  svanta.m raajavayat alla'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whg64WtK3QP",
        "outputId": "a3871dcc-26ab-408d-d665-53e4c41dab02"
      },
      "source": [
        "whole_mal_train = ''\n",
        "for i in range(len(mal_lines)):\n",
        "  whole_mal_train+=str(mal_lines[i])\n",
        "len(whole_mal_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "793979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdZR_pY4Mh5F",
        "outputId": "b191c2d1-4ba6-4513-b370-d8d0acd53229"
      },
      "source": [
        "from indicnlp.langinfo import *\n",
        "\n",
        "lang='ml'\n",
        "vowels = 0\n",
        "for i in range(len(whole_mal_train)):\n",
        "  if(is_vowel(whole_mal_train[i],lang)):\n",
        "    vowels+=1\n",
        "print('Total characters: ',len(whole_mal_train))\n",
        "print('Total vowels: ',vowels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters:  793979\n",
            "Total vowels:  12759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXJ0Pe-kUjoJ"
      },
      "source": [
        "#ULMFiT Malayalam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkRGvPiiVbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52eb093-1f16-4675-f2ae-537b5d6e4b8f"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA7y6RqITFL2"
      },
      "source": [
        "#reference: https://github.com/goru001/nlp-for-malyalam/blob/master/classification/Malyalam_Classification_Model.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciWz6KQDNLNx"
      },
      "source": [
        "from fastai.text import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaPnd2txPS1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc64c49-7ada-493d-b6e3-fcf85e976783"
      },
      "source": [
        "import fastai, torch\n",
        "fastai.__version__ , torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.0.61', '1.7.0+cu101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WDShsGvZVpF"
      },
      "source": [
        "def handle_all_caps(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = replace_all_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def handle_upper_case_first_letter(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = deal_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def lower_case_everything(t: str) -> str:\n",
        "    return t.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9SfSd2PZ25"
      },
      "source": [
        "class CodeMixedMalayalamTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.lang = lang\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/code-mixed-enma/tokenizer_mixed_script/mlen_spm.model\"))\n",
        "        \n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        return self.sp.EncodeAsPieces(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzONojGGPhkg"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/code-mixed-enma/tokenizer_mixed_script/mlen_spm.model\"))\n",
        "itos = [sp.IdToPiece(int(i)) for i in range(25000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E66bBfRbPprc"
      },
      "source": [
        "# 25,000 is the vocab size that we chose in sentencepiece\n",
        "mlen_vocab = Vocab(itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7szhXI2Pw_q"
      },
      "source": [
        "tokenizer = Tokenizer(lang='mlen', tok_func=CodeMixedMalayalamTokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrxEDILWYg0-"
      },
      "source": [
        "tokenizer.pre_rules.append(lower_case_everything)\n",
        "tokenizer.pre_rules.append(handle_all_caps)\n",
        "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gt_DrjaPyyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b95dd86-a371-4645-b920-1f3efea42259"
      },
      "source": [
        "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['xxunk',\n",
              "  'xxpad',\n",
              "  'xxbos',\n",
              "  'xxeos',\n",
              "  'xxfld',\n",
              "  'xxmaj',\n",
              "  'xxup',\n",
              "  'xxrep',\n",
              "  'xxwrep'],\n",
              " [<function fastai.text.transform.fix_html>,\n",
              "  <function fastai.text.transform.replace_rep>,\n",
              "  <function fastai.text.transform.replace_wrep>,\n",
              "  <function fastai.text.transform.spec_add_spaces>,\n",
              "  <function fastai.text.transform.rm_useless_spaces>,\n",
              "  <function __main__.lower_case_everything>,\n",
              "  <function __main__.handle_all_caps>,\n",
              "  <function __main__.handle_upper_case_first_letter>],\n",
              " [<function fastai.text.transform.replace_all_caps>,\n",
              "  <function fastai.text.transform.deal_caps>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joo7nBUWVbsB"
      },
      "source": [
        "label_cols = ['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ii1J6H02fnHy",
        "outputId": "4cc4dd2d-a6ca-4eec-b613-079554c87230"
      },
      "source": [
        "df_test_pred=pd.read_csv('/content/mal_test_preds_2.csv',names=['query','predicted_label'],skiprows=1)\n",
        "df_test_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  query                  predicted_label\n",
              "0     അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...                    Not_offensive\n",
              "1     എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...  Offensive_Targeted_Insult_Group\n",
              "2            Fefka ee padam release cheyyan samadhicho?                    Not_offensive\n",
              "3     അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...                    Not_offensive\n",
              "4     Ravile thane views likes ethra ayyi enn nokan ...                    Not_offensive\n",
              "...                                                 ...                              ...\n",
              "1996  Swargatthil ninnu purathaakkappetta daivatthin...                    Not_offensive\n",
              "1997  Ivide Palakkad Jayettan Fans club nnu ashamsak...                    Not_offensive\n",
              "1998      ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും                    Not_offensive\n",
              "1999  കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...                    Not_offensive\n",
              "2000            Koora padam urappa kandal aryam.. Hello                    Not_offensive\n",
              "\n",
              "[2001 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pbR5zhEY675m",
        "outputId": "83b6bf5c-7de0-4837-f9c6-2b409474f105"
      },
      "source": [
        "df_test_pred['data']=df_test_pred['query']\n",
        "df_test_pred['label']=df_test_pred['predicted_label']\n",
        "\n",
        "mal_train_new = pd.concat([mal_train,df_test_pred])\n",
        "mal_train_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>26.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13696 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  ... predicted_label\n",
              "0     പലദേശം. പല ഭാഷ ഒരേ ഒരു രാജാവ്  അല്ലാതെ  സ്വന്ത...  ...             NaN\n",
              "1     ഈ ഓണം ഏട്ടനും പിള്ളേർക്ക് ഉള്ളതാണ് എന്ന് ഉള്ളവ...  ...             NaN\n",
              "2     ആരണ്ട ആരണ്ട തലുണ്ടാകാണാ ആരണ്ട ഞാൻ ആണ്ട ഞാൻ ആണ്...  ...             NaN\n",
              "3             Sushin syam  Shaiju khalid  Midhun manual  ...             NaN\n",
              "4                             J A K E S.   B EJ O Y !!!  ...             NaN\n",
              "...                                                 ...  ...             ...\n",
              "1996  Swargatthil ninnu purathaakkappetta daivatthin...  ...   Not_offensive\n",
              "1997  Ivide Palakkad Jayettan Fans club nnu ashamsak...  ...   Not_offensive\n",
              "1998      ഈ പടത്തിന് വെയിറ്റ് ചെയ്യുന്ന മമ്മൂക്ക ഫാൻസും  ...   Not_offensive\n",
              "1999  കട്ട ലാലേട്ടൻ ഫാൻസ് ഒരു ലൈക് തന്നിട്ട് പോവാമോ ...  ...   Not_offensive\n",
              "2000            Koora padam urappa kandal aryam.. Hello  ...   Not_offensive\n",
              "\n",
              "[13696 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX-aZDS4TkwA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(mal_train_new['data'],mal_train_new['label'], test_size = 0.2, random_state = 42, stratify=mal_train_new['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM6aCgOjYlip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47d25f7-1837-4ae1-dfcb-305b2a73c738"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "813      Oh enthoot kidu trailer laletta.. kidu mass!!!...\n",
              "3746                      ഇൗ പടം പൊളിയും എന്നത് ഉറപ്പ് ആയി\n",
              "7418     Mamangam Trailer poli aarnnu pakshe padam  Big...\n",
              "3817     Shah Rukh Khan inte FAN cinema de cheriya samy...\n",
              "7085                      Urumi   scene repeat  mode    on\n",
              "                               ...                        \n",
              "3869     Ejjaathi hardwork mammookka!!! Katta waiting p...\n",
              "981      Trailer cuts the great editor Donmax ചുമ്മാതല്...\n",
              "12793    ഇക്കയാണെങ്കിൽ എല്ലാ ഭാഷയും ശൈലികളും നന്നായി പറ...\n",
              "7578                  8 hour kazhinjittum 1M polum aayilla\n",
              "8230     ഷൈലോക്ക്.. big ബ്രദർ കാണാം പൂരം.. ഇന്നലെ ഷൈലോക...\n",
              "Name: data, Length: 10956, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhAHlcX9WrFk"
      },
      "source": [
        "X_train_df = pd.concat([X_train, y_train], axis=1, keys=['text', 'label'])\n",
        "X_val_df = pd.concat([X_val, y_val], axis=1, keys=['text', 'label'])\n",
        "X_test_df = pd.concat([mal_dev['data'], mal_dev['label']], axis=1, keys=['text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zLWWpv0bHq8"
      },
      "source": [
        "# X_train_df['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLD_rdsOP0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d3d4f3c5-18fa-4a7e-a563-02e213c2e8b4"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=mlen_vocab,text_cols='text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL-r5q3FUCDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4ea50f0c-6609-41bd-d976-ddfb43813ff1"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk ▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക ▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല ▁x x bo s ▁dha an de . . . ki da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>മ്പി ന േഷൻ ▁പട ം ▁പൊ ളി ക്കും ▁എന്ന് ▁അഭിപ്രായം ▁ഉള്ള വർ ▁ഒന്ന് ▁ലൈ ക്ക് ▁അടിച്ച േ . . ▁x x bo s ▁വീണ്ടും ▁വീണ്ടും ▁കാണാൻ ▁തോന്ന ുന്നത് ▁എനിക്ക് ▁മാത്ര മ ാണോ . xxunk ▁x x bo s ▁mam mo kka ▁age ▁68 ▁ xxrep ▁4 ▁. ▁no ▁words ▁x x bo s ▁spo ile r ▁a ler t ▁ xxunk ▁odi yan ▁is ▁not ▁mohanlal . ▁mani k yan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>kan ▁ratri ▁2 mani k ▁ala ram ve chen itu ▁raja da ▁pillar u ▁ട്രി പ്പി ൾ ▁strong anu ▁the li yi kum ▁wait ▁x x bo s ▁i tha a anu ▁ nnu mma ▁para nja ▁sha oli n ▁temple ▁a tha va ▁shashi ▁anna nte ▁kotta ram ▁x x bo s ▁trai ler il ▁joseph ▁x x bo s ▁tea s er ▁ er angi ▁ela ▁x x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>▁സ്വാ സി ക ▁കുട്ടി ക്ക് ▁എല്ലാ ▁വിധ ▁വിജയ വും ▁ഉണ്ടാക ട്ടെ ▁ xxrep ▁4 ▁. ▁x x bo s ▁ഇവ ിട ാ രും ▁പറയ ാതെ ▁പോയ ▁പേരു ▁x x bo s ▁പൂ മര ത്തിന് ▁വന്ന ▁അവസ്ഥ ▁വരുത്ത രുത് . . . ▁എ ബ്രി ഡ് ▁ഷ െയിൻ ▁നിലവിൽ ▁മലയാളത്തിലെ ▁എണ്ണം ▁പറഞ്ഞ ▁സംവിധായകന ാണ് . . . ▁x x bo s ▁2 : 05 ▁di le e p ▁de ▁ani yan ▁paranjat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>▁... ▁vara mpo ▁kaa nam ▁en gana ▁nu ▁ xxrep ▁4 ▁. ▁x x bo s ▁nama da ▁model ▁school ▁. ▁model ▁school i ▁pa di che ▁pill ero kke ▁e v de da . . ▁x x bo s ▁trai ler ▁i ' ll ▁tan na ay y ▁full ▁story ▁u on du ▁x x bo s ▁en thu ▁o ola ▁trai ler ▁mam mat ty ▁loka th ol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8C3WPbQUC66"
      },
      "source": [
        "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eeINS4pZeM-"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/AggressionNLP/code-mixed-enma/lm_mixed_script/models.zip' -d '/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/lm_mixed_script/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0naev5MFeko0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b267887-e163-4180-a18d-eb6fe2709b75"
      },
      "source": [
        "# Loading the pretrained language model on malyalam wikipedia\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/lm_mixed_script/models/best_model', with_opt=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁kerala ▁a chay an ▁fan s ▁hit ▁like,▁x x bo s ▁ഇത് ▁don ma x ▁തന്നെ യാണ ോ ▁ചെയ്ത േ xxunk മോ ശം . കോ പ്പി ▁ഏ ട്ടാ ▁mass ▁സെ ക്ഷ ന് ▁കൊടുത്ത ▁ബി ജി എം ▁നല്ല ▁ബോ റ യ്ക്ക ി ണ ല്ലോ . മൊത്ത ത്തിൽ ▁ലോ ▁ക്വാ ളി റ്റി ▁ഫീ ൽ .,▁x x bo s ▁odi yanu ▁mun me yulla ▁la le ttane ▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk,▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക,▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁san chit ▁bu l hara ▁b g m ▁nte ▁ponn o ▁no ▁raksha,▁x x bo s ▁ni vin ▁ഇ ച്ച ായ ൻ ▁ഇത് ▁തകർക്ക ും . . . ▁ആ സി ഫ ലി ▁ഫാ ൻ സിന്റെ ▁വിജയ ാ ശം സ കൾ,▁x x bo s ▁ആ രോ ▁ഒരാൾ ▁അല്ല ▁എന്റെ ▁ഏ ട്ട ൻ ▁my ▁big ▁brother,▁x x bo s ▁super ▁fi li m ▁than k s ▁raj u ve tta ▁la le ttan ▁tha kar thu,▁x x bo s ▁p k ▁ram das . . . ▁namm u de ▁raj e ttan ▁a anennu ▁ nj n ▁para jal ▁ni ga lu de ▁abhiprayam . . . ▁ xxrep ▁4 ▁ xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁gopi che tta nte ▁b g m ▁ um ▁mam mo o kayu m ▁ishta pedunn avar ▁like ▁ xxunk,▁x x bo s ▁ഇത് ▁ഒരു ▁പെണ്ണ ് ▁തന്നെ ▁ആ ണോ ▁direct ▁ചെയ്യുന്നത് ▁poli chu ▁ni vin,▁x x bo s ▁പൃഥ്വി രാജ് ▁സു രാജ േ ട്ട ൻ ▁ലാ ലും ▁അല ക്സ് . . ▁lal ▁j r . ▁ന്റെ ▁ഒരു ▁വെ റൈ റ്റി ▁ചിത്രം ▁പ്രതീക്ഷിക്ക ുന്നു . . ▁best ▁wi shes ▁team,▁x x bo s ▁പോക രുത് ▁മക്കള െ ▁പോ ക്ക ▁ xxrep ▁10 ▁. ▁ന ൻ ▁കണ്ട് ▁എ ന്റ് യെ ▁അമ്മ ോ ▁പോളി യ ▁മറക്ക ില്ല ▁ഒരിക്കലും,▁x x bo s ▁a van ▁varu m ▁ente ▁ makan ▁madhura ▁raja ▁ xxrep ▁4 ▁.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(25000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁kerala ▁a chay an ▁fan s ▁hit ▁like,▁x x bo s ▁ഇത് ▁don ma x ▁തന്നെ യാണ ോ ▁ചെയ്ത േ xxunk മോ ശം . കോ പ്പി ▁ഏ ട്ടാ ▁mass ▁സെ ക്ഷ ന് ▁കൊടുത്ത ▁ബി ജി എം ▁നല്ല ▁ബോ റ യ്ക്ക ി ണ ല്ലോ . മൊത്ത ത്തിൽ ▁ലോ ▁ക്വാ ളി റ്റി ▁ഫീ ൽ .,▁x x bo s ▁odi yanu ▁mun me yulla ▁la le ttane ▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk,▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക,▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁san chit ▁bu l hara ▁b g m ▁nte ▁ponn o ▁no ▁raksha,▁x x bo s ▁ni vin ▁ഇ ച്ച ായ ൻ ▁ഇത് ▁തകർക്ക ും . . . ▁ആ സി ഫ ലി ▁ഫാ ൻ സിന്റെ ▁വിജയ ാ ശം സ കൾ,▁x x bo s ▁ആ രോ ▁ഒരാൾ ▁അല്ല ▁എന്റെ ▁ഏ ട്ട ൻ ▁my ▁big ▁brother,▁x x bo s ▁super ▁fi li m ▁than k s ▁raj u ve tta ▁la le ttan ▁tha kar thu,▁x x bo s ▁p k ▁ram das . . . ▁namm u de ▁raj e ttan ▁a anennu ▁ nj n ▁para jal ▁ni ga lu de ▁abhiprayam . . . ▁ xxrep ▁4 ▁ xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁gopi che tta nte ▁b g m ▁ um ▁mam mo o kayu m ▁ishta pedunn avar ▁like ▁ xxunk,▁x x bo s ▁ഇത് ▁ഒരു ▁പെണ്ണ ് ▁തന്നെ ▁ആ ണോ ▁direct ▁ചെയ്യുന്നത് ▁poli chu ▁ni vin,▁x x bo s ▁പൃഥ്വി രാജ് ▁സു രാജ േ ട്ട ൻ ▁ലാ ലും ▁അല ക്സ് . . ▁lal ▁j r . ▁ന്റെ ▁ഒരു ▁വെ റൈ റ്റി ▁ചിത്രം ▁പ്രതീക്ഷിക്ക ുന്നു . . ▁best ▁wi shes ▁team,▁x x bo s ▁പോക രുത് ▁മക്കള െ ▁പോ ക്ക ▁ xxrep ▁10 ▁. ▁ന ൻ ▁കണ്ട് ▁എ ന്റ് യെ ▁അമ്മ ോ ▁പോളി യ ▁മറക്ക ില്ല ▁ഒരിക്കലും,▁x x bo s ▁a van ▁varu m ▁ente ▁ makan ▁madhura ▁raja ▁ xxrep ▁4 ▁.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(25000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pvdMXwlescX"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kQrKz10is_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "bd45282d-1916-41bf-9663-1af304dab54a"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.102862</td>\n",
              "      <td>4.716438</td>\n",
              "      <td>0.282994</td>\n",
              "      <td>00:19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bjJuFjtivsC"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV8vHBjcl20u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6ed27cbd-c30f-4ac8-b3c8-32ac9704ffee"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.483469</td>\n",
              "      <td>4.477559</td>\n",
              "      <td>0.304381</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.240146</td>\n",
              "      <td>4.222130</td>\n",
              "      <td>0.335170</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.002192</td>\n",
              "      <td>4.105987</td>\n",
              "      <td>0.349386</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.842096</td>\n",
              "      <td>4.064297</td>\n",
              "      <td>0.354381</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.759367</td>\n",
              "      <td>4.058205</td>\n",
              "      <td>0.355148</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUy7fUd2l4X2"
      },
      "source": [
        "learn.save_encoder('mal_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "spDwPlkjAy4n",
        "outputId": "77f6485c-dab0-4137-ff2c-fed2463011ea"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=mlen_vocab,text_cols=['text'], label_cols=['label'], bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "T9gumaBdBswk",
        "outputId": "b024f15c-1991-4c71-9c76-835cd9e82fa8"
      },
      "source": [
        "data_clas.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man ju ▁war ri er ▁man</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁ഞാൻ ▁എനിക്ക് ▁തോന്നിയ ▁കാര്യം ▁പറഞ്ഞ ോട്ട െ . . ▁കൊല്ല രുത് . ▁ഞാൻ ▁ഒരു ▁കട്ട ▁നി വിൻ ▁ഫാ ൻ ▁ആണ് . . f rom ▁his ▁very ▁first ▁movie . ▁മൂത്ത ോ ൻ ▁ വരാൻ ▁കാ ത്തു ▁കാ ത്ത് ▁ഇരിക്ക ുവരുന്നു ▁ xxrep ▁4 ▁. ▁പക്ഷെ ▁trai ler ▁എന്ന െ ▁നിരാശ പ്പെടുത്തി . ▁നി വിൻ ▁ ൽ ▁നിന്ന് ▁പുതിയ ത് ▁ആ യും ▁വ്യത്യസ്ത ം ▁ആ യും ▁യാതൊരു</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁priya pe tta ▁ji bi ▁and ▁jo ju ▁ivi de ▁kure ▁pala than tha kku pi ran na ▁kure ▁la le ttan ▁ha ter s ▁e ▁nall a ▁cinema ye ▁de grade ▁cheyya n ▁shram ikkunn und ▁pakshe ▁enik ku ra ppan u ▁ni ng alu de ▁e ▁kanni ▁cinema ye ▁malayali pre k sha kar ▁iru ▁kay yu m ▁ne e tti ▁swe e kari</td>\n",
              "      <td>Offensive_Untargetede</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁i th inte ▁pinni l ▁pre var thi cha ▁ella r kku m ▁or ayi ram ▁aa sham sa kal ▁oppam ▁e e ▁na ttile ▁niyama ▁v ye va stha ye ▁e du thu ▁kani kkan ▁chan ku ttam ▁kanich a thil ▁hands ▁off ▁... e e ▁film ▁kanda thu kondu ▁a thu ▁onnu m ▁maran ▁pokunn illa ▁. . bu t ▁it ho kke ▁kand</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁i thu ▁po l oru ▁movie ▁malaya la thil ▁kaa nan ▁oru pa a du ▁a grahi chi ru nu ▁paksha e ▁a e no kae ▁different ▁kondu van itund o ▁apo z ho kae ▁malayali ▁that ima ati y itund u ▁i thu ▁a thu ▁po la ava thiri kata e ▁new ▁ gen ▁movie karu m ▁youth um ▁ku ng fu ya e ▁ishta</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZVeJ512C7pL"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s449VQJSC9iJ",
        "outputId": "78dd02a5-ab1f-44b6-850a-6ee094ad96dd"
      },
      "source": [
        "learn.load_encoder('mal_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁kerala ▁a chay an ▁fan s ▁hit ▁like,▁x x bo s ▁ഇത് ▁don ma x ▁തന്നെ യാണ ോ ▁ചെയ്ത േ xxunk മോ ശം . കോ പ്പി ▁ഏ ട്ടാ ▁mass ▁സെ ക്ഷ ന് ▁കൊടുത്ത ▁ബി ജി എം ▁നല്ല ▁ബോ റ യ്ക്ക ി ണ ല്ലോ . മൊത്ത ത്തിൽ ▁ലോ ▁ക്വാ ളി റ്റി ▁ഫീ ൽ .,▁x x bo s ▁odi yanu ▁mun me yulla ▁la le ttane ▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk,▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക,▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁san chit ▁bu l hara ▁b g m ▁nte ▁ponn o ▁no ▁raksha,▁x x bo s ▁ni vin ▁ഇ ച്ച ായ ൻ ▁ഇത് ▁തകർക്ക ും . . . ▁ആ സി ഫ ലി ▁ഫാ ൻ സിന്റെ ▁വിജയ ാ ശം സ കൾ,▁x x bo s ▁ആ രോ ▁ഒരാൾ ▁അല്ല ▁എന്റെ ▁ഏ ട്ട ൻ ▁my ▁big ▁brother,▁x x bo s ▁super ▁fi li m ▁than k s ▁raj u ve tta ▁la le ttan ▁tha kar thu,▁x x bo s ▁p k ▁ram das . . . ▁namm u de ▁raj e ttan ▁a anennu ▁ nj n ▁para jal ▁ni ga lu de ▁abhiprayam . . . ▁ xxrep ▁4 ▁ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁gopi che tta nte ▁b g m ▁ um ▁mam mo o kayu m ▁ishta pedunn avar ▁like ▁ xxunk,▁x x bo s ▁ഇത് ▁ഒരു ▁പെണ്ണ ് ▁തന്നെ ▁ആ ണോ ▁direct ▁ചെയ്യുന്നത് ▁poli chu ▁ni vin,▁x x bo s ▁പൃഥ്വി രാജ് ▁സു രാജ േ ട്ട ൻ ▁ലാ ലും ▁അല ക്സ് . . ▁lal ▁j r . ▁ന്റെ ▁ഒരു ▁വെ റൈ റ്റി ▁ചിത്രം ▁പ്രതീക്ഷിക്ക ുന്നു . . ▁best ▁wi shes ▁team,▁x x bo s ▁പോക രുത് ▁മക്കള െ ▁പോ ക്ക ▁ xxrep ▁10 ▁. ▁ന ൻ ▁കണ്ട് ▁എ ന്റ് യെ ▁അമ്മ ോ ▁പോളി യ ▁മറക്ക ില്ല ▁ഒരിക്കലും,▁x x bo s ▁a van ▁varu m ▁ente ▁ makan ▁madhura ▁raja ▁ xxrep ▁4 ▁.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁kerala ▁a chay an ▁fan s ▁hit ▁like,▁x x bo s ▁ഇത് ▁don ma x ▁തന്നെ യാണ ോ ▁ചെയ്ത േ xxunk മോ ശം . കോ പ്പി ▁ഏ ട്ടാ ▁mass ▁സെ ക്ഷ ന് ▁കൊടുത്ത ▁ബി ജി എം ▁നല്ല ▁ബോ റ യ്ക്ക ി ണ ല്ലോ . മൊത്ത ത്തിൽ ▁ലോ ▁ക്വാ ളി റ്റി ▁ഫീ ൽ .,▁x x bo s ▁odi yanu ▁mun me yulla ▁la le ttane ▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk,▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക,▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁san chit ▁bu l hara ▁b g m ▁nte ▁ponn o ▁no ▁raksha,▁x x bo s ▁ni vin ▁ഇ ച്ച ായ ൻ ▁ഇത് ▁തകർക്ക ും . . . ▁ആ സി ഫ ലി ▁ഫാ ൻ സിന്റെ ▁വിജയ ാ ശം സ കൾ,▁x x bo s ▁ആ രോ ▁ഒരാൾ ▁അല്ല ▁എന്റെ ▁ഏ ട്ട ൻ ▁my ▁big ▁brother,▁x x bo s ▁super ▁fi li m ▁than k s ▁raj u ve tta ▁la le ttan ▁tha kar thu,▁x x bo s ▁p k ▁ram das . . . ▁namm u de ▁raj e ttan ▁a anennu ▁ nj n ▁para jal ▁ni ga lu de ▁abhiprayam . . . ▁ xxrep ▁4 ▁ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁gopi che tta nte ▁b g m ▁ um ▁mam mo o kayu m ▁ishta pedunn avar ▁like ▁ xxunk,▁x x bo s ▁ഇത് ▁ഒരു ▁പെണ്ണ ് ▁തന്നെ ▁ആ ണോ ▁direct ▁ചെയ്യുന്നത് ▁poli chu ▁ni vin,▁x x bo s ▁പൃഥ്വി രാജ് ▁സു രാജ േ ട്ട ൻ ▁ലാ ലും ▁അല ക്സ് . . ▁lal ▁j r . ▁ന്റെ ▁ഒരു ▁വെ റൈ റ്റി ▁ചിത്രം ▁പ്രതീക്ഷിക്ക ുന്നു . . ▁best ▁wi shes ▁team,▁x x bo s ▁പോക രുത് ▁മക്കള െ ▁പോ ക്ക ▁ xxrep ▁10 ▁. ▁ന ൻ ▁കണ്ട് ▁എ ന്റ് യെ ▁അമ്മ ോ ▁പോളി യ ▁മറക്ക ില്ല ▁ഒരിക്കലും,▁x x bo s ▁a van ▁varu m ▁ente ▁ makan ▁madhura ▁raja ▁ xxrep ▁4 ▁.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKXiJqKVC_fe"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLRLHFh9DC6Y",
        "outputId": "df9ee1d3-c56d-491f-90bb-16576540d82f"
      },
      "source": [
        "learn.loss_func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FlattenedLoss of CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5xMmyOJDEFa"
      },
      "source": [
        "mcc = MatthewsCorreff()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6IWLlk7DFnV"
      },
      "source": [
        "learn.metrics = [mcc, accuracy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "43WhXBD1DHZk",
        "outputId": "8d6c8ced-3093-458d-c6ad-c1d5d3dd05bc"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.313689</td>\n",
              "      <td>0.255555</td>\n",
              "      <td>0.592873</td>\n",
              "      <td>0.927372</td>\n",
              "      <td>00:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "6CbfdYCpDIzN",
        "outputId": "2b1f269c-7b14-4f64-88ec-c5e82f6c6637"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.283254</td>\n",
              "      <td>0.246908</td>\n",
              "      <td>0.639773</td>\n",
              "      <td>0.932847</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k2FwrhYDLu-"
      },
      "source": [
        "learn.save('mal_en-second-full')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "yYlODMJVDNE-",
        "outputId": "5e5925c6-37b0-4818-8a64-692b4462406d"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='mal_en_final')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.196340</td>\n",
              "      <td>0.233245</td>\n",
              "      <td>0.634739</td>\n",
              "      <td>0.932482</td>\n",
              "      <td>01:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.204046</td>\n",
              "      <td>0.227879</td>\n",
              "      <td>0.646546</td>\n",
              "      <td>0.931022</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.167785</td>\n",
              "      <td>0.219066</td>\n",
              "      <td>0.641414</td>\n",
              "      <td>0.929927</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.123436</td>\n",
              "      <td>0.227012</td>\n",
              "      <td>0.645635</td>\n",
              "      <td>0.930292</td>\n",
              "      <td>01:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.091981</td>\n",
              "      <td>0.221462</td>\n",
              "      <td>0.658926</td>\n",
              "      <td>0.934307</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.9324817657470703.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 4 with accuracy value: 0.9343065619468689.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvapwjB-DPaU",
        "outputId": "919447cb-e1a3-4d42-8b61-a4c9b07ee943"
      },
      "source": [
        "learn.load('mal_en_final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁kerala ▁a chay an ▁fan s ▁hit ▁like,▁x x bo s ▁ഇത് ▁don ma x ▁തന്നെ യാണ ോ ▁ചെയ്ത േ xxunk മോ ശം . കോ പ്പി ▁ഏ ട്ടാ ▁mass ▁സെ ക്ഷ ന് ▁കൊടുത്ത ▁ബി ജി എം ▁നല്ല ▁ബോ റ യ്ക്ക ി ണ ല്ലോ . മൊത്ത ത്തിൽ ▁ലോ ▁ക്വാ ളി റ്റി ▁ഫീ ൽ .,▁x x bo s ▁odi yanu ▁mun me yulla ▁la le ttane ▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk,▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക,▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁san chit ▁bu l hara ▁b g m ▁nte ▁ponn o ▁no ▁raksha,▁x x bo s ▁ni vin ▁ഇ ച്ച ായ ൻ ▁ഇത് ▁തകർക്ക ും . . . ▁ആ സി ഫ ലി ▁ഫാ ൻ സിന്റെ ▁വിജയ ാ ശം സ കൾ,▁x x bo s ▁ആ രോ ▁ഒരാൾ ▁അല്ല ▁എന്റെ ▁ഏ ട്ട ൻ ▁my ▁big ▁brother,▁x x bo s ▁super ▁fi li m ▁than k s ▁raj u ve tta ▁la le ttan ▁tha kar thu,▁x x bo s ▁p k ▁ram das . . . ▁namm u de ▁raj e ttan ▁a anennu ▁ nj n ▁para jal ▁ni ga lu de ▁abhiprayam . . . ▁ xxrep ▁4 ▁ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁gopi che tta nte ▁b g m ▁ um ▁mam mo o kayu m ▁ishta pedunn avar ▁like ▁ xxunk,▁x x bo s ▁ഇത് ▁ഒരു ▁പെണ്ണ ് ▁തന്നെ ▁ആ ണോ ▁direct ▁ചെയ്യുന്നത് ▁poli chu ▁ni vin,▁x x bo s ▁പൃഥ്വി രാജ് ▁സു രാജ േ ട്ട ൻ ▁ലാ ലും ▁അല ക്സ് . . ▁lal ▁j r . ▁ന്റെ ▁ഒരു ▁വെ റൈ റ്റി ▁ചിത്രം ▁പ്രതീക്ഷിക്ക ുന്നു . . ▁best ▁wi shes ▁team,▁x x bo s ▁പോക രുത് ▁മക്കള െ ▁പോ ക്ക ▁ xxrep ▁10 ▁. ▁ന ൻ ▁കണ്ട് ▁എ ന്റ് യെ ▁അമ്മ ോ ▁പോളി യ ▁മറക്ക ില്ല ▁ഒരിക്കലും,▁x x bo s ▁a van ▁varu m ▁ente ▁ makan ▁madhura ▁raja ▁ xxrep ▁4 ▁.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁kerala ▁a chay an ▁fan s ▁hit ▁like,▁x x bo s ▁ഇത് ▁don ma x ▁തന്നെ യാണ ോ ▁ചെയ്ത േ xxunk മോ ശം . കോ പ്പി ▁ഏ ട്ടാ ▁mass ▁സെ ക്ഷ ന് ▁കൊടുത്ത ▁ബി ജി എം ▁നല്ല ▁ബോ റ യ്ക്ക ി ണ ല്ലോ . മൊത്ത ത്തിൽ ▁ലോ ▁ക്വാ ളി റ്റി ▁ഫീ ൽ .,▁x x bo s ▁odi yanu ▁mun me yulla ▁la le ttane ▁onnu ku de ▁thir ichu ▁ki ttiya runn e ▁ella thil um ▁or e ▁look xxunk,▁x x bo s ▁ഈ ▁ടീ സർ ▁മലയാളത്തിലെ ▁ആദ്യത്തെ ▁500 k ▁like ▁നേട ുമെന്ന് ▁ഉറപ്പ ുള്ള ▁മ മ്മ ുക്ക ▁fan s ▁like ▁ചെയ്യുക,▁x x bo s ▁പല ദേശ ം . ▁പല ▁ഭാഷ ▁ഒരേ ▁ഒരു ▁രാജാവ് ▁അല്ലാതെ ▁സ്വന്തം ▁രാജ വയ ത് ▁അല്ല\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁san chit ▁bu l hara ▁b g m ▁nte ▁ponn o ▁no ▁raksha,▁x x bo s ▁ni vin ▁ഇ ച്ച ായ ൻ ▁ഇത് ▁തകർക്ക ും . . . ▁ആ സി ഫ ലി ▁ഫാ ൻ സിന്റെ ▁വിജയ ാ ശം സ കൾ,▁x x bo s ▁ആ രോ ▁ഒരാൾ ▁അല്ല ▁എന്റെ ▁ഏ ട്ട ൻ ▁my ▁big ▁brother,▁x x bo s ▁super ▁fi li m ▁than k s ▁raj u ve tta ▁la le ttan ▁tha kar thu,▁x x bo s ▁p k ▁ram das . . . ▁namm u de ▁raj e ttan ▁a anennu ▁ nj n ▁para jal ▁ni ga lu de ▁abhiprayam . . . ▁ xxrep ▁4 ▁ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁gopi che tta nte ▁b g m ▁ um ▁mam mo o kayu m ▁ishta pedunn avar ▁like ▁ xxunk,▁x x bo s ▁ഇത് ▁ഒരു ▁പെണ്ണ ് ▁തന്നെ ▁ആ ണോ ▁direct ▁ചെയ്യുന്നത് ▁poli chu ▁ni vin,▁x x bo s ▁പൃഥ്വി രാജ് ▁സു രാജ േ ട്ട ൻ ▁ലാ ലും ▁അല ക്സ് . . ▁lal ▁j r . ▁ന്റെ ▁ഒരു ▁വെ റൈ റ്റി ▁ചിത്രം ▁പ്രതീക്ഷിക്ക ുന്നു . . ▁best ▁wi shes ▁team,▁x x bo s ▁പോക രുത് ▁മക്കള െ ▁പോ ക്ക ▁ xxrep ▁10 ▁. ▁ന ൻ ▁കണ്ട് ▁എ ന്റ് യെ ▁അമ്മ ോ ▁പോളി യ ▁മറക്ക ില്ല ▁ഒരിക്കലും,▁x x bo s ▁a van ▁varu m ▁ente ▁ makan ▁madhura ▁raja ▁ xxrep ▁4 ▁.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qan78ZnmDRBN"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "df_dict = {'query': list(mal_dev['data']), 'actual_label': list(mal_dev['label']), 'predicted_label': ['']*mal_dev.shape[0]}\n",
        "all_nodes = list(set(mal_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*mal_dev.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "    \n",
        "df_result = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result.head()\n",
        "\n",
        "mal_test=mal_test.to_frame()\n",
        "preds = []\n",
        "for index, row in mal_test.iterrows():\n",
        "    p = learn.predict(row['data'])\n",
        "    preds.append(str(p[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKXbikF9f4oQ"
      },
      "source": [
        "mal_test['text']=mal_test['data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "-aJA24_fdzW3",
        "outputId": "f54dbf1f-7139-4f49-83dd-b2bef3f1c433"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "\n",
        "data_lm_2 = TextClasDataBunch.from_df(path='/content',train_df=X_train_df, valid_df=X_val_df,  test_df=mal_test, tokenizer=tokenizer, vocab=mlen_vocab,text_cols='text',label_cols=['label'])\n",
        "learn = text_classifier_learner(data_lm_2, arch=AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/models/mal_en_fine_tuned_enc')\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/models/mal_en_final')\n",
        "\n",
        "df_dict = {'query': list(mal_test['text']), 'predicted_label': ['']*mal_test.shape[0]}\n",
        "all_nodes = list(set(mal_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*mal_test.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "\n",
        "\n",
        "df_result_2 = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result_2.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result_2.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-malayalam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.000366868</td>\n",
              "      <td>0.000251058</td>\n",
              "      <td>0.994766</td>\n",
              "      <td>0.00346055</td>\n",
              "      <td>0.00115573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "      <td>0.261547</td>\n",
              "      <td>0.369347</td>\n",
              "      <td>0.0708671</td>\n",
              "      <td>0.295421</td>\n",
              "      <td>0.00281822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.0028828</td>\n",
              "      <td>0.00533228</td>\n",
              "      <td>0.962859</td>\n",
              "      <td>0.0264426</td>\n",
              "      <td>0.00248293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.00343776</td>\n",
              "      <td>0.00132228</td>\n",
              "      <td>0.978265</td>\n",
              "      <td>0.015695</td>\n",
              "      <td>0.00128001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.000342353</td>\n",
              "      <td>0.000275865</td>\n",
              "      <td>0.994301</td>\n",
              "      <td>0.00193163</td>\n",
              "      <td>0.00314934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... not-malayalam\n",
              "0  അപ്പൊ ഇതൊരൊന്നൊരാ മൊതലാണല്ലേ  Suraj ആണ് നടൻ ന്...  ...    0.00115573\n",
              "1  എന്ത് ഊള എഡിറ്റിംഗ് ആടോ ഇത് ഒരുമാതിരി vivo vid...  ...    0.00281822\n",
              "2         Fefka ee padam release cheyyan samadhicho?  ...    0.00248293\n",
              "3  അആഹാ.. സംഗീതം ജെക്‌സ് ബിജോയ് ആണ് അപ്പൊ പൊട്ടലു...  ...    0.00128001\n",
              "4  Ravile thane views likes ethra ayyi enn nokan ...  ...    0.00314934\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX3XAYUO2SoQ"
      },
      "source": [
        "df_test_pred_2 = pd.DataFrame(\n",
        "    {'query': mal_test['data'],\n",
        "     'predicted_label': preds    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VrddEYV6im5"
      },
      "source": [
        "df_test_pred_2.to_csv('mal_test_preds_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uBXPVC-DVgr",
        "outputId": "f1001c2b-b53c-48b7-ce17-b9310e1f7aa7"
      },
      "source": [
        "accuracy_score(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9514757378689345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAxoe1QVDXAS",
        "outputId": "b041cdf6-f0ed-4b9e-da23-8707506b0397"
      },
      "source": [
        "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7552146165655927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSceQeYUF6_Z",
        "outputId": "c9ccc9a4-5830-47dd-d515-99cc11481e09"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(df_result['actual_label'], df_result['predicted_label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "                       Not_offensive       0.97      0.98      0.97      1779\n",
            "     Offensive_Targeted_Insult_Group       0.57      0.31      0.40        13\n",
            "Offensive_Targeted_Insult_Individual       0.80      0.33      0.47        24\n",
            "               Offensive_Untargetede       0.55      0.60      0.57        20\n",
            "                       not-malayalam       0.81      0.87      0.83       163\n",
            "\n",
            "                            accuracy                           0.95      1999\n",
            "                           macro avg       0.74      0.62      0.65      1999\n",
            "                        weighted avg       0.95      0.95      0.95      1999\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIRxewFmAUTa"
      },
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "                       Not_offensive       0.97      0.98      0.97      1779\n",
        "     Offensive_Targeted_Insult_Group       0.57      0.31      0.40        13\n",
        "Offensive_Targeted_Insult_Individual       0.80      0.33      0.47        24\n",
        "               Offensive_Untargetede       0.55      0.60      0.57        20\n",
        "                       not-malayalam       0.81      0.87      0.83       163\n",
        "\n",
        "                            accuracy                           0.95      1999\n",
        "                           macro avg       0.74      0.62      0.65      1999\n",
        "                        weighted avg       0.95      0.95      0.95      1999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoYU0GjQSGOc"
      },
      "source": [
        "df_result.to_excel('mal_ml_2.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMg9ospsmbJJ"
      },
      "source": [
        "df_result_2.to_excel('mal_ml_test_preds.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvsJe8sQCoMN"
      },
      "source": [
        "!mv '/content/models' '/content/drive/MyDrive/AggressionNLP/MalayalamEnglish'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PddAWTknUsi5"
      },
      "source": [
        "#ULMFiT Tamil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie_XwWMjUsi6",
        "outputId": "92d38b30-6035-4d12-f557-0afd4c90fcfc"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdcUu0gsUsi6"
      },
      "source": [
        "#reference: https://github.com/goru001/nlp-for-malyalam/blob/master/classification/Malyalam_Classification_Model.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpeVROz3Usi7"
      },
      "source": [
        "from fastai.text import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV23245zUsi7",
        "outputId": "80b0a2e7-db18-408b-c2ee-0f28e2b1f8b8"
      },
      "source": [
        "import fastai, torch\n",
        "fastai.__version__ , torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.0.61', '1.7.0+cu101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ-j2lEdVaKW"
      },
      "source": [
        "def handle_all_caps(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = replace_all_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def handle_upper_case_first_letter(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = deal_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def lower_case_everything(t: str) -> str:\n",
        "    return t.lower().replace('@user', '').replace('#tag ', '').replace('rt ', '').strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y7PyqQCVd1j"
      },
      "source": [
        "class CodeMixedTamilTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.lang = lang\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/tokenizer/taen_spm.model\"))\n",
        "        \n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        return self.sp.EncodeAsPieces(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ_sTZ3KUsi8"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/tokenizer/taen_spm.model\"))\n",
        "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yq8TYyMUsi8"
      },
      "source": [
        "# 8,000 is the vocab size that we chose in sentencepiece\n",
        "taen_vocab = Vocab(itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RI-HrtKUsi8"
      },
      "source": [
        "tokenizer = Tokenizer(lang='taen', tok_func=CodeMixedTamilTokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zJH0YaWhmU"
      },
      "source": [
        "tokenizer.pre_rules.append(lower_case_everything)\n",
        "tokenizer.pre_rules.append(handle_all_caps)\n",
        "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtOxyCiyUsi8",
        "outputId": "2e791900-55ea-4213-d38f-1104747e2414"
      },
      "source": [
        "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['xxunk',\n",
              "  'xxpad',\n",
              "  'xxbos',\n",
              "  'xxeos',\n",
              "  'xxfld',\n",
              "  'xxmaj',\n",
              "  'xxup',\n",
              "  'xxrep',\n",
              "  'xxwrep'],\n",
              " [<function fastai.text.transform.fix_html>,\n",
              "  <function fastai.text.transform.replace_rep>,\n",
              "  <function fastai.text.transform.replace_wrep>,\n",
              "  <function fastai.text.transform.spec_add_spaces>,\n",
              "  <function fastai.text.transform.rm_useless_spaces>,\n",
              "  <function __main__.lower_case_everything>,\n",
              "  <function __main__.handle_all_caps>,\n",
              "  <function __main__.handle_upper_case_first_letter>],\n",
              " [<function fastai.text.transform.replace_all_caps>,\n",
              "  <function fastai.text.transform.deal_caps>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKxxecpXUsi8"
      },
      "source": [
        "label_cols = ['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OW5OElSXViPh",
        "outputId": "46b3d950-07b8-485d-ffc2-eacbb27618bf"
      },
      "source": [
        "tamil_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35134</th>\n",
              "      <td>Trending number #2 idhukku nammalam karanamnu ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35135</th>\n",
              "      <td>Movie script super, athuvum HIP HOP Tamizha mu...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35136</th>\n",
              "      <td>Just 3k likes for 300k likes</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35137</th>\n",
              "      <td>Aaloo le lo. Kanda le lo.</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35138</th>\n",
              "      <td>நாமக்கல் மாவட்டம்  வன்னியர் சார்பாக திரௌபதி பட...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34898 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    data  ... token_length\n",
              "0                      movie vara level la Erika poguthu  ...            6\n",
              "1      I love Ajith Kumar Vivegam movie inki mjy bht ...  ...           11\n",
              "2              Padam nalla comedy padama irukum polaye..  ...            6\n",
              "3      karthick subburaj anne .... intha padam vetri ...  ...           11\n",
              "4      கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  ...            6\n",
              "...                                                  ...  ...          ...\n",
              "35134  Trending number #2 idhukku nammalam karanamnu ...  ...           15\n",
              "35135  Movie script super, athuvum HIP HOP Tamizha mu...  ...            9\n",
              "35136                       Just 3k likes for 300k likes  ...            6\n",
              "35137                          Aaloo le lo. Kanda le lo.  ...            6\n",
              "35138  நாமக்கல் மாவட்டம்  வன்னியர் சார்பாக திரௌபதி பட...  ...           13\n",
              "\n",
              "[34898 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "_v2Mr6yJU3aj",
        "outputId": "d8a44940-2d71-4cae-ee78-076f96032129"
      },
      "source": [
        "\n",
        "\n",
        "df_result_2['data']=df_result_2['query']\n",
        "df_result_2['label']=df_result_2['predicted_label']\n",
        "\n",
        "tamil_train_new = pd.concat([tamil_train,df_result_2])\n",
        "tamil_train_new\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4387</th>\n",
              "      <td>மண்ணு பொண்ணு ரெண்டுமே ஒன்னு அதுல எவன் கைய வச்ச...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>மண்ணு பொண்ணு ரெண்டுமே ஒன்னு அதுல எவன் கைய வச்ச...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.766744</td>\n",
              "      <td>0.0503728</td>\n",
              "      <td>0.00911015</td>\n",
              "      <td>0.153053</td>\n",
              "      <td>0.0108718</td>\n",
              "      <td>0.00984812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4388</th>\n",
              "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.00502923</td>\n",
              "      <td>0.000932901</td>\n",
              "      <td>0.991985</td>\n",
              "      <td>0.00125333</td>\n",
              "      <td>0.00035997</td>\n",
              "      <td>0.000439906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4389</th>\n",
              "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.433976</td>\n",
              "      <td>0.070667</td>\n",
              "      <td>0.0175401</td>\n",
              "      <td>0.260035</td>\n",
              "      <td>0.0493117</td>\n",
              "      <td>0.16847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4390</th>\n",
              "      <td>Vijay's all movies look like same.</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Vijay's all movies look like same.</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.756128</td>\n",
              "      <td>0.126564</td>\n",
              "      <td>0.00353285</td>\n",
              "      <td>0.091604</td>\n",
              "      <td>0.00840872</td>\n",
              "      <td>0.013763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4391</th>\n",
              "      <td>Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "      <td>0.118437</td>\n",
              "      <td>0.206409</td>\n",
              "      <td>0.0360143</td>\n",
              "      <td>0.371831</td>\n",
              "      <td>0.0636174</td>\n",
              "      <td>0.203691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39290 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  ... Offensive_Untargetede\n",
              "0                     movie vara level la Erika poguthu  ...                   NaN\n",
              "1     I love Ajith Kumar Vivegam movie inki mjy bht ...  ...                   NaN\n",
              "2             Padam nalla comedy padama irukum polaye..  ...                   NaN\n",
              "3     karthick subburaj anne .... intha padam vetri ...  ...                   NaN\n",
              "4     கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  ...                   NaN\n",
              "...                                                 ...  ...                   ...\n",
              "4387  மண்ணு பொண்ணு ரெண்டுமே ஒன்னு அதுல எவன் கைய வச்ச...  ...            0.00984812\n",
              "4388  Babu mele ko ye song sunke kuch yesa feel hua ...  ...           0.000439906\n",
              "4389  asuran= aadukalam+pudupettai+ wada chennai..ye...  ...               0.16847\n",
              "4390                 Vijay's all movies look like same.  ...              0.013763\n",
              "4391  Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...  ...              0.203691\n",
              "\n",
              "[39290 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NobfJMIUUsi8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(tamil_train_new['data'],tamil_train_new['label'], test_size = 0.2, random_state = 42, stratify=tamil_train_new['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3vkSUfDUsi9",
        "outputId": "535bc5f1-2f75-426a-cafe-0c5ef863c8c6"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24687    Punda mathi iruku,evan la nadikalanu ipa yaru ...\n",
              "16896                Suriya anna mass next cm suriya  anna\n",
              "30882            Really semaa Karthik bro.. bgm Vera level\n",
              "146                          Kiya yeh movie Hindi me hai ?\n",
              "8549     15 Million varum nu solravanga mattum like pan...\n",
              "                               ...                        \n",
              "17064    இவரு பாட்ட யாரும் பாடக்கூடாதாம்.... ஆனா இவரு ம...\n",
              "18423                             KRISH-4    HIT LIKE HERE\n",
              "1902        தென் மாவட்டம் சார்பாக வெற்றி பெற வாழ்த்துக்கள்\n",
              "1022     pesi pesi time waste pannama trailer views inc...\n",
              "18629    Edhula aichu nithyamenon last varaik uiyroda i...\n",
              "Name: data, Length: 31432, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJU2xW1eUsi9"
      },
      "source": [
        "X_train_df = pd.concat([X_train, y_train], axis=1, keys=['text', 'label'])\n",
        "X_val_df = pd.concat([X_val, y_val], axis=1, keys=['text', 'label'])\n",
        "X_test_df = pd.concat([tamil_dev['data'], tamil_dev['label']], axis=1, keys=['text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WijUIiOzUsi9"
      },
      "source": [
        "# X_train_df['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "UOje1MIUUsi9",
        "outputId": "c2183e2a-ff84-4f0c-de1d-ebcd31750cf3"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=taen_vocab,text_cols='text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "w_u7HNoFUsi9",
        "outputId": "562e8a3b-1b89-4eda-953d-c0f66c405a20"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ? ▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a ▁x x bo s ▁dai ▁ev anda ▁in tha ▁te as er ▁ kku ▁dis like ▁poo tt avan ▁ivan u hal a ▁ethir kki rav anga ▁ like ▁po du nga ▁x x bo s ▁tha la</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>aya ▁se ruppa la ▁adi kkan um ▁x x bo s ▁eth ana ▁na al ▁tha an ▁na angalum ▁ho ll y wood ▁su per ▁her o ▁va ▁pa ak ur adu ▁nam ma ▁o o ur la um ▁ir ru ka an nga ▁pa ap o om . . . ▁b y ▁a 3 ▁x x bo s ▁se m ma ▁pa . . ▁ but ▁enna ku ▁ind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>▁cel i br ation um ▁dhe e pa vali ▁var e kkum ▁mattum ▁than ▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk . xxunk . xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk . . . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk . . . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>▁the va ▁pad uth u . . . ▁an y way s ▁w ish es ▁f rom ▁nor mal ▁com mon s ▁hu man ▁ wit ho ut ▁an y ▁shi tt y ▁bri de ▁f rom ▁tamilnadu ▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ . . . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk . xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk . ? ▁ xxunk ▁ xxunk ▁x x bo s ▁indian ▁en d ru ▁kur um po th u ▁e ppa di ▁a singam ai ▁i hr uku ▁tamil an ▁en d ru ▁kur um po th u ▁e ppa di ▁unarvu ▁pon kut hu ▁x x bo s ▁ xxunk ▁</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69B4HhoWUsi-"
      },
      "source": [
        "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxJAQRnSdfil"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel/models.zip' -d '/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc_DzlMuUsi-",
        "outputId": "5e5c02d8-aef9-4051-c9aa-e55c27a128ba"
      },
      "source": [
        "# Loading the pretrained language model on malyalam wikipedia\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel/models/best_model', with_opt=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁pun da ▁math i ▁iru ku , e van ▁la ▁nadi kal anu ▁ip a ▁yar u ▁wat ha ▁al u tha,▁x x bo s ▁su riya ▁anna ▁mas s ▁ne x t ▁c m ▁su riya ▁anna,▁x x bo s ▁re al ly ▁se ma a ▁kar thi k ▁br o . . ▁b g m ▁ver a ▁le vel,▁x x bo s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ?,▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁b g m ▁ asu su al ▁theri kka ▁vit aru ▁sam ▁c s,▁x x bo s ▁padi pa ▁mat um ▁edu th uki d ave ▁mudiyath u ▁chi d ambar am ▁enna ▁padi cha ▁b . e xxunk,▁x x bo s ▁vellore ▁ mavatt am ▁vanni ya ▁kul a ▁k sa 3 n ▁mo vi e ▁vatt ri ▁para ▁vayu th u kal,▁x x bo s ▁hi ndi ▁mai ▁k b ▁a aye ga ▁2. 0 ▁ka ▁tra il er,▁x x bo s ▁tha la ▁vant ha ▁po thum . . ▁vis ulu ▁par akum le ▁the ath re ▁le h . . ▁ter ike ▁vid rom . . en ni kum ▁e ppa y um ▁tha la ▁mattum tha . xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(8000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁pun da ▁math i ▁iru ku , e van ▁la ▁nadi kal anu ▁ip a ▁yar u ▁wat ha ▁al u tha,▁x x bo s ▁su riya ▁anna ▁mas s ▁ne x t ▁c m ▁su riya ▁anna,▁x x bo s ▁re al ly ▁se ma a ▁kar thi k ▁br o . . ▁b g m ▁ver a ▁le vel,▁x x bo s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ?,▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁b g m ▁ asu su al ▁theri kka ▁vit aru ▁sam ▁c s,▁x x bo s ▁padi pa ▁mat um ▁edu th uki d ave ▁mudiyath u ▁chi d ambar am ▁enna ▁padi cha ▁b . e xxunk,▁x x bo s ▁vellore ▁ mavatt am ▁vanni ya ▁kul a ▁k sa 3 n ▁mo vi e ▁vatt ri ▁para ▁vayu th u kal,▁x x bo s ▁hi ndi ▁mai ▁k b ▁a aye ga ▁2. 0 ▁ka ▁tra il er,▁x x bo s ▁tha la ▁vant ha ▁po thum . . ▁vis ulu ▁par akum le ▁the ath re ▁le h . . ▁ter ike ▁vid rom . . en ni kum ▁e ppa y um ▁tha la ▁mattum tha . xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: LMTextList\n",
              "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(8000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vSso7WbUsi-"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "V7JrzwIgUsi-",
        "outputId": "380090fd-8606-4267-b0f3-a5bbdef3a86f"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.342346</td>\n",
              "      <td>3.190416</td>\n",
              "      <td>0.450147</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSshThU-Usi-"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "i86Newk8Usi-",
        "outputId": "c38d2e5f-9c89-4763-bed5-77e7c1949aa5"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.047039</td>\n",
              "      <td>2.946275</td>\n",
              "      <td>0.485142</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.818084</td>\n",
              "      <td>2.737316</td>\n",
              "      <td>0.511586</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.663767</td>\n",
              "      <td>2.650596</td>\n",
              "      <td>0.522545</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.578151</td>\n",
              "      <td>2.620064</td>\n",
              "      <td>0.526327</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.541581</td>\n",
              "      <td>2.616519</td>\n",
              "      <td>0.526984</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ka25TvIUsi_"
      },
      "source": [
        "learn.save_encoder('ta_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "itfvYW44Usi_",
        "outputId": "6a57a188-d97d-46dd-aea5-d5bee2438c04"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df,test_df=X_test_df, tokenizer=tokenizer, vocab=taen_vocab,text_cols=['text'], label_cols=['label'], bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "BohPonEpUsi_",
        "outputId": "4b79d658-3569-4020-caa4-e8a7301d2568"
      },
      "source": [
        "data_clas.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁ xxunk ▁ xxrep ▁10 ▁= ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁o k ▁sir , ▁ena ku ▁ore ▁sil a ▁kel vi gal ▁mattum ▁tha a ▁iru ku ▁in tha ▁ padat ha ▁ pathi y um , ▁un ga ▁sa a dhi ▁kala ach a ara tha ▁ pathi y um , ▁kel vi -1 : ▁ne eng a ▁sol dra ▁ma ari ▁un ga ▁sa a thi ▁pengal a ▁em a a than um ▁</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁in tha ▁nad ag a ▁katha l ▁ , ▁sa a thi ▁ver i , ▁it hu ▁ella tha um ▁vid a ▁ne nga ▁yar a ▁vir um puri ngal o ▁avan gal oda ▁ori gin al ity ▁a ▁theri n ju ka ▁t ry ▁pan ung a . . ▁avan ga ▁f am il ya ▁theri n ju ka ▁t ry ▁pan ung a ▁ava</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>▁x x bo s ▁surya ▁ve sh ti ▁ ah ▁cor re c ta ▁madi chu ▁nad akum ▁podhu ▁var a ▁te as er ▁b g m ▁h m m ▁se m m ▁ xxrep ▁5 ▁a ▁ . . . ▁ power fu l ▁di al o gu es ▁and ▁ex p res sion s . . . ▁f d f s . . . ▁selva ra gh avan</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HLjlamaUsi_"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAjyAoN3Usi_",
        "outputId": "a1a0975b-1bff-4327-fb75-fd5eab61e533"
      },
      "source": [
        "learn.load_encoder('ta_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁pun da ▁math i ▁iru ku , e van ▁la ▁nadi kal anu ▁ip a ▁yar u ▁wat ha ▁al u tha,▁x x bo s ▁su riya ▁anna ▁mas s ▁ne x t ▁c m ▁su riya ▁anna,▁x x bo s ▁re al ly ▁se ma a ▁kar thi k ▁br o . . ▁b g m ▁ver a ▁le vel,▁x x bo s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ?,▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁b g m ▁ asu su al ▁theri kka ▁vit aru ▁sam ▁c s,▁x x bo s ▁padi pa ▁mat um ▁edu th uki d ave ▁mudiyath u ▁chi d ambar am ▁enna ▁padi cha ▁b . e xxunk,▁x x bo s ▁vellore ▁ mavatt am ▁vanni ya ▁kul a ▁k sa 3 n ▁mo vi e ▁vatt ri ▁para ▁vayu th u kal,▁x x bo s ▁hi ndi ▁mai ▁k b ▁a aye ga ▁2. 0 ▁ka ▁tra il er,▁x x bo s ▁tha la ▁vant ha ▁po thum . . ▁vis ulu ▁par akum le ▁the ath re ▁le h . . ▁ter ike ▁vid rom . . en ni kum ▁e ppa y um ▁tha la ▁mattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁pun da ▁math i ▁iru ku , e van ▁la ▁nadi kal anu ▁ip a ▁yar u ▁wat ha ▁al u tha,▁x x bo s ▁su riya ▁anna ▁mas s ▁ne x t ▁c m ▁su riya ▁anna,▁x x bo s ▁re al ly ▁se ma a ▁kar thi k ▁br o . . ▁b g m ▁ver a ▁le vel,▁x x bo s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ?,▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁b g m ▁ asu su al ▁theri kka ▁vit aru ▁sam ▁c s,▁x x bo s ▁padi pa ▁mat um ▁edu th uki d ave ▁mudiyath u ▁chi d ambar am ▁enna ▁padi cha ▁b . e xxunk,▁x x bo s ▁vellore ▁ mavatt am ▁vanni ya ▁kul a ▁k sa 3 n ▁mo vi e ▁vatt ri ▁para ▁vayu th u kal,▁x x bo s ▁hi ndi ▁mai ▁k b ▁a aye ga ▁2. 0 ▁ka ▁tra il er,▁x x bo s ▁tha la ▁vant ha ▁po thum . . ▁vis ulu ▁par akum le ▁the ath re ▁le h . . ▁ter ike ▁vid rom . . en ni kum ▁e ppa y um ▁tha la ▁mattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BAFF0EMUsjA"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Yl7YVfUsjA",
        "outputId": "f08edc4c-b0d2-42a7-fdf4-14586b1ff562"
      },
      "source": [
        "learn.loss_func.func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmdsdYr1UsjA"
      },
      "source": [
        "mcc = MatthewsCorreff()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fVLQLi4UsjA"
      },
      "source": [
        "learn.metrics = [mcc, accuracy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "DRe8ZtvcUsjA",
        "outputId": "ce76f5f0-fa00-4ff0-beca-82c7fbd34260"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.756907</td>\n",
              "      <td>0.746978</td>\n",
              "      <td>0.260864</td>\n",
              "      <td>0.759735</td>\n",
              "      <td>02:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "1Q3kHq-pUsjA",
        "outputId": "dbc32053-9039-44ee-d07c-506310f405a8"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.714599</td>\n",
              "      <td>0.689862</td>\n",
              "      <td>0.359258</td>\n",
              "      <td>0.776788</td>\n",
              "      <td>02:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD21VEJrUsjB"
      },
      "source": [
        "learn.save('ta_en_second-full')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "JP9eH5P8UsjB",
        "outputId": "257e3e77-0892-459a-9357-eb3ba0bf9cd7"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='ta_en_final')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.689207</td>\n",
              "      <td>0.685190</td>\n",
              "      <td>0.398968</td>\n",
              "      <td>0.781878</td>\n",
              "      <td>03:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.690695</td>\n",
              "      <td>0.682075</td>\n",
              "      <td>0.383667</td>\n",
              "      <td>0.781878</td>\n",
              "      <td>03:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.566103</td>\n",
              "      <td>0.666720</td>\n",
              "      <td>0.423357</td>\n",
              "      <td>0.787223</td>\n",
              "      <td>03:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.661854</td>\n",
              "      <td>0.666134</td>\n",
              "      <td>0.429674</td>\n",
              "      <td>0.790150</td>\n",
              "      <td>03:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.583230</td>\n",
              "      <td>0.666931</td>\n",
              "      <td>0.443367</td>\n",
              "      <td>0.789005</td>\n",
              "      <td>03:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.7818783521652222.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with accuracy value: 0.787223219871521.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with accuracy value: 0.7901501655578613.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8_yljAvUsjB",
        "outputId": "8df5d9ca-9f43-4ab4-9e73-81d0b4cf0c99"
      },
      "source": [
        "learn.load('ta_en_final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁pun da ▁math i ▁iru ku , e van ▁la ▁nadi kal anu ▁ip a ▁yar u ▁wat ha ▁al u tha,▁x x bo s ▁su riya ▁anna ▁mas s ▁ne x t ▁c m ▁su riya ▁anna,▁x x bo s ▁re al ly ▁se ma a ▁kar thi k ▁br o . . ▁b g m ▁ver a ▁le vel,▁x x bo s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ?,▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁b g m ▁ asu su al ▁theri kka ▁vit aru ▁sam ▁c s,▁x x bo s ▁padi pa ▁mat um ▁edu th uki d ave ▁mudiyath u ▁chi d ambar am ▁enna ▁padi cha ▁b . e xxunk,▁x x bo s ▁vellore ▁ mavatt am ▁vanni ya ▁kul a ▁k sa 3 n ▁mo vi e ▁vatt ri ▁para ▁vayu th u kal,▁x x bo s ▁hi ndi ▁mai ▁k b ▁a aye ga ▁2. 0 ▁ka ▁tra il er,▁x x bo s ▁tha la ▁vant ha ▁po thum . . ▁vis ulu ▁par akum le ▁the ath re ▁le h . . ▁ter ike ▁vid rom . . en ni kum ▁e ppa y um ▁tha la ▁mattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁pun da ▁math i ▁iru ku , e van ▁la ▁nadi kal anu ▁ip a ▁yar u ▁wat ha ▁al u tha,▁x x bo s ▁su riya ▁anna ▁mas s ▁ne x t ▁c m ▁su riya ▁anna,▁x x bo s ▁re al ly ▁se ma a ▁kar thi k ▁br o . . ▁b g m ▁ver a ▁le vel,▁x x bo s ▁ki ya ▁ye h ▁mo vi e ▁hi ndi ▁me ▁ha i ▁ ?,▁x x bo s ▁15 ▁million ▁varum ▁nu ▁sol rav anga ▁mattum ▁ like ▁pann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁b g m ▁ asu su al ▁theri kka ▁vit aru ▁sam ▁c s,▁x x bo s ▁padi pa ▁mat um ▁edu th uki d ave ▁mudiyath u ▁chi d ambar am ▁enna ▁padi cha ▁b . e xxunk,▁x x bo s ▁vellore ▁ mavatt am ▁vanni ya ▁kul a ▁k sa 3 n ▁mo vi e ▁vatt ri ▁para ▁vayu th u kal,▁x x bo s ▁hi ndi ▁mai ▁k b ▁a aye ga ▁2. 0 ▁ka ▁tra il er,▁x x bo s ▁tha la ▁vant ha ▁po thum . . ▁vis ulu ▁par akum le ▁the ath re ▁le h . . ▁ter ike ▁vid rom . . en ni kum ▁e ppa y um ▁tha la ▁mattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁ xxunk ▁ xxrep ▁5 ▁ . ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxunk ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "sIpIH18TUsjB",
        "outputId": "0b7d577a-4cd0-4835-868d-9b1b32c12028"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "df_dict = {'query': list(tamil_dev['data']), 'actual_label': list(tamil_dev['label']), 'predicted_label': ['']*tamil_dev.shape[0]}\n",
        "all_nodes = list(set(tamil_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*tamil_dev.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "    \n",
        "df_result = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>actual_label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Handsome hunk  keri vaa thalaivaa</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.916551</td>\n",
              "      <td>0.00724097</td>\n",
              "      <td>0.00865</td>\n",
              "      <td>0.0110568</td>\n",
              "      <td>0.00214555</td>\n",
              "      <td>0.0543557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>தென்காசி மாவட்டம் நாடார் சமுதாயம் சார்பாக வாழ்...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.815139</td>\n",
              "      <td>0.0541358</td>\n",
              "      <td>0.0150543</td>\n",
              "      <td>0.084791</td>\n",
              "      <td>0.0080838</td>\n",
              "      <td>0.0227958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>je vous aime bravo pour clip de merde que j éc...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.0453488</td>\n",
              "      <td>0.00458638</td>\n",
              "      <td>0.946284</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.00056139</td>\n",
              "      <td>0.00198686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>சிறப்பு..... மேலும் இது போன்ற படைப்புகள் மிக அ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.835185</td>\n",
              "      <td>0.0371791</td>\n",
              "      <td>0.00562095</td>\n",
              "      <td>0.100766</td>\n",
              "      <td>0.00728475</td>\n",
              "      <td>0.0139635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vera level BGM .. semma  trailer. 🤞</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.97987</td>\n",
              "      <td>0.0021728</td>\n",
              "      <td>0.000523575</td>\n",
              "      <td>0.0124726</td>\n",
              "      <td>0.00112337</td>\n",
              "      <td>0.00383817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... Offensive_Untargetede\n",
              "0                  Handsome hunk  keri vaa thalaivaa  ...             0.0543557\n",
              "1  தென்காசி மாவட்டம் நாடார் சமுதாயம் சார்பாக வாழ்...  ...             0.0227958\n",
              "2  je vous aime bravo pour clip de merde que j éc...  ...            0.00198686\n",
              "3  சிறப்பு..... மேலும் இது போன்ற படைப்புகள் மிக அ...  ...             0.0139635\n",
              "4                Vera level BGM .. semma  trailer. 🤞  ...            0.00383817\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "8g-xmsqJFNwV",
        "outputId": "097a9b9f-3173-4746-c99c-132723ab9bbe"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "\n",
        "data_lm_2 = TextClasDataBunch.from_df(path='/content',train_df=X_train_df, valid_df=X_val_df,  test_df=tamil_test, tokenizer=tokenizer, vocab=taen_vocab,text_cols='text',label_cols=['label'])\n",
        "learn = text_classifier_learner(data_lm_2, arch=AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ta_en_fine_tuned_enc')\n",
        "learn.load('/content/models/ta_en_final')\n",
        "\n",
        "df_dict = {'query': list(tamil_test['text']), 'predicted_label': ['']*tamil_test.shape[0]}\n",
        "all_nodes = list(set(tamil_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*tamil_test.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "\n",
        "\n",
        "df_result_2 = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result_2.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result_2.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.12.2018 epo trailer pathutu irken ... Semay...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.933539</td>\n",
              "      <td>0.0125657</td>\n",
              "      <td>0.000161656</td>\n",
              "      <td>0.0142688</td>\n",
              "      <td>0.00379991</td>\n",
              "      <td>0.0356647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paka thana poro movie la Enna irukunu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.884475</td>\n",
              "      <td>0.00980871</td>\n",
              "      <td>0.000540717</td>\n",
              "      <td>0.0301754</td>\n",
              "      <td>0.00785153</td>\n",
              "      <td>0.0671488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.108697</td>\n",
              "      <td>0.000490859</td>\n",
              "      <td>0.888975</td>\n",
              "      <td>0.000768708</td>\n",
              "      <td>0.000254336</td>\n",
              "      <td>0.000814123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suriya anna vera level anna mass</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.995826</td>\n",
              "      <td>0.0005907</td>\n",
              "      <td>0.00175378</td>\n",
              "      <td>0.000963272</td>\n",
              "      <td>0.000355577</td>\n",
              "      <td>0.000511215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
              "      <td>Offensive_Targeted_Insult_Individual</td>\n",
              "      <td>0.00735499</td>\n",
              "      <td>0.965543</td>\n",
              "      <td>6.06248e-06</td>\n",
              "      <td>0.0153884</td>\n",
              "      <td>0.00287892</td>\n",
              "      <td>0.00882823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... Offensive_Untargetede\n",
              "0  14.12.2018 epo trailer pathutu irken ... Semay...  ...             0.0356647\n",
              "1              Paka thana poro movie la Enna irukunu  ...             0.0671488\n",
              "2  “U kena tunggu lebih lama lagi untuk tahu saya...  ...           0.000814123\n",
              "3                   Suriya anna vera level anna mass  ...           0.000511215\n",
              "4  suma kaththaatha da sound over a pooda kudaath...  ...            0.00882823\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "PmKrv9bJUeF_",
        "outputId": "d5275dc9-9b3c-4e91-f413-ce0b49952774"
      },
      "source": [
        "df_result_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.12.2018 epo trailer pathutu irken ... Semay...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.933539</td>\n",
              "      <td>0.0125657</td>\n",
              "      <td>0.000161656</td>\n",
              "      <td>0.0142688</td>\n",
              "      <td>0.00379991</td>\n",
              "      <td>0.0356647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paka thana poro movie la Enna irukunu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.884475</td>\n",
              "      <td>0.00980871</td>\n",
              "      <td>0.000540717</td>\n",
              "      <td>0.0301754</td>\n",
              "      <td>0.00785153</td>\n",
              "      <td>0.0671488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.108697</td>\n",
              "      <td>0.000490859</td>\n",
              "      <td>0.888975</td>\n",
              "      <td>0.000768708</td>\n",
              "      <td>0.000254336</td>\n",
              "      <td>0.000814123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suriya anna vera level anna mass</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.995826</td>\n",
              "      <td>0.0005907</td>\n",
              "      <td>0.00175378</td>\n",
              "      <td>0.000963272</td>\n",
              "      <td>0.000355577</td>\n",
              "      <td>0.000511215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
              "      <td>Offensive_Targeted_Insult_Individual</td>\n",
              "      <td>0.00735499</td>\n",
              "      <td>0.965543</td>\n",
              "      <td>6.06248e-06</td>\n",
              "      <td>0.0153884</td>\n",
              "      <td>0.00287892</td>\n",
              "      <td>0.00882823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4387</th>\n",
              "      <td>மண்ணு பொண்ணு ரெண்டுமே ஒன்னு அதுல எவன் கைய வச்ச...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.804067</td>\n",
              "      <td>0.0462996</td>\n",
              "      <td>0.00572953</td>\n",
              "      <td>0.122385</td>\n",
              "      <td>0.00809177</td>\n",
              "      <td>0.0134272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4388</th>\n",
              "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.00732125</td>\n",
              "      <td>0.000576099</td>\n",
              "      <td>0.991246</td>\n",
              "      <td>0.000474777</td>\n",
              "      <td>0.000115585</td>\n",
              "      <td>0.000266283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4389</th>\n",
              "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.455658</td>\n",
              "      <td>0.0601226</td>\n",
              "      <td>0.0147018</td>\n",
              "      <td>0.139337</td>\n",
              "      <td>0.0395907</td>\n",
              "      <td>0.290589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4390</th>\n",
              "      <td>Vijay's all movies look like same.</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.814768</td>\n",
              "      <td>0.104247</td>\n",
              "      <td>0.00771375</td>\n",
              "      <td>0.0489836</td>\n",
              "      <td>0.0128513</td>\n",
              "      <td>0.0114361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4391</th>\n",
              "      <td>Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...</td>\n",
              "      <td>Offensive_Untargetede</td>\n",
              "      <td>0.148166</td>\n",
              "      <td>0.0568848</td>\n",
              "      <td>0.00879186</td>\n",
              "      <td>0.256198</td>\n",
              "      <td>0.0474622</td>\n",
              "      <td>0.482497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4392 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  query  ... Offensive_Untargetede\n",
              "0     14.12.2018 epo trailer pathutu irken ... Semay...  ...             0.0356647\n",
              "1                 Paka thana poro movie la Enna irukunu  ...             0.0671488\n",
              "2     “U kena tunggu lebih lama lagi untuk tahu saya...  ...           0.000814123\n",
              "3                      Suriya anna vera level anna mass  ...           0.000511215\n",
              "4     suma kaththaatha da sound over a pooda kudaath...  ...            0.00882823\n",
              "...                                                 ...  ...                   ...\n",
              "4387  மண்ணு பொண்ணு ரெண்டுமே ஒன்னு அதுல எவன் கைய வச்ச...  ...             0.0134272\n",
              "4388  Babu mele ko ye song sunke kuch yesa feel hua ...  ...           0.000266283\n",
              "4389  asuran= aadukalam+pudupettai+ wada chennai..ye...  ...              0.290589\n",
              "4390                 Vijay's all movies look like same.  ...             0.0114361\n",
              "4391  Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...  ...              0.482497\n",
              "\n",
              "[4392 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZcSRFY-UsjB",
        "outputId": "dd99bec3-569b-46a0-c685-3a1bf7527b57"
      },
      "source": [
        "accuracy_score(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7766636280765725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahTaia5JUsjC",
        "outputId": "09c5cccd-221c-4d63-82a0-b568238e1974"
      },
      "source": [
        "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4116986942218667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjK2zdm6UsjC",
        "outputId": "21f8d292-760a-426b-9107-8a0a89718009"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(df_result['actual_label'], df_result['predicted_label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "                       Not_offensive       0.81      0.96      0.88      3193\n",
            "     Offensive_Targeted_Insult_Group       0.41      0.13      0.20       295\n",
            "Offensive_Targeted_Insult_Individual       0.52      0.26      0.35       307\n",
            "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
            "               Offensive_Untargetede       0.46      0.25      0.32       356\n",
            "                           not-Tamil       0.86      0.70      0.77       172\n",
            "\n",
            "                            accuracy                           0.78      4388\n",
            "                           macro avg       0.51      0.38      0.42      4388\n",
            "                        weighted avg       0.72      0.78      0.73      4388\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeZfZzfOUsjC"
      },
      "source": [
        "df_result.to_excel('taen_ml.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAtMXIzNUr1w"
      },
      "source": [
        "df_result_2.to_excel('taen_ml_test_preds.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf0han8CrxD8"
      },
      "source": [
        "# precision    recall  f1-score   support\n",
        "\n",
        "#                        Not_offensive       0.81      0.96      0.88      3193\n",
        "#      Offensive_Targeted_Insult_Group       0.41      0.13      0.20       295\n",
        "# Offensive_Targeted_Insult_Individual       0.52      0.26      0.35       307\n",
        "#      Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
        "#                Offensive_Untargetede       0.46      0.25      0.32       356\n",
        "#                            not-Tamil       0.86      0.70      0.77       172\n",
        "\n",
        "#                             accuracy                           0.78      4388\n",
        "#                            macro avg       0.51      0.38      0.42      4388\n",
        "#                         weighted avg       0.72      0.78      0.73      4388"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0o1O5K-fPTv"
      },
      "source": [
        "!mv '/content/models' '/content/drive/MyDrive/AggressionNLP/TamilEnglishResults'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}