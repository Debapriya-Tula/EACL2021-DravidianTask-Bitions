{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malayalam&Tamil_PseudoLabelling AggressionNLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeOfcNmWoXVX"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmVdECMZhXM5"
      },
      "source": [
        "cols=['data','label','index']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh0WiAcPqlj8"
      },
      "source": [
        " # Malayalam Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeR7l5C8gVUM"
      },
      "source": [
        "mal_train = pd.read_csv('/content/drive/MyDrive/mal_full_offensive_train.csv',sep='\\t',names=cols)\n",
        "mal_dev= pd.read_csv('/content/drive/MyDrive/mal_full_offensive_dev.csv',sep='\\t',names=cols)\n",
        "mal_test = pd.read_csv('/content/drive/MyDrive/mal_full_offensive_test.csv',sep='\\t',names=['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "126ray1WgfTb"
      },
      "source": [
        "mal_train = mal_train[['data','label']]\n",
        "mal_dev = mal_dev[['data','label']]\n",
        "mal_test = mal_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lARPtI7bicjB",
        "outputId": "e0f06b46-1f03-47d4-bea7-c5d00d8f4727"
      },
      "source": [
        "mal_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç. ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡¥à ‡¥ì‡¥£‡¥Ç ‡¥è‡¥ü‡µç‡¥ü‡¥®‡µÅ‡¥Ç ‡¥™‡¥ø‡¥≥‡µç‡¥≥‡µá‡µº‡¥ï‡µç‡¥ï‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥§‡¥æ‡¥£‡µç ‡¥é‡¥®‡µç‡¥®‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥µ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0  ‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç. ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§...  Not_offensive\n",
              "1  ‡¥à ‡¥ì‡¥£‡¥Ç ‡¥è‡¥ü‡µç‡¥ü‡¥®‡µÅ‡¥Ç ‡¥™‡¥ø‡¥≥‡µç‡¥≥‡µá‡µº‡¥ï‡µç‡¥ï‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥§‡¥æ‡¥£‡µç ‡¥é‡¥®‡µç‡¥®‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥µ...  Not_offensive\n",
              "2  ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç...  Not_offensive\n",
              "3          Sushin syam  Shaiju khalid  Midhun manual  Not_offensive\n",
              "4                          J A K E S.   B EJ O Y !!!  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0c5F_sZghiY",
        "outputId": "bbad6893-fabe-4c25-ae75-c7d6999a50fa"
      },
      "source": [
        "mal_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16010 entries, 0 to 16009\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    16010 non-null  object\n",
            " 1   label   16010 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 250.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzAypPcVPzri",
        "outputId": "73c7387f-f2ac-4d8b-ac74-cb6336685257"
      },
      "source": [
        "mal_train[mal_train['label']=='not-malayalam']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Semma voice.  ..Iam Tamil Nadu</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Mere naam ka kachra karo sab mil k</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>I am waiting for kappan Moganla and Surya</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>MALAYALAM DJ REMIX NEW NON STOP EVERGREENSONGS...</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>Thrissur pooram trailer  hidden details</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15957</th>\n",
              "      <td>poli...but felt like a mix of korean serial ki...</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15980</th>\n",
              "      <td>Tamil film Pizza de oru style</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15986</th>\n",
              "      <td>Iam tamil but i love malayalam</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>All india lalettan fans  Hit like</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16008</th>\n",
              "      <td>Like from Madurai (Tamil nadu) ....</td>\n",
              "      <td>not-malayalam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1287 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    data          label\n",
              "25                        Semma voice.  ..Iam Tamil Nadu  not-malayalam\n",
              "47                    Mere naam ka kachra karo sab mil k  not-malayalam\n",
              "74             I am waiting for kappan Moganla and Surya  not-malayalam\n",
              "89     MALAYALAM DJ REMIX NEW NON STOP EVERGREENSONGS...  not-malayalam\n",
              "108              Thrissur pooram trailer  hidden details  not-malayalam\n",
              "...                                                  ...            ...\n",
              "15957  poli...but felt like a mix of korean serial ki...  not-malayalam\n",
              "15980                      Tamil film Pizza de oru style  not-malayalam\n",
              "15986                     Iam tamil but i love malayalam  not-malayalam\n",
              "15997                  All india lalettan fans  Hit like  not-malayalam\n",
              "16008                Like from Madurai (Tamil nadu) ....  not-malayalam\n",
              "\n",
              "[1287 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA9uGUi4gjZm",
        "outputId": "4176ed42-84f9-4f4f-d4cf-2ab97110df2c"
      },
      "source": [
        "mal_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           14153\n",
              "not-malayalam                            1287\n",
              "Offensive_Targeted_Insult_Individual      239\n",
              "Offensive_Untargetede                     191\n",
              "Offensive_Targeted_Insult_Group           140\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "civzfUfPipDL",
        "outputId": "6242d0a4-5e51-4910-e893-fefe6436266a"
      },
      "source": [
        "print(len(mal_train))\n",
        "mal_train = mal_train.drop_duplicates()\n",
        "print(len(mal_train))\n",
        "mal_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16010\n",
            "11695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           10382\n",
              "not-malayalam                             882\n",
              "Offensive_Targeted_Insult_Individual      171\n",
              "Offensive_Untargetede                     154\n",
              "Offensive_Targeted_Insult_Group           106\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns6NoLoRkH-L",
        "outputId": "e85cab2d-5c4c-4707-a1ef-271d2a474b25"
      },
      "source": [
        "mal_train['token_length'] = [len(x.split(\" \")) for x in mal_train.data]\n",
        "print(max(mal_train.token_length))\n",
        "print(min(mal_train.token_length))\n",
        "print(sum(mal_train.token_length)/len(mal_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224\n",
            "1\n",
            "9.707396323215049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkeFX9h8qrUL"
      },
      "source": [
        " # Tamil Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0596OJtkZh_"
      },
      "source": [
        "tamil_train = pd.read_csv('/content/drive/MyDrive/tamil_offensive_full_train.csv',sep='\\t',names=cols)\n",
        "tamil_dev= pd.read_csv('/content/drive/MyDrive/tamil_offensive_full_dev.csv',sep='\\t',names=cols)\n",
        "tamil_test = pd.read_csv('/content/drive/MyDrive/tamil_offensive_full_test.csv',sep='\\t',names=['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDRlZgMSpyB2"
      },
      "source": [
        "tamil_train = tamil_train[['data','label']]\n",
        "tamil_dev = tamil_dev[['data','label']]\n",
        "tamil_test = tamil_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj30bqBPqAL_",
        "outputId": "8df18dc9-b0b1-433f-82e8-eab298314d53"
      },
      "source": [
        "tamil_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0                  movie vara level la Erika poguthu  Not_offensive\n",
              "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n",
              "2          Padam nalla comedy padama irukum polaye..  Not_offensive\n",
              "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n",
              "4  ‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1VOpZPRqJLD",
        "outputId": "cbdda776-d0df-48c8-a4fd-a0fd70c4325f"
      },
      "source": [
        "tamil_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35139 entries, 0 to 35138\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    35139 non-null  object\n",
            " 1   label   35139 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 549.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR_fnvcnqKxx",
        "outputId": "eaf8f3d2-04cc-405a-b7d5-0ff0f536f110"
      },
      "source": [
        "tamil_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           25425\n",
              "Offensive_Untargetede                    2906\n",
              "Offensive_Targeted_Insult_Group          2557\n",
              "Offensive_Targeted_Insult_Individual     2343\n",
              "not-Tamil                                1454\n",
              "Offensive_Targeted_Insult_Other           454\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEIb6xtbqQpX",
        "outputId": "22f33c4f-c1cd-4eb7-b6bf-f3e40b79a845"
      },
      "source": [
        "print(len(tamil_train))\n",
        "tamil_train = tamil_train.drop_duplicates()\n",
        "print(len(tamil_train))\n",
        "tamil_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35139\n",
            "34898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           25215\n",
              "Offensive_Untargetede                    2894\n",
              "Offensive_Targeted_Insult_Group          2550\n",
              "Offensive_Targeted_Insult_Individual     2338\n",
              "not-Tamil                                1447\n",
              "Offensive_Targeted_Insult_Other           454\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFMUBqX-qT92",
        "outputId": "73277108-7791-41b3-d2f6-672a7280eac2"
      },
      "source": [
        "tamil_train['token_length'] = [len(x.split(\" \")) for x in tamil_train.data]\n",
        "print(max(tamil_train.token_length))\n",
        "print(min(tamil_train.token_length))\n",
        "print(sum(tamil_train.token_length)/len(tamil_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152\n",
            "1\n",
            "10.86618144306264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyIq8yVorLSn"
      },
      "source": [
        "# Kannada data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXGbeChFqWc5"
      },
      "source": [
        "kannada_train = pd.read_csv('/content/drive/MyDrive/kannada_offensive_train.csv',sep='\\t',names=cols)\n",
        "kannada_dev= pd.read_csv('/content/drive/MyDrive/kannada_offensive_dev.csv',sep='\\t',names=cols)\n",
        "kannada_test = pd.read_csv('/content/drive/MyDrive/kannada_offensive_test.csv',sep='\\t',names=['data'])\n",
        "kannada_train = kannada_train[['data','label']]\n",
        "kannada_dev = kannada_dev[['data','label']]\n",
        "kannada_test = kannada_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcktB08pquQV",
        "outputId": "75efe5d6-92fd-46b4-a6a0-e4e738524d9d"
      },
      "source": [
        "kannada_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tik tok alli jagala madtidralla adra baggenu o...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anyone from kerala here</td>\n",
              "      <td>not-Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie rerelease madi plss</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amazon prime alli bittidira....yella manele no...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Guru sure news nanu tik tok dawn lod madeda ya...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0  Tik tok alli jagala madtidralla adra baggenu o...  Not_offensive\n",
              "1                            Anyone from kerala here    not-Kannada\n",
              "2                          Movie rerelease madi plss  Not_offensive\n",
              "3  Amazon prime alli bittidira....yella manele no...  Not_offensive\n",
              "4  Guru sure news nanu tik tok dawn lod madeda ya...  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR7FQUZgq8TJ",
        "outputId": "6f15e8f6-389f-495a-cda7-0ea1daf5db13"
      },
      "source": [
        "kannada_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6217 entries, 0 to 6216\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    6217 non-null   object\n",
            " 1   label   6217 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 97.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-IXQZ3kq-M-",
        "outputId": "f7fc7f9c-0c53-44ce-b455-572dd7bd6836"
      },
      "source": [
        "print(len(kannada_train))\n",
        "kannada_train = kannada_train.drop_duplicates()\n",
        "print(len(kannada_train))\n",
        "kannada_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6217\n",
            "5936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           3382\n",
              "not-Kannada                             1407\n",
              "Offensive_Targeted_Insult_Individual     486\n",
              "Offensive_Targeted_Insult_Group          327\n",
              "Offensive_Untargetede                    212\n",
              "Offensive_Targeted_Insult_Other          122\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sydvTcZ7rAzc",
        "outputId": "528102de-958e-4cae-f5bb-caf4988eea05"
      },
      "source": [
        "kannada_train['token_length'] = [len(x.split(\" \")) for x in kannada_train.data]\n",
        "print(max(kannada_train.token_length))\n",
        "print(min(kannada_train.token_length))\n",
        "print(sum(kannada_train.token_length)/len(kannada_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n",
            "1\n",
            "8.141677897574125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSCgUvtCuENc"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XElKehJjrGiz",
        "outputId": "709a00f8-10d9-4013-d7b5-9ce62eb228cf"
      },
      "source": [
        "!pip install indic-nlp-library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.19.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Installing collected packages: morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ctdevt8AzIl",
        "outputId": "d2e574d2-1726-4124-87c2-25dc47ac9a7e"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 41.40 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSE_pcYviHoc"
      },
      "source": [
        "INDIC_NLP_RESOURCES=r\"/content/indic_nlp_resources\"\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkKukZJkBaIF"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHCiLp9r9Oay"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YneaCz4whVT0",
        "outputId": "66305f8a-8919-41ed-943a-e11f44a5f3a2"
      },
      "source": [
        "mal_lines = []\n",
        "for i in mal_train['data']:\n",
        "  mal_lines.append(i)\n",
        "len(mal_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2k0-lmBuIFG"
      },
      "source": [
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "\n",
        "# input_text=\"‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç. ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‡¥∞‡¥æ‡¥ú‡¥µ‡¥Ø‡¥§‡µç ‡¥Ö‡¥≤‡µç‡¥≤\"\n",
        "# remove_nuktas=False\n",
        "factory=IndicNormalizerFactory()\n",
        "normalizer=factory.get_normalizer(\"ml\")\n",
        "\n",
        "# %%time\n",
        "nor_mal_lines = []\n",
        "for i in range(len(mal_lines)):\n",
        "  nor_mal_line = normalizer.normalize(mal_lines[i])\n",
        "  nor_mal_lines.append(nor_mal_line)\n",
        "# new_mal_lines "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDZWW-d8uqmD",
        "outputId": "1887b1ed-3051-49b6-ab4f-de37e3ab6225"
      },
      "source": [
        "len(nor_mal_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1TWLIlU-6lM"
      },
      "source": [
        "Tokenization word level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL5h8qy52UUD"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "tokenized_mal_lines = []\n",
        "for i in range(len(mal_lines)):\n",
        "  tokenized_mal_line = indic_tokenize.trivial_tokenize(nor_mal_lines[i])\n",
        "  tokenized_mal_lines.append(tokenized_mal_line)\n",
        "# tokenized_mal_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkotkbN75aTV",
        "outputId": "1a37fe4b-e5ac-469b-fe61-971b335652f5"
      },
      "source": [
        "tokenized_mal_lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " 'Royal',\n",
              " 'Mech',\n",
              " '‡¥Ü‡¥ü‡¥æ',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥Æ‡µÄ‡¥∂',\n",
              " '‡¥™‡¥ø‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " 'royal',\n",
              " 'Mech',\n",
              " '‡¥Ü‡¥ü‡¥æ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTZdMa7S7THG",
        "outputId": "a39f356a-000d-4191-994e-9e4e5621cb78"
      },
      "source": [
        "mal_lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª Royal Mech ‡¥Ü‡¥ü‡¥æ  ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Æ‡µÄ‡¥∂ ‡¥™‡¥ø‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥® ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª royal Mech ‡¥Ü‡¥ü‡¥æ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNJ589jE_3l4",
        "outputId": "f039dd7a-656c-4dfa-9847-3a1f2ba68df3"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "transliterated_mal_lines = []\n",
        "flags=[]\n",
        "for i in range(len(mal_lines)):\n",
        "  transliterated_mal_line = ItransTransliterator.from_itrans(mal_lines[i],'ml')\n",
        "  if(transliterated_mal_line == mal_lines[i]):\n",
        "    flag=1\n",
        "  else:\n",
        "    flag=0\n",
        "  flags.append(flag)\n",
        "  transliterated_mal_lines.append(transliterated_mal_line)\n",
        "transliterated_mal_lines[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç\\u0d64 ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‡¥∞‡¥æ‡¥ú‡¥µ‡¥Ø‡¥§‡µç ‡¥Ö‡¥≤‡µç‡¥≤'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4i9ECuUAa0r",
        "outputId": "eada95f8-3050-46b1-a69b-f2128fb86eec"
      },
      "source": [
        "print('native malayalam sentences: ',sum(flags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "native malayalam sentences:  1298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3GVT_UHDUX3",
        "outputId": "8453beba-0d43-4803-be4c-7aae3588ba4e"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "en_transliterated_mal_lines = []\n",
        "flags=[]\n",
        "for i in range(len(mal_lines)):\n",
        "  en_transliterated_mal_line = ItransTransliterator.to_itrans(mal_lines[i],'ml')\n",
        "  if(en_transliterated_mal_line == mal_lines[i]):\n",
        "    flag=1\n",
        "  else:\n",
        "    flag=0\n",
        "  flags.append(flag)\n",
        "  en_transliterated_mal_lines.append(en_transliterated_mal_line)\n",
        "en_transliterated_mal_lines[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'paladesha.m. pala bhaaSha .ore .oru raajaav  allaat.e  svanta.m raajavayat alla'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whg64WtK3QP",
        "outputId": "a3871dcc-26ab-408d-d665-53e4c41dab02"
      },
      "source": [
        "whole_mal_train = ''\n",
        "for i in range(len(mal_lines)):\n",
        "  whole_mal_train+=str(mal_lines[i])\n",
        "len(whole_mal_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "793979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdZR_pY4Mh5F",
        "outputId": "b191c2d1-4ba6-4513-b370-d8d0acd53229"
      },
      "source": [
        "from indicnlp.langinfo import *\n",
        "\n",
        "lang='ml'\n",
        "vowels = 0\n",
        "for i in range(len(whole_mal_train)):\n",
        "  if(is_vowel(whole_mal_train[i],lang)):\n",
        "    vowels+=1\n",
        "print('Total characters: ',len(whole_mal_train))\n",
        "print('Total vowels: ',vowels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters:  793979\n",
            "Total vowels:  12759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXJ0Pe-kUjoJ"
      },
      "source": [
        "#ULMFiT Malayalam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkRGvPiiVbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52eb093-1f16-4675-f2ae-537b5d6e4b8f"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA7y6RqITFL2"
      },
      "source": [
        "#reference: https://github.com/goru001/nlp-for-malyalam/blob/master/classification/Malyalam_Classification_Model.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciWz6KQDNLNx"
      },
      "source": [
        "from fastai.text import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaPnd2txPS1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc64c49-7ada-493d-b6e3-fcf85e976783"
      },
      "source": [
        "import fastai, torch\n",
        "fastai.__version__ , torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.0.61', '1.7.0+cu101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WDShsGvZVpF"
      },
      "source": [
        "def handle_all_caps(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = replace_all_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def handle_upper_case_first_letter(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = deal_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def lower_case_everything(t: str) -> str:\n",
        "    return t.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9SfSd2PZ25"
      },
      "source": [
        "class CodeMixedMalayalamTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.lang = lang\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/code-mixed-enma/tokenizer_mixed_script/mlen_spm.model\"))\n",
        "        \n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        return self.sp.EncodeAsPieces(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzONojGGPhkg"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/code-mixed-enma/tokenizer_mixed_script/mlen_spm.model\"))\n",
        "itos = [sp.IdToPiece(int(i)) for i in range(25000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E66bBfRbPprc"
      },
      "source": [
        "# 25,000 is the vocab size that we chose in sentencepiece\n",
        "mlen_vocab = Vocab(itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7szhXI2Pw_q"
      },
      "source": [
        "tokenizer = Tokenizer(lang='mlen', tok_func=CodeMixedMalayalamTokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrxEDILWYg0-"
      },
      "source": [
        "tokenizer.pre_rules.append(lower_case_everything)\n",
        "tokenizer.pre_rules.append(handle_all_caps)\n",
        "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gt_DrjaPyyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b95dd86-a371-4645-b920-1f3efea42259"
      },
      "source": [
        "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['xxunk',\n",
              "  'xxpad',\n",
              "  'xxbos',\n",
              "  'xxeos',\n",
              "  'xxfld',\n",
              "  'xxmaj',\n",
              "  'xxup',\n",
              "  'xxrep',\n",
              "  'xxwrep'],\n",
              " [<function fastai.text.transform.fix_html>,\n",
              "  <function fastai.text.transform.replace_rep>,\n",
              "  <function fastai.text.transform.replace_wrep>,\n",
              "  <function fastai.text.transform.spec_add_spaces>,\n",
              "  <function fastai.text.transform.rm_useless_spaces>,\n",
              "  <function __main__.lower_case_everything>,\n",
              "  <function __main__.handle_all_caps>,\n",
              "  <function __main__.handle_upper_case_first_letter>],\n",
              " [<function fastai.text.transform.replace_all_caps>,\n",
              "  <function fastai.text.transform.deal_caps>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joo7nBUWVbsB"
      },
      "source": [
        "label_cols = ['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ii1J6H02fnHy",
        "outputId": "4cc4dd2d-a6ca-4eec-b613-079554c87230"
      },
      "source": [
        "df_test_pred=pd.read_csv('/content/mal_test_preds_2.csv',names=['query','predicted_label'],skiprows=1)\n",
        "df_test_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥á‡¥§‡µä‡¥∞‡µä‡¥®‡µç‡¥®‡µä‡¥∞‡¥æ ‡¥Æ‡µä‡¥§‡¥≤‡¥æ‡¥£‡¥≤‡µç‡¥≤‡µá  Suraj ‡¥Ü‡¥£‡µç ‡¥®‡¥ü‡µª ‡¥®‡µç...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡¥é‡¥®‡µç‡¥§‡µç ‡¥ä‡¥≥ ‡¥é‡¥°‡¥ø‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç ‡¥Ü‡¥ü‡µã ‡¥á‡¥§‡µç ‡¥í‡¥∞‡µÅ‡¥Æ‡¥æ‡¥§‡¥ø‡¥∞‡¥ø vivo vid...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡¥Ö‡¥Ü‡¥π‡¥æ.. ‡¥∏‡¥Ç‡¥ó‡µÄ‡¥§‡¥Ç ‡¥ú‡µÜ‡¥ï‡µç‚Äå‡¥∏‡µç ‡¥¨‡¥ø‡¥ú‡µã‡¥Ø‡µç ‡¥Ü‡¥£‡µç ‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥™‡µä‡¥ü‡µç‡¥ü‡¥≤‡µÅ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>‡¥à ‡¥™‡¥ü‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥µ‡µÜ‡¥Ø‡¥ø‡¥±‡µç‡¥±‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥® ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ï‡µç‡¥ï ‡¥´‡¥æ‡µª‡¥∏‡µÅ‡¥Ç</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>‡¥ï‡¥ü‡µç‡¥ü ‡¥≤‡¥æ‡¥≤‡µá‡¥ü‡µç‡¥ü‡µª ‡¥´‡¥æ‡µª‡¥∏‡µç ‡¥í‡¥∞‡µÅ ‡¥≤‡µà‡¥ï‡µç ‡¥§‡¥®‡µç‡¥®‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥™‡µã‡¥µ‡¥æ‡¥Æ‡µã ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2001 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  query                  predicted_label\n",
              "0     ‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥á‡¥§‡µä‡¥∞‡µä‡¥®‡µç‡¥®‡µä‡¥∞‡¥æ ‡¥Æ‡µä‡¥§‡¥≤‡¥æ‡¥£‡¥≤‡µç‡¥≤‡µá  Suraj ‡¥Ü‡¥£‡µç ‡¥®‡¥ü‡µª ‡¥®‡µç...                    Not_offensive\n",
              "1     ‡¥é‡¥®‡µç‡¥§‡µç ‡¥ä‡¥≥ ‡¥é‡¥°‡¥ø‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç ‡¥Ü‡¥ü‡µã ‡¥á‡¥§‡µç ‡¥í‡¥∞‡µÅ‡¥Æ‡¥æ‡¥§‡¥ø‡¥∞‡¥ø vivo vid...  Offensive_Targeted_Insult_Group\n",
              "2            Fefka ee padam release cheyyan samadhicho?                    Not_offensive\n",
              "3     ‡¥Ö‡¥Ü‡¥π‡¥æ.. ‡¥∏‡¥Ç‡¥ó‡µÄ‡¥§‡¥Ç ‡¥ú‡µÜ‡¥ï‡µç‚Äå‡¥∏‡µç ‡¥¨‡¥ø‡¥ú‡µã‡¥Ø‡µç ‡¥Ü‡¥£‡µç ‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥™‡µä‡¥ü‡µç‡¥ü‡¥≤‡µÅ...                    Not_offensive\n",
              "4     Ravile thane views likes ethra ayyi enn nokan ...                    Not_offensive\n",
              "...                                                 ...                              ...\n",
              "1996  Swargatthil ninnu purathaakkappetta daivatthin...                    Not_offensive\n",
              "1997  Ivide Palakkad Jayettan Fans club nnu ashamsak...                    Not_offensive\n",
              "1998      ‡¥à ‡¥™‡¥ü‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥µ‡µÜ‡¥Ø‡¥ø‡¥±‡µç‡¥±‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥® ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ï‡µç‡¥ï ‡¥´‡¥æ‡µª‡¥∏‡µÅ‡¥Ç                    Not_offensive\n",
              "1999  ‡¥ï‡¥ü‡µç‡¥ü ‡¥≤‡¥æ‡¥≤‡µá‡¥ü‡µç‡¥ü‡µª ‡¥´‡¥æ‡µª‡¥∏‡µç ‡¥í‡¥∞‡µÅ ‡¥≤‡µà‡¥ï‡µç ‡¥§‡¥®‡µç‡¥®‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥™‡µã‡¥µ‡¥æ‡¥Æ‡µã ...                    Not_offensive\n",
              "2000            Koora padam urappa kandal aryam.. Hello                    Not_offensive\n",
              "\n",
              "[2001 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pbR5zhEY675m",
        "outputId": "83b6bf5c-7de0-4837-f9c6-2b409474f105"
      },
      "source": [
        "df_test_pred['data']=df_test_pred['query']\n",
        "df_test_pred['label']=df_test_pred['predicted_label']\n",
        "\n",
        "mal_train_new = pd.concat([mal_train,df_test_pred])\n",
        "mal_train_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç. ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡¥à ‡¥ì‡¥£‡¥Ç ‡¥è‡¥ü‡µç‡¥ü‡¥®‡µÅ‡¥Ç ‡¥™‡¥ø‡¥≥‡µç‡¥≥‡µá‡µº‡¥ï‡µç‡¥ï‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥§‡¥æ‡¥£‡µç ‡¥é‡¥®‡µç‡¥®‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥µ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>26.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sushin syam  Shaiju khalid  Midhun manual</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J A K E S.   B EJ O Y !!!</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Swargatthil ninnu purathaakkappetta daivatthin...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ivide Palakkad Jayettan Fans club nnu ashamsak...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>‡¥à ‡¥™‡¥ü‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥µ‡µÜ‡¥Ø‡¥ø‡¥±‡µç‡¥±‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥® ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ï‡µç‡¥ï ‡¥´‡¥æ‡µª‡¥∏‡µÅ‡¥Ç</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>‡¥à ‡¥™‡¥ü‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥µ‡µÜ‡¥Ø‡¥ø‡¥±‡µç‡¥±‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥® ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ï‡µç‡¥ï ‡¥´‡¥æ‡µª‡¥∏‡µÅ‡¥Ç</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>‡¥ï‡¥ü‡µç‡¥ü ‡¥≤‡¥æ‡¥≤‡µá‡¥ü‡µç‡¥ü‡µª ‡¥´‡¥æ‡µª‡¥∏‡µç ‡¥í‡¥∞‡µÅ ‡¥≤‡µà‡¥ï‡µç ‡¥§‡¥®‡µç‡¥®‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥™‡µã‡¥µ‡¥æ‡¥Æ‡µã ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>‡¥ï‡¥ü‡µç‡¥ü ‡¥≤‡¥æ‡¥≤‡µá‡¥ü‡µç‡¥ü‡µª ‡¥´‡¥æ‡µª‡¥∏‡µç ‡¥í‡¥∞‡µÅ ‡¥≤‡µà‡¥ï‡µç ‡¥§‡¥®‡µç‡¥®‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥™‡µã‡¥µ‡¥æ‡¥Æ‡µã ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Koora padam urappa kandal aryam.. Hello</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13696 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  ... predicted_label\n",
              "0     ‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç. ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§...  ...             NaN\n",
              "1     ‡¥à ‡¥ì‡¥£‡¥Ç ‡¥è‡¥ü‡µç‡¥ü‡¥®‡µÅ‡¥Ç ‡¥™‡¥ø‡¥≥‡µç‡¥≥‡µá‡µº‡¥ï‡µç‡¥ï‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥§‡¥æ‡¥£‡µç ‡¥é‡¥®‡µç‡¥®‡µç ‡¥â‡¥≥‡µç‡¥≥‡¥µ...  ...             NaN\n",
              "2     ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç...  ...             NaN\n",
              "3             Sushin syam  Shaiju khalid  Midhun manual  ...             NaN\n",
              "4                             J A K E S.   B EJ O Y !!!  ...             NaN\n",
              "...                                                 ...  ...             ...\n",
              "1996  Swargatthil ninnu purathaakkappetta daivatthin...  ...   Not_offensive\n",
              "1997  Ivide Palakkad Jayettan Fans club nnu ashamsak...  ...   Not_offensive\n",
              "1998      ‡¥à ‡¥™‡¥ü‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‡¥µ‡µÜ‡¥Ø‡¥ø‡¥±‡µç‡¥±‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥® ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ï‡µç‡¥ï ‡¥´‡¥æ‡µª‡¥∏‡µÅ‡¥Ç  ...   Not_offensive\n",
              "1999  ‡¥ï‡¥ü‡µç‡¥ü ‡¥≤‡¥æ‡¥≤‡µá‡¥ü‡µç‡¥ü‡µª ‡¥´‡¥æ‡µª‡¥∏‡µç ‡¥í‡¥∞‡µÅ ‡¥≤‡µà‡¥ï‡µç ‡¥§‡¥®‡µç‡¥®‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥™‡µã‡¥µ‡¥æ‡¥Æ‡µã ...  ...   Not_offensive\n",
              "2000            Koora padam urappa kandal aryam.. Hello  ...   Not_offensive\n",
              "\n",
              "[13696 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX-aZDS4TkwA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(mal_train_new['data'],mal_train_new['label'], test_size = 0.2, random_state = 42, stratify=mal_train_new['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM6aCgOjYlip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47d25f7-1837-4ae1-dfcb-305b2a73c738"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "813      Oh enthoot kidu trailer laletta.. kidu mass!!!...\n",
              "3746                      ‡¥á‡µó ‡¥™‡¥ü‡¥Ç ‡¥™‡µä‡¥≥‡¥ø‡¥Ø‡µÅ‡¥Ç ‡¥é‡¥®‡µç‡¥®‡¥§‡µç ‡¥â‡¥±‡¥™‡µç‡¥™‡µç ‡¥Ü‡¥Ø‡¥ø\n",
              "7418     Mamangam Trailer poli aarnnu pakshe padam  Big...\n",
              "3817     Shah Rukh Khan inte FAN cinema de cheriya samy...\n",
              "7085                      Urumi   scene repeat  mode    on\n",
              "                               ...                        \n",
              "3869     Ejjaathi hardwork mammookka!!! Katta waiting p...\n",
              "981      Trailer cuts the great editor Donmax ‡¥ö‡µÅ‡¥Æ‡µç‡¥Æ‡¥æ‡¥§‡¥≤‡µç...\n",
              "12793    ‡¥á‡¥ï‡µç‡¥ï‡¥Ø‡¥æ‡¥£‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥é‡¥≤‡µç‡¥≤‡¥æ ‡¥≠‡¥æ‡¥∑‡¥Ø‡µÅ‡¥Ç ‡¥∂‡µà‡¥≤‡¥ø‡¥ï‡¥≥‡µÅ‡¥Ç ‡¥®‡¥®‡µç‡¥®‡¥æ‡¥Ø‡¥ø ‡¥™‡¥±...\n",
              "7578                  8 hour kazhinjittum 1M polum aayilla\n",
              "8230     ‡¥∑‡µà‡¥≤‡µã‡¥ï‡µç‡¥ï‡µç.. big ‡¥¨‡µç‡¥∞‡¥¶‡µº ‡¥ï‡¥æ‡¥£‡¥æ‡¥Ç ‡¥™‡µÇ‡¥∞‡¥Ç.. ‡¥á‡¥®‡µç‡¥®‡¥≤‡µÜ ‡¥∑‡µà‡¥≤‡µã‡¥ï...\n",
              "Name: data, Length: 10956, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhAHlcX9WrFk"
      },
      "source": [
        "X_train_df = pd.concat([X_train, y_train], axis=1, keys=['text', 'label'])\n",
        "X_val_df = pd.concat([X_val, y_val], axis=1, keys=['text', 'label'])\n",
        "X_test_df = pd.concat([mal_dev['data'], mal_dev['label']], axis=1, keys=['text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zLWWpv0bHq8"
      },
      "source": [
        "# X_train_df['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLD_rdsOP0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d3d4f3c5-18fa-4a7e-a563-02e213c2e8b4"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=mlen_vocab,text_cols='text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL-r5q3FUCDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4ea50f0c-6609-41bd-d976-ddfb43813ff1"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk ‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï ‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅx x bo s ‚ñÅdha an de . . . ki da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>‡¥Æ‡µç‡¥™‡¥ø ‡¥® ‡µá‡¥∑‡µª ‚ñÅ‡¥™‡¥ü ‡¥Ç ‚ñÅ‡¥™‡µä ‡¥≥‡¥ø ‡¥ï‡µç‡¥ï‡µÅ‡¥Ç ‚ñÅ‡¥é‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥Ö‡¥≠‡¥ø‡¥™‡µç‡¥∞‡¥æ‡¥Ø‡¥Ç ‚ñÅ‡¥â‡¥≥‡µç‡¥≥ ‡¥µ‡µº ‚ñÅ‡¥í‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥≤‡µà ‡¥ï‡µç‡¥ï‡µç ‚ñÅ‡¥Ö‡¥ü‡¥ø‡¥ö‡µç‡¥ö ‡µá . . ‚ñÅx x bo s ‚ñÅ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‚ñÅ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‚ñÅ‡¥ï‡¥æ‡¥£‡¥æ‡µª ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥® ‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‚ñÅ‡¥Æ‡¥æ‡¥§‡µç‡¥∞ ‡¥Æ ‡¥æ‡¥£‡µã . xxunk ‚ñÅx x bo s ‚ñÅmam mo kka ‚ñÅage ‚ñÅ68 ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ. ‚ñÅno ‚ñÅwords ‚ñÅx x bo s ‚ñÅspo ile r ‚ñÅa ler t ‚ñÅ xxunk ‚ñÅodi yan ‚ñÅis ‚ñÅnot ‚ñÅmohanlal . ‚ñÅmani k yan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>kan ‚ñÅratri ‚ñÅ2 mani k ‚ñÅala ram ve chen itu ‚ñÅraja da ‚ñÅpillar u ‚ñÅ‡¥ü‡µç‡¥∞‡¥ø ‡¥™‡µç‡¥™‡¥ø ‡µæ ‚ñÅstrong anu ‚ñÅthe li yi kum ‚ñÅwait ‚ñÅx x bo s ‚ñÅi tha a anu ‚ñÅ nnu mma ‚ñÅpara nja ‚ñÅsha oli n ‚ñÅtemple ‚ñÅa tha va ‚ñÅshashi ‚ñÅanna nte ‚ñÅkotta ram ‚ñÅx x bo s ‚ñÅtrai ler il ‚ñÅjoseph ‚ñÅx x bo s ‚ñÅtea s er ‚ñÅ er angi ‚ñÅela ‚ñÅx x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>‚ñÅ‡¥∏‡µç‡¥µ‡¥æ ‡¥∏‡¥ø ‡¥ï ‚ñÅ‡¥ï‡µÅ‡¥ü‡µç‡¥ü‡¥ø ‡¥ï‡µç‡¥ï‡µç ‚ñÅ‡¥é‡¥≤‡µç‡¥≤‡¥æ ‚ñÅ‡¥µ‡¥ø‡¥ß ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥µ‡µÅ‡¥Ç ‚ñÅ‡¥â‡¥£‡µç‡¥ü‡¥æ‡¥ï ‡¥ü‡µç‡¥ü‡µÜ ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ. ‚ñÅx x bo s ‚ñÅ‡¥á‡¥µ ‡¥ø‡¥ü ‡¥æ ‡¥∞‡µÅ‡¥Ç ‚ñÅ‡¥™‡¥±‡¥Ø ‡¥æ‡¥§‡µÜ ‚ñÅ‡¥™‡µã‡¥Ø ‚ñÅ‡¥™‡µá‡¥∞‡µÅ ‚ñÅx x bo s ‚ñÅ‡¥™‡µÇ ‡¥Æ‡¥∞ ‡¥§‡µç‡¥§‡¥ø‡¥®‡µç ‚ñÅ‡¥µ‡¥®‡µç‡¥® ‚ñÅ‡¥Ö‡¥µ‡¥∏‡µç‡¥• ‚ñÅ‡¥µ‡¥∞‡µÅ‡¥§‡µç‡¥§ ‡¥∞‡µÅ‡¥§‡µç . . . ‚ñÅ‡¥é ‡¥¨‡µç‡¥∞‡¥ø ‡¥°‡µç ‚ñÅ‡¥∑ ‡µÜ‡¥Ø‡¥ø‡µª ‚ñÅ‡¥®‡¥ø‡¥≤‡¥µ‡¥ø‡µΩ ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥é‡¥£‡µç‡¥£‡¥Ç ‚ñÅ‡¥™‡¥±‡¥û‡µç‡¥û ‚ñÅ‡¥∏‡¥Ç‡¥µ‡¥ø‡¥ß‡¥æ‡¥Ø‡¥ï‡¥® ‡¥æ‡¥£‡µç . . . ‚ñÅx x bo s ‚ñÅ2 : 05 ‚ñÅdi le e p ‚ñÅde ‚ñÅani yan ‚ñÅparanjat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>‚ñÅ... ‚ñÅvara mpo ‚ñÅkaa nam ‚ñÅen gana ‚ñÅnu ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ. ‚ñÅx x bo s ‚ñÅnama da ‚ñÅmodel ‚ñÅschool ‚ñÅ. ‚ñÅmodel ‚ñÅschool i ‚ñÅpa di che ‚ñÅpill ero kke ‚ñÅe v de da . . ‚ñÅx x bo s ‚ñÅtrai ler ‚ñÅi ' ll ‚ñÅtan na ay y ‚ñÅfull ‚ñÅstory ‚ñÅu on du ‚ñÅx x bo s ‚ñÅen thu ‚ñÅo ola ‚ñÅtrai ler ‚ñÅmam mat ty ‚ñÅloka th ol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8C3WPbQUC66"
      },
      "source": [
        "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eeINS4pZeM-"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/AggressionNLP/code-mixed-enma/lm_mixed_script/models.zip' -d '/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/lm_mixed_script/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0naev5MFeko0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b267887-e163-4180-a18d-eb6fe2709b75"
      },
      "source": [
        "# Loading the pretrained language model on malyalam wikipedia\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/lm_mixed_script/models/best_model', with_opt=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅkerala ‚ñÅa chay an ‚ñÅfan s ‚ñÅhit ‚ñÅlike,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅdon ma x ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥Ø‡¥æ‡¥£ ‡µã ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡µá xxunk ‡¥Æ‡µã ‡¥∂‡¥Ç . ‡¥ï‡µã ‡¥™‡µç‡¥™‡¥ø ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü‡¥æ ‚ñÅmass ‚ñÅ‡¥∏‡µÜ ‡¥ï‡µç‡¥∑ ‡¥®‡µç ‚ñÅ‡¥ï‡µä‡¥ü‡µÅ‡¥§‡µç‡¥§ ‚ñÅ‡¥¨‡¥ø ‡¥ú‡¥ø ‡¥é‡¥Ç ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥¨‡µã ‡¥± ‡¥Ø‡µç‡¥ï‡µç‡¥ï ‡¥ø ‡¥£ ‡¥≤‡µç‡¥≤‡µã . ‡¥Æ‡µä‡¥§‡µç‡¥§ ‡¥§‡µç‡¥§‡¥ø‡µΩ ‚ñÅ‡¥≤‡µã ‚ñÅ‡¥ï‡µç‡¥µ‡¥æ ‡¥≥‡¥ø ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥´‡µÄ ‡µΩ .,‚ñÅx x bo s ‚ñÅodi yanu ‚ñÅmun me yulla ‚ñÅla le ttane ‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk,‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï,‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅsan chit ‚ñÅbu l hara ‚ñÅb g m ‚ñÅnte ‚ñÅponn o ‚ñÅno ‚ñÅraksha,‚ñÅx x bo s ‚ñÅni vin ‚ñÅ‡¥á ‡¥ö‡µç‡¥ö ‡¥æ‡¥Ø ‡µª ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥§‡¥ï‡µº‡¥ï‡µç‡¥ï ‡µÅ‡¥Ç . . . ‚ñÅ‡¥Ü ‡¥∏‡¥ø ‡¥´ ‡¥≤‡¥ø ‚ñÅ‡¥´‡¥æ ‡µª ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥æ ‡¥∂‡¥Ç ‡¥∏ ‡¥ï‡µæ,‚ñÅx x bo s ‚ñÅ‡¥Ü ‡¥∞‡µã ‚ñÅ‡¥í‡¥∞‡¥æ‡µæ ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅ‡¥é‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü ‡µª ‚ñÅmy ‚ñÅbig ‚ñÅbrother,‚ñÅx x bo s ‚ñÅsuper ‚ñÅfi li m ‚ñÅthan k s ‚ñÅraj u ve tta ‚ñÅla le ttan ‚ñÅtha kar thu,‚ñÅx x bo s ‚ñÅp k ‚ñÅram das . . . ‚ñÅnamm u de ‚ñÅraj e ttan ‚ñÅa anennu ‚ñÅ nj n ‚ñÅpara jal ‚ñÅni ga lu de ‚ñÅabhiprayam . . . ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅgopi che tta nte ‚ñÅb g m ‚ñÅ um ‚ñÅmam mo o kayu m ‚ñÅishta pedunn avar ‚ñÅlike ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥™‡µÜ‡¥£‡µç‡¥£ ‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü ‡¥£‡µã ‚ñÅdirect ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅpoli chu ‚ñÅni vin,‚ñÅx x bo s ‚ñÅ‡¥™‡µÉ‡¥•‡µç‡¥µ‡¥ø ‡¥∞‡¥æ‡¥ú‡µç ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡µª ‚ñÅ‡¥≤‡¥æ ‡¥≤‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥≤ ‡¥ï‡µç‡¥∏‡µç . . ‚ñÅlal ‚ñÅj r . ‚ñÅ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥µ‡µÜ ‡¥±‡µà ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥™‡µç‡¥∞‡¥§‡µÄ‡¥ï‡µç‡¥∑‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥®‡µç‡¥®‡µÅ . . ‚ñÅbest ‚ñÅwi shes ‚ñÅteam,‚ñÅx x bo s ‚ñÅ‡¥™‡µã‡¥ï ‡¥∞‡µÅ‡¥§‡µç ‚ñÅ‡¥Æ‡¥ï‡µç‡¥ï‡¥≥ ‡µÜ ‚ñÅ‡¥™‡µã ‡¥ï‡µç‡¥ï ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅ‡¥® ‡µª ‚ñÅ‡¥ï‡¥£‡µç‡¥ü‡µç ‚ñÅ‡¥é ‡¥®‡µç‡¥±‡µç ‡¥Ø‡µÜ ‚ñÅ‡¥Ö‡¥Æ‡µç‡¥Æ ‡µã ‚ñÅ‡¥™‡µã‡¥≥‡¥ø ‡¥Ø ‚ñÅ‡¥Æ‡¥±‡¥ï‡µç‡¥ï ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ‡¥í‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥≤‡µÅ‡¥Ç,‚ñÅx x bo s ‚ñÅa van ‚ñÅvaru m ‚ñÅente ‚ñÅ makan ‚ñÅmadhura ‚ñÅraja ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(25000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅkerala ‚ñÅa chay an ‚ñÅfan s ‚ñÅhit ‚ñÅlike,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅdon ma x ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥Ø‡¥æ‡¥£ ‡µã ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡µá xxunk ‡¥Æ‡µã ‡¥∂‡¥Ç . ‡¥ï‡µã ‡¥™‡µç‡¥™‡¥ø ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü‡¥æ ‚ñÅmass ‚ñÅ‡¥∏‡µÜ ‡¥ï‡µç‡¥∑ ‡¥®‡µç ‚ñÅ‡¥ï‡µä‡¥ü‡µÅ‡¥§‡µç‡¥§ ‚ñÅ‡¥¨‡¥ø ‡¥ú‡¥ø ‡¥é‡¥Ç ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥¨‡µã ‡¥± ‡¥Ø‡µç‡¥ï‡µç‡¥ï ‡¥ø ‡¥£ ‡¥≤‡µç‡¥≤‡µã . ‡¥Æ‡µä‡¥§‡µç‡¥§ ‡¥§‡µç‡¥§‡¥ø‡µΩ ‚ñÅ‡¥≤‡µã ‚ñÅ‡¥ï‡µç‡¥µ‡¥æ ‡¥≥‡¥ø ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥´‡µÄ ‡µΩ .,‚ñÅx x bo s ‚ñÅodi yanu ‚ñÅmun me yulla ‚ñÅla le ttane ‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk,‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï,‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅsan chit ‚ñÅbu l hara ‚ñÅb g m ‚ñÅnte ‚ñÅponn o ‚ñÅno ‚ñÅraksha,‚ñÅx x bo s ‚ñÅni vin ‚ñÅ‡¥á ‡¥ö‡µç‡¥ö ‡¥æ‡¥Ø ‡µª ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥§‡¥ï‡µº‡¥ï‡µç‡¥ï ‡µÅ‡¥Ç . . . ‚ñÅ‡¥Ü ‡¥∏‡¥ø ‡¥´ ‡¥≤‡¥ø ‚ñÅ‡¥´‡¥æ ‡µª ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥æ ‡¥∂‡¥Ç ‡¥∏ ‡¥ï‡µæ,‚ñÅx x bo s ‚ñÅ‡¥Ü ‡¥∞‡µã ‚ñÅ‡¥í‡¥∞‡¥æ‡µæ ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅ‡¥é‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü ‡µª ‚ñÅmy ‚ñÅbig ‚ñÅbrother,‚ñÅx x bo s ‚ñÅsuper ‚ñÅfi li m ‚ñÅthan k s ‚ñÅraj u ve tta ‚ñÅla le ttan ‚ñÅtha kar thu,‚ñÅx x bo s ‚ñÅp k ‚ñÅram das . . . ‚ñÅnamm u de ‚ñÅraj e ttan ‚ñÅa anennu ‚ñÅ nj n ‚ñÅpara jal ‚ñÅni ga lu de ‚ñÅabhiprayam . . . ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅgopi che tta nte ‚ñÅb g m ‚ñÅ um ‚ñÅmam mo o kayu m ‚ñÅishta pedunn avar ‚ñÅlike ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥™‡µÜ‡¥£‡µç‡¥£ ‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü ‡¥£‡µã ‚ñÅdirect ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅpoli chu ‚ñÅni vin,‚ñÅx x bo s ‚ñÅ‡¥™‡µÉ‡¥•‡µç‡¥µ‡¥ø ‡¥∞‡¥æ‡¥ú‡µç ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡µª ‚ñÅ‡¥≤‡¥æ ‡¥≤‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥≤ ‡¥ï‡µç‡¥∏‡µç . . ‚ñÅlal ‚ñÅj r . ‚ñÅ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥µ‡µÜ ‡¥±‡µà ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥™‡µç‡¥∞‡¥§‡µÄ‡¥ï‡µç‡¥∑‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥®‡µç‡¥®‡µÅ . . ‚ñÅbest ‚ñÅwi shes ‚ñÅteam,‚ñÅx x bo s ‚ñÅ‡¥™‡µã‡¥ï ‡¥∞‡µÅ‡¥§‡µç ‚ñÅ‡¥Æ‡¥ï‡µç‡¥ï‡¥≥ ‡µÜ ‚ñÅ‡¥™‡µã ‡¥ï‡µç‡¥ï ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅ‡¥® ‡µª ‚ñÅ‡¥ï‡¥£‡µç‡¥ü‡µç ‚ñÅ‡¥é ‡¥®‡µç‡¥±‡µç ‡¥Ø‡µÜ ‚ñÅ‡¥Ö‡¥Æ‡µç‡¥Æ ‡µã ‚ñÅ‡¥™‡µã‡¥≥‡¥ø ‡¥Ø ‚ñÅ‡¥Æ‡¥±‡¥ï‡µç‡¥ï ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ‡¥í‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥≤‡µÅ‡¥Ç,‚ñÅx x bo s ‚ñÅa van ‚ñÅvaru m ‚ñÅente ‚ñÅ makan ‚ñÅmadhura ‚ñÅraja ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(25000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pvdMXwlescX"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kQrKz10is_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "bd45282d-1916-41bf-9663-1af304dab54a"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.102862</td>\n",
              "      <td>4.716438</td>\n",
              "      <td>0.282994</td>\n",
              "      <td>00:19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bjJuFjtivsC"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV8vHBjcl20u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6ed27cbd-c30f-4ac8-b3c8-32ac9704ffee"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.483469</td>\n",
              "      <td>4.477559</td>\n",
              "      <td>0.304381</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.240146</td>\n",
              "      <td>4.222130</td>\n",
              "      <td>0.335170</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.002192</td>\n",
              "      <td>4.105987</td>\n",
              "      <td>0.349386</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.842096</td>\n",
              "      <td>4.064297</td>\n",
              "      <td>0.354381</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.759367</td>\n",
              "      <td>4.058205</td>\n",
              "      <td>0.355148</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUy7fUd2l4X2"
      },
      "source": [
        "learn.save_encoder('mal_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "spDwPlkjAy4n",
        "outputId": "77f6485c-dab0-4137-ff2c-fed2463011ea"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=mlen_vocab,text_cols=['text'], label_cols=['label'], bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "T9gumaBdBswk",
        "outputId": "b024f15c-1991-4c71-9c76-835cd9e82fa8"
      },
      "source": [
        "data_clas.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman ju ‚ñÅwar ri er ‚ñÅman</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅ‡¥û‡¥æ‡µª ‚ñÅ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‚ñÅ‡¥§‡µã‡¥®‡µç‡¥®‡¥ø‡¥Ø ‚ñÅ‡¥ï‡¥æ‡¥∞‡µç‡¥Ø‡¥Ç ‚ñÅ‡¥™‡¥±‡¥û‡µç‡¥û ‡µã‡¥ü‡µç‡¥ü ‡µÜ . . ‚ñÅ‡¥ï‡µä‡¥≤‡µç‡¥≤ ‡¥∞‡µÅ‡¥§‡µç . ‚ñÅ‡¥û‡¥æ‡µª ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥ï‡¥ü‡µç‡¥ü ‚ñÅ‡¥®‡¥ø ‡¥µ‡¥ø‡µª ‚ñÅ‡¥´‡¥æ ‡µª ‚ñÅ‡¥Ü‡¥£‡µç . . f rom ‚ñÅhis ‚ñÅvery ‚ñÅfirst ‚ñÅmovie . ‚ñÅ‡¥Æ‡µÇ‡¥§‡µç‡¥§ ‡µã ‡µª ‚ñÅ ‡¥µ‡¥∞‡¥æ‡µª ‚ñÅ‡¥ï‡¥æ ‡¥§‡µç‡¥§‡µÅ ‚ñÅ‡¥ï‡¥æ ‡¥§‡µç‡¥§‡µç ‚ñÅ‡¥á‡¥∞‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥µ‡¥∞‡µÅ‡¥®‡µç‡¥®‡µÅ ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ. ‚ñÅ‡¥™‡¥ï‡µç‡¥∑‡µÜ ‚ñÅtrai ler ‚ñÅ‡¥é‡¥®‡µç‡¥® ‡µÜ ‚ñÅ‡¥®‡¥ø‡¥∞‡¥æ‡¥∂ ‡¥™‡µç‡¥™‡µÜ‡¥ü‡µÅ‡¥§‡µç‡¥§‡¥ø . ‚ñÅ‡¥®‡¥ø ‡¥µ‡¥ø‡µª ‚ñÅ ‡µΩ ‚ñÅ‡¥®‡¥ø‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥™‡µÅ‡¥§‡¥ø‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ü ‡¥Ø‡µÅ‡¥Ç ‚ñÅ‡¥µ‡µç‡¥Ø‡¥§‡µç‡¥Ø‡¥∏‡µç‡¥§ ‡¥Ç ‚ñÅ‡¥Ü ‡¥Ø‡µÅ‡¥Ç ‚ñÅ‡¥Ø‡¥æ‡¥§‡µä‡¥∞‡µÅ</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅpriya pe tta ‚ñÅji bi ‚ñÅand ‚ñÅjo ju ‚ñÅivi de ‚ñÅkure ‚ñÅpala than tha kku pi ran na ‚ñÅkure ‚ñÅla le ttan ‚ñÅha ter s ‚ñÅe ‚ñÅnall a ‚ñÅcinema ye ‚ñÅde grade ‚ñÅcheyya n ‚ñÅshram ikkunn und ‚ñÅpakshe ‚ñÅenik ku ra ppan u ‚ñÅni ng alu de ‚ñÅe ‚ñÅkanni ‚ñÅcinema ye ‚ñÅmalayali pre k sha kar ‚ñÅiru ‚ñÅkay yu m ‚ñÅne e tti ‚ñÅswe e kari</td>\n",
              "      <td>Offensive_Untargetede</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅi th inte ‚ñÅpinni l ‚ñÅpre var thi cha ‚ñÅella r kku m ‚ñÅor ayi ram ‚ñÅaa sham sa kal ‚ñÅoppam ‚ñÅe e ‚ñÅna ttile ‚ñÅniyama ‚ñÅv ye va stha ye ‚ñÅe du thu ‚ñÅkani kkan ‚ñÅchan ku ttam ‚ñÅkanich a thil ‚ñÅhands ‚ñÅoff ‚ñÅ... e e ‚ñÅfilm ‚ñÅkanda thu kondu ‚ñÅa thu ‚ñÅonnu m ‚ñÅmaran ‚ñÅpokunn illa ‚ñÅ. . bu t ‚ñÅit ho kke ‚ñÅkand</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅi thu ‚ñÅpo l oru ‚ñÅmovie ‚ñÅmalaya la thil ‚ñÅkaa nan ‚ñÅoru pa a du ‚ñÅa grahi chi ru nu ‚ñÅpaksha e ‚ñÅa e no kae ‚ñÅdifferent ‚ñÅkondu van itund o ‚ñÅapo z ho kae ‚ñÅmalayali ‚ñÅthat ima ati y itund u ‚ñÅi thu ‚ñÅa thu ‚ñÅpo la ava thiri kata e ‚ñÅnew ‚ñÅ gen ‚ñÅmovie karu m ‚ñÅyouth um ‚ñÅku ng fu ya e ‚ñÅishta</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZVeJ512C7pL"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s449VQJSC9iJ",
        "outputId": "78dd02a5-ab1f-44b6-850a-6ee094ad96dd"
      },
      "source": [
        "learn.load_encoder('mal_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅkerala ‚ñÅa chay an ‚ñÅfan s ‚ñÅhit ‚ñÅlike,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅdon ma x ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥Ø‡¥æ‡¥£ ‡µã ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡µá xxunk ‡¥Æ‡µã ‡¥∂‡¥Ç . ‡¥ï‡µã ‡¥™‡µç‡¥™‡¥ø ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü‡¥æ ‚ñÅmass ‚ñÅ‡¥∏‡µÜ ‡¥ï‡µç‡¥∑ ‡¥®‡µç ‚ñÅ‡¥ï‡µä‡¥ü‡µÅ‡¥§‡µç‡¥§ ‚ñÅ‡¥¨‡¥ø ‡¥ú‡¥ø ‡¥é‡¥Ç ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥¨‡µã ‡¥± ‡¥Ø‡µç‡¥ï‡µç‡¥ï ‡¥ø ‡¥£ ‡¥≤‡µç‡¥≤‡µã . ‡¥Æ‡µä‡¥§‡µç‡¥§ ‡¥§‡µç‡¥§‡¥ø‡µΩ ‚ñÅ‡¥≤‡µã ‚ñÅ‡¥ï‡µç‡¥µ‡¥æ ‡¥≥‡¥ø ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥´‡µÄ ‡µΩ .,‚ñÅx x bo s ‚ñÅodi yanu ‚ñÅmun me yulla ‚ñÅla le ttane ‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk,‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï,‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅsan chit ‚ñÅbu l hara ‚ñÅb g m ‚ñÅnte ‚ñÅponn o ‚ñÅno ‚ñÅraksha,‚ñÅx x bo s ‚ñÅni vin ‚ñÅ‡¥á ‡¥ö‡µç‡¥ö ‡¥æ‡¥Ø ‡µª ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥§‡¥ï‡µº‡¥ï‡µç‡¥ï ‡µÅ‡¥Ç . . . ‚ñÅ‡¥Ü ‡¥∏‡¥ø ‡¥´ ‡¥≤‡¥ø ‚ñÅ‡¥´‡¥æ ‡µª ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥æ ‡¥∂‡¥Ç ‡¥∏ ‡¥ï‡µæ,‚ñÅx x bo s ‚ñÅ‡¥Ü ‡¥∞‡µã ‚ñÅ‡¥í‡¥∞‡¥æ‡µæ ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅ‡¥é‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü ‡µª ‚ñÅmy ‚ñÅbig ‚ñÅbrother,‚ñÅx x bo s ‚ñÅsuper ‚ñÅfi li m ‚ñÅthan k s ‚ñÅraj u ve tta ‚ñÅla le ttan ‚ñÅtha kar thu,‚ñÅx x bo s ‚ñÅp k ‚ñÅram das . . . ‚ñÅnamm u de ‚ñÅraj e ttan ‚ñÅa anennu ‚ñÅ nj n ‚ñÅpara jal ‚ñÅni ga lu de ‚ñÅabhiprayam . . . ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅgopi che tta nte ‚ñÅb g m ‚ñÅ um ‚ñÅmam mo o kayu m ‚ñÅishta pedunn avar ‚ñÅlike ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥™‡µÜ‡¥£‡µç‡¥£ ‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü ‡¥£‡µã ‚ñÅdirect ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅpoli chu ‚ñÅni vin,‚ñÅx x bo s ‚ñÅ‡¥™‡µÉ‡¥•‡µç‡¥µ‡¥ø ‡¥∞‡¥æ‡¥ú‡µç ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡µª ‚ñÅ‡¥≤‡¥æ ‡¥≤‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥≤ ‡¥ï‡µç‡¥∏‡µç . . ‚ñÅlal ‚ñÅj r . ‚ñÅ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥µ‡µÜ ‡¥±‡µà ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥™‡µç‡¥∞‡¥§‡µÄ‡¥ï‡µç‡¥∑‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥®‡µç‡¥®‡µÅ . . ‚ñÅbest ‚ñÅwi shes ‚ñÅteam,‚ñÅx x bo s ‚ñÅ‡¥™‡µã‡¥ï ‡¥∞‡µÅ‡¥§‡µç ‚ñÅ‡¥Æ‡¥ï‡µç‡¥ï‡¥≥ ‡µÜ ‚ñÅ‡¥™‡µã ‡¥ï‡µç‡¥ï ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅ‡¥® ‡µª ‚ñÅ‡¥ï‡¥£‡µç‡¥ü‡µç ‚ñÅ‡¥é ‡¥®‡µç‡¥±‡µç ‡¥Ø‡µÜ ‚ñÅ‡¥Ö‡¥Æ‡µç‡¥Æ ‡µã ‚ñÅ‡¥™‡µã‡¥≥‡¥ø ‡¥Ø ‚ñÅ‡¥Æ‡¥±‡¥ï‡µç‡¥ï ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ‡¥í‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥≤‡µÅ‡¥Ç,‚ñÅx x bo s ‚ñÅa van ‚ñÅvaru m ‚ñÅente ‚ñÅ makan ‚ñÅmadhura ‚ñÅraja ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅkerala ‚ñÅa chay an ‚ñÅfan s ‚ñÅhit ‚ñÅlike,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅdon ma x ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥Ø‡¥æ‡¥£ ‡µã ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡µá xxunk ‡¥Æ‡µã ‡¥∂‡¥Ç . ‡¥ï‡µã ‡¥™‡µç‡¥™‡¥ø ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü‡¥æ ‚ñÅmass ‚ñÅ‡¥∏‡µÜ ‡¥ï‡µç‡¥∑ ‡¥®‡µç ‚ñÅ‡¥ï‡µä‡¥ü‡µÅ‡¥§‡µç‡¥§ ‚ñÅ‡¥¨‡¥ø ‡¥ú‡¥ø ‡¥é‡¥Ç ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥¨‡µã ‡¥± ‡¥Ø‡µç‡¥ï‡µç‡¥ï ‡¥ø ‡¥£ ‡¥≤‡µç‡¥≤‡µã . ‡¥Æ‡µä‡¥§‡µç‡¥§ ‡¥§‡µç‡¥§‡¥ø‡µΩ ‚ñÅ‡¥≤‡µã ‚ñÅ‡¥ï‡µç‡¥µ‡¥æ ‡¥≥‡¥ø ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥´‡µÄ ‡µΩ .,‚ñÅx x bo s ‚ñÅodi yanu ‚ñÅmun me yulla ‚ñÅla le ttane ‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk,‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï,‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅsan chit ‚ñÅbu l hara ‚ñÅb g m ‚ñÅnte ‚ñÅponn o ‚ñÅno ‚ñÅraksha,‚ñÅx x bo s ‚ñÅni vin ‚ñÅ‡¥á ‡¥ö‡µç‡¥ö ‡¥æ‡¥Ø ‡µª ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥§‡¥ï‡µº‡¥ï‡µç‡¥ï ‡µÅ‡¥Ç . . . ‚ñÅ‡¥Ü ‡¥∏‡¥ø ‡¥´ ‡¥≤‡¥ø ‚ñÅ‡¥´‡¥æ ‡µª ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥æ ‡¥∂‡¥Ç ‡¥∏ ‡¥ï‡µæ,‚ñÅx x bo s ‚ñÅ‡¥Ü ‡¥∞‡µã ‚ñÅ‡¥í‡¥∞‡¥æ‡µæ ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅ‡¥é‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü ‡µª ‚ñÅmy ‚ñÅbig ‚ñÅbrother,‚ñÅx x bo s ‚ñÅsuper ‚ñÅfi li m ‚ñÅthan k s ‚ñÅraj u ve tta ‚ñÅla le ttan ‚ñÅtha kar thu,‚ñÅx x bo s ‚ñÅp k ‚ñÅram das . . . ‚ñÅnamm u de ‚ñÅraj e ttan ‚ñÅa anennu ‚ñÅ nj n ‚ñÅpara jal ‚ñÅni ga lu de ‚ñÅabhiprayam . . . ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅgopi che tta nte ‚ñÅb g m ‚ñÅ um ‚ñÅmam mo o kayu m ‚ñÅishta pedunn avar ‚ñÅlike ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥™‡µÜ‡¥£‡µç‡¥£ ‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü ‡¥£‡µã ‚ñÅdirect ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅpoli chu ‚ñÅni vin,‚ñÅx x bo s ‚ñÅ‡¥™‡µÉ‡¥•‡µç‡¥µ‡¥ø ‡¥∞‡¥æ‡¥ú‡µç ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡µª ‚ñÅ‡¥≤‡¥æ ‡¥≤‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥≤ ‡¥ï‡µç‡¥∏‡µç . . ‚ñÅlal ‚ñÅj r . ‚ñÅ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥µ‡µÜ ‡¥±‡µà ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥™‡µç‡¥∞‡¥§‡µÄ‡¥ï‡µç‡¥∑‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥®‡µç‡¥®‡µÅ . . ‚ñÅbest ‚ñÅwi shes ‚ñÅteam,‚ñÅx x bo s ‚ñÅ‡¥™‡µã‡¥ï ‡¥∞‡µÅ‡¥§‡µç ‚ñÅ‡¥Æ‡¥ï‡µç‡¥ï‡¥≥ ‡µÜ ‚ñÅ‡¥™‡µã ‡¥ï‡µç‡¥ï ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅ‡¥® ‡µª ‚ñÅ‡¥ï‡¥£‡µç‡¥ü‡µç ‚ñÅ‡¥é ‡¥®‡µç‡¥±‡µç ‡¥Ø‡µÜ ‚ñÅ‡¥Ö‡¥Æ‡µç‡¥Æ ‡µã ‚ñÅ‡¥™‡µã‡¥≥‡¥ø ‡¥Ø ‚ñÅ‡¥Æ‡¥±‡¥ï‡µç‡¥ï ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ‡¥í‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥≤‡µÅ‡¥Ç,‚ñÅx x bo s ‚ñÅa van ‚ñÅvaru m ‚ñÅente ‚ñÅ makan ‚ñÅmadhura ‚ñÅraja ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKXiJqKVC_fe"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLRLHFh9DC6Y",
        "outputId": "df9ee1d3-c56d-491f-90bb-16576540d82f"
      },
      "source": [
        "learn.loss_func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FlattenedLoss of CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5xMmyOJDEFa"
      },
      "source": [
        "mcc = MatthewsCorreff()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6IWLlk7DFnV"
      },
      "source": [
        "learn.metrics = [mcc, accuracy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "43WhXBD1DHZk",
        "outputId": "8d6c8ced-3093-458d-c6ad-c1d5d3dd05bc"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.313689</td>\n",
              "      <td>0.255555</td>\n",
              "      <td>0.592873</td>\n",
              "      <td>0.927372</td>\n",
              "      <td>00:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "6CbfdYCpDIzN",
        "outputId": "2b1f269c-7b14-4f64-88ec-c5e82f6c6637"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.283254</td>\n",
              "      <td>0.246908</td>\n",
              "      <td>0.639773</td>\n",
              "      <td>0.932847</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k2FwrhYDLu-"
      },
      "source": [
        "learn.save('mal_en-second-full')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "yYlODMJVDNE-",
        "outputId": "5e5925c6-37b0-4818-8a64-692b4462406d"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='mal_en_final')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.196340</td>\n",
              "      <td>0.233245</td>\n",
              "      <td>0.634739</td>\n",
              "      <td>0.932482</td>\n",
              "      <td>01:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.204046</td>\n",
              "      <td>0.227879</td>\n",
              "      <td>0.646546</td>\n",
              "      <td>0.931022</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.167785</td>\n",
              "      <td>0.219066</td>\n",
              "      <td>0.641414</td>\n",
              "      <td>0.929927</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.123436</td>\n",
              "      <td>0.227012</td>\n",
              "      <td>0.645635</td>\n",
              "      <td>0.930292</td>\n",
              "      <td>01:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.091981</td>\n",
              "      <td>0.221462</td>\n",
              "      <td>0.658926</td>\n",
              "      <td>0.934307</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.9324817657470703.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 4 with accuracy value: 0.9343065619468689.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvapwjB-DPaU",
        "outputId": "919447cb-e1a3-4d42-8b61-a4c9b07ee943"
      },
      "source": [
        "learn.load('mal_en_final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅkerala ‚ñÅa chay an ‚ñÅfan s ‚ñÅhit ‚ñÅlike,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅdon ma x ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥Ø‡¥æ‡¥£ ‡µã ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡µá xxunk ‡¥Æ‡µã ‡¥∂‡¥Ç . ‡¥ï‡µã ‡¥™‡µç‡¥™‡¥ø ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü‡¥æ ‚ñÅmass ‚ñÅ‡¥∏‡µÜ ‡¥ï‡µç‡¥∑ ‡¥®‡µç ‚ñÅ‡¥ï‡µä‡¥ü‡µÅ‡¥§‡µç‡¥§ ‚ñÅ‡¥¨‡¥ø ‡¥ú‡¥ø ‡¥é‡¥Ç ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥¨‡µã ‡¥± ‡¥Ø‡µç‡¥ï‡µç‡¥ï ‡¥ø ‡¥£ ‡¥≤‡µç‡¥≤‡µã . ‡¥Æ‡µä‡¥§‡µç‡¥§ ‡¥§‡µç‡¥§‡¥ø‡µΩ ‚ñÅ‡¥≤‡µã ‚ñÅ‡¥ï‡µç‡¥µ‡¥æ ‡¥≥‡¥ø ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥´‡µÄ ‡µΩ .,‚ñÅx x bo s ‚ñÅodi yanu ‚ñÅmun me yulla ‚ñÅla le ttane ‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk,‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï,‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅsan chit ‚ñÅbu l hara ‚ñÅb g m ‚ñÅnte ‚ñÅponn o ‚ñÅno ‚ñÅraksha,‚ñÅx x bo s ‚ñÅni vin ‚ñÅ‡¥á ‡¥ö‡µç‡¥ö ‡¥æ‡¥Ø ‡µª ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥§‡¥ï‡µº‡¥ï‡µç‡¥ï ‡µÅ‡¥Ç . . . ‚ñÅ‡¥Ü ‡¥∏‡¥ø ‡¥´ ‡¥≤‡¥ø ‚ñÅ‡¥´‡¥æ ‡µª ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥æ ‡¥∂‡¥Ç ‡¥∏ ‡¥ï‡µæ,‚ñÅx x bo s ‚ñÅ‡¥Ü ‡¥∞‡µã ‚ñÅ‡¥í‡¥∞‡¥æ‡µæ ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅ‡¥é‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü ‡µª ‚ñÅmy ‚ñÅbig ‚ñÅbrother,‚ñÅx x bo s ‚ñÅsuper ‚ñÅfi li m ‚ñÅthan k s ‚ñÅraj u ve tta ‚ñÅla le ttan ‚ñÅtha kar thu,‚ñÅx x bo s ‚ñÅp k ‚ñÅram das . . . ‚ñÅnamm u de ‚ñÅraj e ttan ‚ñÅa anennu ‚ñÅ nj n ‚ñÅpara jal ‚ñÅni ga lu de ‚ñÅabhiprayam . . . ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅgopi che tta nte ‚ñÅb g m ‚ñÅ um ‚ñÅmam mo o kayu m ‚ñÅishta pedunn avar ‚ñÅlike ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥™‡µÜ‡¥£‡µç‡¥£ ‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü ‡¥£‡µã ‚ñÅdirect ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅpoli chu ‚ñÅni vin,‚ñÅx x bo s ‚ñÅ‡¥™‡µÉ‡¥•‡µç‡¥µ‡¥ø ‡¥∞‡¥æ‡¥ú‡µç ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡µª ‚ñÅ‡¥≤‡¥æ ‡¥≤‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥≤ ‡¥ï‡µç‡¥∏‡µç . . ‚ñÅlal ‚ñÅj r . ‚ñÅ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥µ‡µÜ ‡¥±‡µà ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥™‡µç‡¥∞‡¥§‡µÄ‡¥ï‡µç‡¥∑‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥®‡µç‡¥®‡µÅ . . ‚ñÅbest ‚ñÅwi shes ‚ñÅteam,‚ñÅx x bo s ‚ñÅ‡¥™‡µã‡¥ï ‡¥∞‡µÅ‡¥§‡µç ‚ñÅ‡¥Æ‡¥ï‡µç‡¥ï‡¥≥ ‡µÜ ‚ñÅ‡¥™‡µã ‡¥ï‡µç‡¥ï ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅ‡¥® ‡µª ‚ñÅ‡¥ï‡¥£‡µç‡¥ü‡µç ‚ñÅ‡¥é ‡¥®‡µç‡¥±‡µç ‡¥Ø‡µÜ ‚ñÅ‡¥Ö‡¥Æ‡µç‡¥Æ ‡µã ‚ñÅ‡¥™‡µã‡¥≥‡¥ø ‡¥Ø ‚ñÅ‡¥Æ‡¥±‡¥ï‡µç‡¥ï ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ‡¥í‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥≤‡µÅ‡¥Ç,‚ñÅx x bo s ‚ñÅa van ‚ñÅvaru m ‚ñÅente ‚ñÅ makan ‚ñÅmadhura ‚ñÅraja ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (10956 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅkerala ‚ñÅa chay an ‚ñÅfan s ‚ñÅhit ‚ñÅlike,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅdon ma x ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥Ø‡¥æ‡¥£ ‡µã ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡µá xxunk ‡¥Æ‡µã ‡¥∂‡¥Ç . ‡¥ï‡µã ‡¥™‡µç‡¥™‡¥ø ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü‡¥æ ‚ñÅmass ‚ñÅ‡¥∏‡µÜ ‡¥ï‡µç‡¥∑ ‡¥®‡µç ‚ñÅ‡¥ï‡µä‡¥ü‡µÅ‡¥§‡µç‡¥§ ‚ñÅ‡¥¨‡¥ø ‡¥ú‡¥ø ‡¥é‡¥Ç ‚ñÅ‡¥®‡¥≤‡µç‡¥≤ ‚ñÅ‡¥¨‡µã ‡¥± ‡¥Ø‡µç‡¥ï‡µç‡¥ï ‡¥ø ‡¥£ ‡¥≤‡µç‡¥≤‡µã . ‡¥Æ‡µä‡¥§‡µç‡¥§ ‡¥§‡µç‡¥§‡¥ø‡µΩ ‚ñÅ‡¥≤‡µã ‚ñÅ‡¥ï‡µç‡¥µ‡¥æ ‡¥≥‡¥ø ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥´‡µÄ ‡µΩ .,‚ñÅx x bo s ‚ñÅodi yanu ‚ñÅmun me yulla ‚ñÅla le ttane ‚ñÅonnu ku de ‚ñÅthir ichu ‚ñÅki ttiya runn e ‚ñÅella thil um ‚ñÅor e ‚ñÅlook xxunk,‚ñÅx x bo s ‚ñÅ‡¥à ‚ñÅ‡¥ü‡µÄ ‡¥∏‡µº ‚ñÅ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡µÜ ‚ñÅ‡¥Ü‡¥¶‡µç‡¥Ø‡¥§‡µç‡¥§‡µÜ ‚ñÅ500 k ‚ñÅlike ‚ñÅ‡¥®‡µá‡¥ü ‡µÅ‡¥Æ‡µÜ‡¥®‡µç‡¥®‡µç ‚ñÅ‡¥â‡¥±‡¥™‡µç‡¥™ ‡µÅ‡¥≥‡µç‡¥≥ ‚ñÅ‡¥Æ ‡¥Æ‡µç‡¥Æ ‡µÅ‡¥ï‡µç‡¥ï ‚ñÅfan s ‚ñÅlike ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï,‚ñÅx x bo s ‚ñÅ‡¥™‡¥≤ ‡¥¶‡µá‡¥∂ ‡¥Ç . ‚ñÅ‡¥™‡¥≤ ‚ñÅ‡¥≠‡¥æ‡¥∑ ‚ñÅ‡¥í‡¥∞‡µá ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ ‚ñÅ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‚ñÅ‡¥∞‡¥æ‡¥ú ‡¥µ‡¥Ø ‡¥§‡µç ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (2740 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅsan chit ‚ñÅbu l hara ‚ñÅb g m ‚ñÅnte ‚ñÅponn o ‚ñÅno ‚ñÅraksha,‚ñÅx x bo s ‚ñÅni vin ‚ñÅ‡¥á ‡¥ö‡µç‡¥ö ‡¥æ‡¥Ø ‡µª ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥§‡¥ï‡µº‡¥ï‡µç‡¥ï ‡µÅ‡¥Ç . . . ‚ñÅ‡¥Ü ‡¥∏‡¥ø ‡¥´ ‡¥≤‡¥ø ‚ñÅ‡¥´‡¥æ ‡µª ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥µ‡¥ø‡¥ú‡¥Ø ‡¥æ ‡¥∂‡¥Ç ‡¥∏ ‡¥ï‡µæ,‚ñÅx x bo s ‚ñÅ‡¥Ü ‡¥∞‡µã ‚ñÅ‡¥í‡¥∞‡¥æ‡µæ ‚ñÅ‡¥Ö‡¥≤‡µç‡¥≤ ‚ñÅ‡¥é‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥è ‡¥ü‡µç‡¥ü ‡µª ‚ñÅmy ‚ñÅbig ‚ñÅbrother,‚ñÅx x bo s ‚ñÅsuper ‚ñÅfi li m ‚ñÅthan k s ‚ñÅraj u ve tta ‚ñÅla le ttan ‚ñÅtha kar thu,‚ñÅx x bo s ‚ñÅp k ‚ñÅram das . . . ‚ñÅnamm u de ‚ñÅraj e ttan ‚ñÅa anennu ‚ñÅ nj n ‚ñÅpara jal ‚ñÅni ga lu de ‚ñÅabhiprayam . . . ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (1999 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅgopi che tta nte ‚ñÅb g m ‚ñÅ um ‚ñÅmam mo o kayu m ‚ñÅishta pedunn avar ‚ñÅlike ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅ‡¥á‡¥§‡µç ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥™‡µÜ‡¥£‡µç‡¥£ ‡µç ‚ñÅ‡¥§‡¥®‡µç‡¥®‡µÜ ‚ñÅ‡¥Ü ‡¥£‡µã ‚ñÅdirect ‚ñÅ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‚ñÅpoli chu ‚ñÅni vin,‚ñÅx x bo s ‚ñÅ‡¥™‡µÉ‡¥•‡µç‡¥µ‡¥ø ‡¥∞‡¥æ‡¥ú‡µç ‚ñÅ‡¥∏‡µÅ ‡¥∞‡¥æ‡¥ú ‡µá ‡¥ü‡µç‡¥ü ‡µª ‚ñÅ‡¥≤‡¥æ ‡¥≤‡µÅ‡¥Ç ‚ñÅ‡¥Ö‡¥≤ ‡¥ï‡µç‡¥∏‡µç . . ‚ñÅlal ‚ñÅj r . ‚ñÅ‡¥®‡µç‡¥±‡µÜ ‚ñÅ‡¥í‡¥∞‡µÅ ‚ñÅ‡¥µ‡µÜ ‡¥±‡µà ‡¥±‡µç‡¥±‡¥ø ‚ñÅ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‚ñÅ‡¥™‡µç‡¥∞‡¥§‡µÄ‡¥ï‡µç‡¥∑‡¥ø‡¥ï‡µç‡¥ï ‡µÅ‡¥®‡µç‡¥®‡µÅ . . ‚ñÅbest ‚ñÅwi shes ‚ñÅteam,‚ñÅx x bo s ‚ñÅ‡¥™‡µã‡¥ï ‡¥∞‡µÅ‡¥§‡µç ‚ñÅ‡¥Æ‡¥ï‡µç‡¥ï‡¥≥ ‡µÜ ‚ñÅ‡¥™‡µã ‡¥ï‡µç‡¥ï ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ. ‚ñÅ‡¥® ‡µª ‚ñÅ‡¥ï‡¥£‡µç‡¥ü‡µç ‚ñÅ‡¥é ‡¥®‡µç‡¥±‡µç ‡¥Ø‡µÜ ‚ñÅ‡¥Ö‡¥Æ‡µç‡¥Æ ‡µã ‚ñÅ‡¥™‡µã‡¥≥‡¥ø ‡¥Ø ‚ñÅ‡¥Æ‡¥±‡¥ï‡µç‡¥ï ‡¥ø‡¥≤‡µç‡¥≤ ‚ñÅ‡¥í‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥≤‡µÅ‡¥Ç,‚ñÅx x bo s ‚ñÅa van ‚ñÅvaru m ‚ñÅente ‚ñÅ makan ‚ñÅmadhura ‚ñÅraja ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ.\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f9f4d3cbb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qan78ZnmDRBN"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "df_dict = {'query': list(mal_dev['data']), 'actual_label': list(mal_dev['label']), 'predicted_label': ['']*mal_dev.shape[0]}\n",
        "all_nodes = list(set(mal_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*mal_dev.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "    \n",
        "df_result = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result.head()\n",
        "\n",
        "mal_test=mal_test.to_frame()\n",
        "preds = []\n",
        "for index, row in mal_test.iterrows():\n",
        "    p = learn.predict(row['data'])\n",
        "    preds.append(str(p[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKXbikF9f4oQ"
      },
      "source": [
        "mal_test['text']=mal_test['data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "-aJA24_fdzW3",
        "outputId": "f54dbf1f-7139-4f49-83dd-b2bef3f1c433"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "\n",
        "data_lm_2 = TextClasDataBunch.from_df(path='/content',train_df=X_train_df, valid_df=X_val_df,  test_df=mal_test, tokenizer=tokenizer, vocab=mlen_vocab,text_cols='text',label_cols=['label'])\n",
        "learn = text_classifier_learner(data_lm_2, arch=AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/models/mal_en_fine_tuned_enc')\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/MalayalamEnglish/models/mal_en_final')\n",
        "\n",
        "df_dict = {'query': list(mal_test['text']), 'predicted_label': ['']*mal_test.shape[0]}\n",
        "all_nodes = list(set(mal_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*mal_test.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "\n",
        "\n",
        "df_result_2 = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result_2.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result_2.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-malayalam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥á‡¥§‡µä‡¥∞‡µä‡¥®‡µç‡¥®‡µä‡¥∞‡¥æ ‡¥Æ‡µä‡¥§‡¥≤‡¥æ‡¥£‡¥≤‡µç‡¥≤‡µá  Suraj ‡¥Ü‡¥£‡µç ‡¥®‡¥ü‡µª ‡¥®‡µç...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.000366868</td>\n",
              "      <td>0.000251058</td>\n",
              "      <td>0.994766</td>\n",
              "      <td>0.00346055</td>\n",
              "      <td>0.00115573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡¥é‡¥®‡µç‡¥§‡µç ‡¥ä‡¥≥ ‡¥é‡¥°‡¥ø‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç ‡¥Ü‡¥ü‡µã ‡¥á‡¥§‡µç ‡¥í‡¥∞‡µÅ‡¥Æ‡¥æ‡¥§‡¥ø‡¥∞‡¥ø vivo vid...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "      <td>0.261547</td>\n",
              "      <td>0.369347</td>\n",
              "      <td>0.0708671</td>\n",
              "      <td>0.295421</td>\n",
              "      <td>0.00281822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fefka ee padam release cheyyan samadhicho?</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.0028828</td>\n",
              "      <td>0.00533228</td>\n",
              "      <td>0.962859</td>\n",
              "      <td>0.0264426</td>\n",
              "      <td>0.00248293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡¥Ö‡¥Ü‡¥π‡¥æ.. ‡¥∏‡¥Ç‡¥ó‡µÄ‡¥§‡¥Ç ‡¥ú‡µÜ‡¥ï‡µç‚Äå‡¥∏‡µç ‡¥¨‡¥ø‡¥ú‡µã‡¥Ø‡µç ‡¥Ü‡¥£‡µç ‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥™‡µä‡¥ü‡µç‡¥ü‡¥≤‡µÅ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.00343776</td>\n",
              "      <td>0.00132228</td>\n",
              "      <td>0.978265</td>\n",
              "      <td>0.015695</td>\n",
              "      <td>0.00128001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ravile thane views likes ethra ayyi enn nokan ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.000342353</td>\n",
              "      <td>0.000275865</td>\n",
              "      <td>0.994301</td>\n",
              "      <td>0.00193163</td>\n",
              "      <td>0.00314934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... not-malayalam\n",
              "0  ‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥á‡¥§‡µä‡¥∞‡µä‡¥®‡µç‡¥®‡µä‡¥∞‡¥æ ‡¥Æ‡µä‡¥§‡¥≤‡¥æ‡¥£‡¥≤‡µç‡¥≤‡µá  Suraj ‡¥Ü‡¥£‡µç ‡¥®‡¥ü‡µª ‡¥®‡µç...  ...    0.00115573\n",
              "1  ‡¥é‡¥®‡µç‡¥§‡µç ‡¥ä‡¥≥ ‡¥é‡¥°‡¥ø‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç ‡¥Ü‡¥ü‡µã ‡¥á‡¥§‡µç ‡¥í‡¥∞‡µÅ‡¥Æ‡¥æ‡¥§‡¥ø‡¥∞‡¥ø vivo vid...  ...    0.00281822\n",
              "2         Fefka ee padam release cheyyan samadhicho?  ...    0.00248293\n",
              "3  ‡¥Ö‡¥Ü‡¥π‡¥æ.. ‡¥∏‡¥Ç‡¥ó‡µÄ‡¥§‡¥Ç ‡¥ú‡µÜ‡¥ï‡µç‚Äå‡¥∏‡µç ‡¥¨‡¥ø‡¥ú‡µã‡¥Ø‡µç ‡¥Ü‡¥£‡µç ‡¥Ö‡¥™‡µç‡¥™‡µä ‡¥™‡µä‡¥ü‡µç‡¥ü‡¥≤‡µÅ...  ...    0.00128001\n",
              "4  Ravile thane views likes ethra ayyi enn nokan ...  ...    0.00314934\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX3XAYUO2SoQ"
      },
      "source": [
        "df_test_pred_2 = pd.DataFrame(\n",
        "    {'query': mal_test['data'],\n",
        "     'predicted_label': preds    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VrddEYV6im5"
      },
      "source": [
        "df_test_pred_2.to_csv('mal_test_preds_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uBXPVC-DVgr",
        "outputId": "f1001c2b-b53c-48b7-ce17-b9310e1f7aa7"
      },
      "source": [
        "accuracy_score(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9514757378689345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAxoe1QVDXAS",
        "outputId": "b041cdf6-f0ed-4b9e-da23-8707506b0397"
      },
      "source": [
        "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7552146165655927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSceQeYUF6_Z",
        "outputId": "c9ccc9a4-5830-47dd-d515-99cc11481e09"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(df_result['actual_label'], df_result['predicted_label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "                       Not_offensive       0.97      0.98      0.97      1779\n",
            "     Offensive_Targeted_Insult_Group       0.57      0.31      0.40        13\n",
            "Offensive_Targeted_Insult_Individual       0.80      0.33      0.47        24\n",
            "               Offensive_Untargetede       0.55      0.60      0.57        20\n",
            "                       not-malayalam       0.81      0.87      0.83       163\n",
            "\n",
            "                            accuracy                           0.95      1999\n",
            "                           macro avg       0.74      0.62      0.65      1999\n",
            "                        weighted avg       0.95      0.95      0.95      1999\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIRxewFmAUTa"
      },
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "                       Not_offensive       0.97      0.98      0.97      1779\n",
        "     Offensive_Targeted_Insult_Group       0.57      0.31      0.40        13\n",
        "Offensive_Targeted_Insult_Individual       0.80      0.33      0.47        24\n",
        "               Offensive_Untargetede       0.55      0.60      0.57        20\n",
        "                       not-malayalam       0.81      0.87      0.83       163\n",
        "\n",
        "                            accuracy                           0.95      1999\n",
        "                           macro avg       0.74      0.62      0.65      1999\n",
        "                        weighted avg       0.95      0.95      0.95      1999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoYU0GjQSGOc"
      },
      "source": [
        "df_result.to_excel('mal_ml_2.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMg9ospsmbJJ"
      },
      "source": [
        "df_result_2.to_excel('mal_ml_test_preds.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvsJe8sQCoMN"
      },
      "source": [
        "!mv '/content/models' '/content/drive/MyDrive/AggressionNLP/MalayalamEnglish'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PddAWTknUsi5"
      },
      "source": [
        "#ULMFiT Tamil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie_XwWMjUsi6",
        "outputId": "92d38b30-6035-4d12-f557-0afd4c90fcfc"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdcUu0gsUsi6"
      },
      "source": [
        "#reference: https://github.com/goru001/nlp-for-malyalam/blob/master/classification/Malyalam_Classification_Model.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpeVROz3Usi7"
      },
      "source": [
        "from fastai.text import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV23245zUsi7",
        "outputId": "80b0a2e7-db18-408b-c2ee-0f28e2b1f8b8"
      },
      "source": [
        "import fastai, torch\n",
        "fastai.__version__ , torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.0.61', '1.7.0+cu101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ-j2lEdVaKW"
      },
      "source": [
        "def handle_all_caps(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = replace_all_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def handle_upper_case_first_letter(t: str) -> str:\n",
        "    tokens = t.split()\n",
        "    tokens = deal_caps(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def lower_case_everything(t: str) -> str:\n",
        "    return t.lower().replace('@user', '').replace('#tag ', '').replace('rt ', '').strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y7PyqQCVd1j"
      },
      "source": [
        "class CodeMixedTamilTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.lang = lang\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/tokenizer/taen_spm.model\"))\n",
        "        \n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        return self.sp.EncodeAsPieces(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ_sTZ3KUsi8"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(str(\"/content/drive/MyDrive/AggressionNLP/tokenizer/taen_spm.model\"))\n",
        "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yq8TYyMUsi8"
      },
      "source": [
        "# 8,000 is the vocab size that we chose in sentencepiece\n",
        "taen_vocab = Vocab(itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RI-HrtKUsi8"
      },
      "source": [
        "tokenizer = Tokenizer(lang='taen', tok_func=CodeMixedTamilTokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zJH0YaWhmU"
      },
      "source": [
        "tokenizer.pre_rules.append(lower_case_everything)\n",
        "tokenizer.pre_rules.append(handle_all_caps)\n",
        "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtOxyCiyUsi8",
        "outputId": "2e791900-55ea-4213-d38f-1104747e2414"
      },
      "source": [
        "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['xxunk',\n",
              "  'xxpad',\n",
              "  'xxbos',\n",
              "  'xxeos',\n",
              "  'xxfld',\n",
              "  'xxmaj',\n",
              "  'xxup',\n",
              "  'xxrep',\n",
              "  'xxwrep'],\n",
              " [<function fastai.text.transform.fix_html>,\n",
              "  <function fastai.text.transform.replace_rep>,\n",
              "  <function fastai.text.transform.replace_wrep>,\n",
              "  <function fastai.text.transform.spec_add_spaces>,\n",
              "  <function fastai.text.transform.rm_useless_spaces>,\n",
              "  <function __main__.lower_case_everything>,\n",
              "  <function __main__.handle_all_caps>,\n",
              "  <function __main__.handle_upper_case_first_letter>],\n",
              " [<function fastai.text.transform.replace_all_caps>,\n",
              "  <function fastai.text.transform.deal_caps>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKxxecpXUsi8"
      },
      "source": [
        "label_cols = ['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OW5OElSXViPh",
        "outputId": "46b3d950-07b8-485d-ffc2-eacbb27618bf"
      },
      "source": [
        "tamil_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35134</th>\n",
              "      <td>Trending number #2 idhukku nammalam karanamnu ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35135</th>\n",
              "      <td>Movie script super, athuvum HIP HOP Tamizha mu...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35136</th>\n",
              "      <td>Just 3k likes for 300k likes</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35137</th>\n",
              "      <td>Aaloo le lo. Kanda le lo.</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35138</th>\n",
              "      <td>‡Æ®‡Ææ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≤‡Øç ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç  ‡Æµ‡Æ©‡Øç‡Æ©‡Æø‡ÆØ‡Æ∞‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æ§‡Æø‡Æ∞‡Øå‡Æ™‡Æ§‡Æø ‡Æ™‡Æü...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34898 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    data  ... token_length\n",
              "0                      movie vara level la Erika poguthu  ...            6\n",
              "1      I love Ajith Kumar Vivegam movie inki mjy bht ...  ...           11\n",
              "2              Padam nalla comedy padama irukum polaye..  ...            6\n",
              "3      karthick subburaj anne .... intha padam vetri ...  ...           11\n",
              "4      ‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å  ...            6\n",
              "...                                                  ...  ...          ...\n",
              "35134  Trending number #2 idhukku nammalam karanamnu ...  ...           15\n",
              "35135  Movie script super, athuvum HIP HOP Tamizha mu...  ...            9\n",
              "35136                       Just 3k likes for 300k likes  ...            6\n",
              "35137                          Aaloo le lo. Kanda le lo.  ...            6\n",
              "35138  ‡Æ®‡Ææ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≤‡Øç ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç  ‡Æµ‡Æ©‡Øç‡Æ©‡Æø‡ÆØ‡Æ∞‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æ§‡Æø‡Æ∞‡Øå‡Æ™‡Æ§‡Æø ‡Æ™‡Æü...  ...           13\n",
              "\n",
              "[34898 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "_v2Mr6yJU3aj",
        "outputId": "d8a44940-2d71-4cae-ee78-076f96032129"
      },
      "source": [
        "\n",
        "\n",
        "df_result_2['data']=df_result_2['query']\n",
        "df_result_2['label']=df_result_2['predicted_label']\n",
        "\n",
        "tamil_train_new = pd.concat([tamil_train,df_result_2])\n",
        "tamil_train_new\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4387</th>\n",
              "      <td>‡ÆÆ‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ™‡Øä‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æí‡Æ©‡Øç‡Æ©‡ØÅ ‡ÆÖ‡Æ§‡ØÅ‡Æ≤ ‡Æé‡Æµ‡Æ©‡Øç ‡Æï‡Øà‡ÆØ ‡Æµ‡Æö‡Øç‡Æö...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>‡ÆÆ‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ™‡Øä‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æí‡Æ©‡Øç‡Æ©‡ØÅ ‡ÆÖ‡Æ§‡ØÅ‡Æ≤ ‡Æé‡Æµ‡Æ©‡Øç ‡Æï‡Øà‡ÆØ ‡Æµ‡Æö‡Øç‡Æö...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.766744</td>\n",
              "      <td>0.0503728</td>\n",
              "      <td>0.00911015</td>\n",
              "      <td>0.153053</td>\n",
              "      <td>0.0108718</td>\n",
              "      <td>0.00984812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4388</th>\n",
              "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.00502923</td>\n",
              "      <td>0.000932901</td>\n",
              "      <td>0.991985</td>\n",
              "      <td>0.00125333</td>\n",
              "      <td>0.00035997</td>\n",
              "      <td>0.000439906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4389</th>\n",
              "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.433976</td>\n",
              "      <td>0.070667</td>\n",
              "      <td>0.0175401</td>\n",
              "      <td>0.260035</td>\n",
              "      <td>0.0493117</td>\n",
              "      <td>0.16847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4390</th>\n",
              "      <td>Vijay's all movies look like same.</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Vijay's all movies look like same.</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.756128</td>\n",
              "      <td>0.126564</td>\n",
              "      <td>0.00353285</td>\n",
              "      <td>0.091604</td>\n",
              "      <td>0.00840872</td>\n",
              "      <td>0.013763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4391</th>\n",
              "      <td>Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "      <td>0.118437</td>\n",
              "      <td>0.206409</td>\n",
              "      <td>0.0360143</td>\n",
              "      <td>0.371831</td>\n",
              "      <td>0.0636174</td>\n",
              "      <td>0.203691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39290 rows √ó 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  ... Offensive_Untargetede\n",
              "0                     movie vara level la Erika poguthu  ...                   NaN\n",
              "1     I love Ajith Kumar Vivegam movie inki mjy bht ...  ...                   NaN\n",
              "2             Padam nalla comedy padama irukum polaye..  ...                   NaN\n",
              "3     karthick subburaj anne .... intha padam vetri ...  ...                   NaN\n",
              "4     ‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å  ...                   NaN\n",
              "...                                                 ...  ...                   ...\n",
              "4387  ‡ÆÆ‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ™‡Øä‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æí‡Æ©‡Øç‡Æ©‡ØÅ ‡ÆÖ‡Æ§‡ØÅ‡Æ≤ ‡Æé‡Æµ‡Æ©‡Øç ‡Æï‡Øà‡ÆØ ‡Æµ‡Æö‡Øç‡Æö...  ...            0.00984812\n",
              "4388  Babu mele ko ye song sunke kuch yesa feel hua ...  ...           0.000439906\n",
              "4389  asuran= aadukalam+pudupettai+ wada chennai..ye...  ...               0.16847\n",
              "4390                 Vijay's all movies look like same.  ...              0.013763\n",
              "4391  Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...  ...              0.203691\n",
              "\n",
              "[39290 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NobfJMIUUsi8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(tamil_train_new['data'],tamil_train_new['label'], test_size = 0.2, random_state = 42, stratify=tamil_train_new['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3vkSUfDUsi9",
        "outputId": "535bc5f1-2f75-426a-cafe-0c5ef863c8c6"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24687    Punda mathi iruku,evan la nadikalanu ipa yaru ...\n",
              "16896                Suriya anna mass next cm suriya  anna\n",
              "30882            Really semaa Karthik bro.. bgm Vera level\n",
              "146                          Kiya yeh movie Hindi me hai ?\n",
              "8549     15 Million varum nu solravanga mattum like pan...\n",
              "                               ...                        \n",
              "17064    ‡Æá‡Æµ‡Æ∞‡ØÅ ‡Æ™‡Ææ‡Æü‡Øç‡Æü ‡ÆØ‡Ææ‡Æ∞‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Ææ‡Æü‡Æï‡Øç‡Æï‡ØÇ‡Æü‡Ææ‡Æ§‡Ææ‡ÆÆ‡Øç.... ‡ÆÜ‡Æ©‡Ææ ‡Æá‡Æµ‡Æ∞‡ØÅ ‡ÆÆ...\n",
              "18423                             KRISH-4    HIT LIKE HERE\n",
              "1902        ‡Æ§‡ØÜ‡Æ©‡Øç ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç\n",
              "1022     pesi pesi time waste pannama trailer views inc...\n",
              "18629    Edhula aichu nithyamenon last varaik uiyroda i...\n",
              "Name: data, Length: 31432, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJU2xW1eUsi9"
      },
      "source": [
        "X_train_df = pd.concat([X_train, y_train], axis=1, keys=['text', 'label'])\n",
        "X_val_df = pd.concat([X_val, y_val], axis=1, keys=['text', 'label'])\n",
        "X_test_df = pd.concat([tamil_dev['data'], tamil_dev['label']], axis=1, keys=['text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WijUIiOzUsi9"
      },
      "source": [
        "# X_train_df['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "UOje1MIUUsi9",
        "outputId": "c2183e2a-ff84-4f0c-de1d-ebcd31750cf3"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=taen_vocab,text_cols='text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "w_u7HNoFUsi9",
        "outputId": "562e8a3b-1b89-4eda-953d-c0f66c405a20"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ? ‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a ‚ñÅx x bo s ‚ñÅdai ‚ñÅev anda ‚ñÅin tha ‚ñÅte as er ‚ñÅ kku ‚ñÅdis like ‚ñÅpoo tt avan ‚ñÅivan u hal a ‚ñÅethir kki rav anga ‚ñÅ like ‚ñÅpo du nga ‚ñÅx x bo s ‚ñÅtha la</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>aya ‚ñÅse ruppa la ‚ñÅadi kkan um ‚ñÅx x bo s ‚ñÅeth ana ‚ñÅna al ‚ñÅtha an ‚ñÅna angalum ‚ñÅho ll y wood ‚ñÅsu per ‚ñÅher o ‚ñÅva ‚ñÅpa ak ur adu ‚ñÅnam ma ‚ñÅo o ur la um ‚ñÅir ru ka an nga ‚ñÅpa ap o om . . . ‚ñÅb y ‚ñÅa 3 ‚ñÅx x bo s ‚ñÅse m ma ‚ñÅpa . . ‚ñÅ but ‚ñÅenna ku ‚ñÅind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>‚ñÅcel i br ation um ‚ñÅdhe e pa vali ‚ñÅvar e kkum ‚ñÅmattum ‚ñÅthan ‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk . xxunk . xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk . . . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk . . . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>‚ñÅthe va ‚ñÅpad uth u . . . ‚ñÅan y way s ‚ñÅw ish es ‚ñÅf rom ‚ñÅnor mal ‚ñÅcom mon s ‚ñÅhu man ‚ñÅ wit ho ut ‚ñÅan y ‚ñÅshi tt y ‚ñÅbri de ‚ñÅf rom ‚ñÅtamilnadu ‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ . . . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk . xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk . ? ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅx x bo s ‚ñÅindian ‚ñÅen d ru ‚ñÅkur um po th u ‚ñÅe ppa di ‚ñÅa singam ai ‚ñÅi hr uku ‚ñÅtamil an ‚ñÅen d ru ‚ñÅkur um po th u ‚ñÅe ppa di ‚ñÅunarvu ‚ñÅpon kut hu ‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69B4HhoWUsi-"
      },
      "source": [
        "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxJAQRnSdfil"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel/models.zip' -d '/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc_DzlMuUsi-",
        "outputId": "5e5c02d8-aef9-4051-c9aa-e55c27a128ba"
      },
      "source": [
        "# Loading the pretrained language model on malyalam wikipedia\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel/models/best_model', with_opt=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅpun da ‚ñÅmath i ‚ñÅiru ku , e van ‚ñÅla ‚ñÅnadi kal anu ‚ñÅip a ‚ñÅyar u ‚ñÅwat ha ‚ñÅal u tha,‚ñÅx x bo s ‚ñÅsu riya ‚ñÅanna ‚ñÅmas s ‚ñÅne x t ‚ñÅc m ‚ñÅsu riya ‚ñÅanna,‚ñÅx x bo s ‚ñÅre al ly ‚ñÅse ma a ‚ñÅkar thi k ‚ñÅbr o . . ‚ñÅb g m ‚ñÅver a ‚ñÅle vel,‚ñÅx x bo s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ?,‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅb g m ‚ñÅ asu su al ‚ñÅtheri kka ‚ñÅvit aru ‚ñÅsam ‚ñÅc s,‚ñÅx x bo s ‚ñÅpadi pa ‚ñÅmat um ‚ñÅedu th uki d ave ‚ñÅmudiyath u ‚ñÅchi d ambar am ‚ñÅenna ‚ñÅpadi cha ‚ñÅb . e xxunk,‚ñÅx x bo s ‚ñÅvellore ‚ñÅ mavatt am ‚ñÅvanni ya ‚ñÅkul a ‚ñÅk sa 3 n ‚ñÅmo vi e ‚ñÅvatt ri ‚ñÅpara ‚ñÅvayu th u kal,‚ñÅx x bo s ‚ñÅhi ndi ‚ñÅmai ‚ñÅk b ‚ñÅa aye ga ‚ñÅ2. 0 ‚ñÅka ‚ñÅtra il er,‚ñÅx x bo s ‚ñÅtha la ‚ñÅvant ha ‚ñÅpo thum . . ‚ñÅvis ulu ‚ñÅpar akum le ‚ñÅthe ath re ‚ñÅle h . . ‚ñÅter ike ‚ñÅvid rom . . en ni kum ‚ñÅe ppa y um ‚ñÅtha la ‚ñÅmattum tha . xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅhan ds ome ‚ñÅhu n k ‚ñÅke ri ‚ñÅva a ‚ñÅtha lai va a,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅje ‚ñÅ vo us ‚ñÅai me ‚ñÅbr avo ‚ñÅpo ur ‚ñÅcli p ‚ñÅde ‚ñÅmer de ‚ñÅqu e ‚ñÅj ‚ñÅ xxunk co u te ‚ñÅau ‚ñÅto il ette .,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ .,‚ñÅx x bo s ‚ñÅver a ‚ñÅle vel ‚ñÅb g m ‚ñÅ . . ‚ñÅse m ma ‚ñÅtra il er . ‚ñÅ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(8000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅpun da ‚ñÅmath i ‚ñÅiru ku , e van ‚ñÅla ‚ñÅnadi kal anu ‚ñÅip a ‚ñÅyar u ‚ñÅwat ha ‚ñÅal u tha,‚ñÅx x bo s ‚ñÅsu riya ‚ñÅanna ‚ñÅmas s ‚ñÅne x t ‚ñÅc m ‚ñÅsu riya ‚ñÅanna,‚ñÅx x bo s ‚ñÅre al ly ‚ñÅse ma a ‚ñÅkar thi k ‚ñÅbr o . . ‚ñÅb g m ‚ñÅver a ‚ñÅle vel,‚ñÅx x bo s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ?,‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅb g m ‚ñÅ asu su al ‚ñÅtheri kka ‚ñÅvit aru ‚ñÅsam ‚ñÅc s,‚ñÅx x bo s ‚ñÅpadi pa ‚ñÅmat um ‚ñÅedu th uki d ave ‚ñÅmudiyath u ‚ñÅchi d ambar am ‚ñÅenna ‚ñÅpadi cha ‚ñÅb . e xxunk,‚ñÅx x bo s ‚ñÅvellore ‚ñÅ mavatt am ‚ñÅvanni ya ‚ñÅkul a ‚ñÅk sa 3 n ‚ñÅmo vi e ‚ñÅvatt ri ‚ñÅpara ‚ñÅvayu th u kal,‚ñÅx x bo s ‚ñÅhi ndi ‚ñÅmai ‚ñÅk b ‚ñÅa aye ga ‚ñÅ2. 0 ‚ñÅka ‚ñÅtra il er,‚ñÅx x bo s ‚ñÅtha la ‚ñÅvant ha ‚ñÅpo thum . . ‚ñÅvis ulu ‚ñÅpar akum le ‚ñÅthe ath re ‚ñÅle h . . ‚ñÅter ike ‚ñÅvid rom . . en ni kum ‚ñÅe ppa y um ‚ñÅtha la ‚ñÅmattum tha . xxunk\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x bo s ‚ñÅhan ds ome ‚ñÅhu n k ‚ñÅke ri ‚ñÅva a ‚ñÅtha lai va a,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅje ‚ñÅ vo us ‚ñÅai me ‚ñÅbr avo ‚ñÅpo ur ‚ñÅcli p ‚ñÅde ‚ñÅmer de ‚ñÅqu e ‚ñÅj ‚ñÅ xxunk co u te ‚ñÅau ‚ñÅto il ette .,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ .,‚ñÅx x bo s ‚ñÅver a ‚ñÅle vel ‚ñÅb g m ‚ñÅ . . ‚ñÅse m ma ‚ñÅtra il er . ‚ñÅ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(8000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vSso7WbUsi-"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "V7JrzwIgUsi-",
        "outputId": "380090fd-8606-4267-b0f3-a5bbdef3a86f"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.342346</td>\n",
              "      <td>3.190416</td>\n",
              "      <td>0.450147</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSshThU-Usi-"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "i86Newk8Usi-",
        "outputId": "c38d2e5f-9c89-4763-bed5-77e7c1949aa5"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.047039</td>\n",
              "      <td>2.946275</td>\n",
              "      <td>0.485142</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.818084</td>\n",
              "      <td>2.737316</td>\n",
              "      <td>0.511586</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.663767</td>\n",
              "      <td>2.650596</td>\n",
              "      <td>0.522545</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.578151</td>\n",
              "      <td>2.620064</td>\n",
              "      <td>0.526327</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.541581</td>\n",
              "      <td>2.616519</td>\n",
              "      <td>0.526984</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ka25TvIUsi_"
      },
      "source": [
        "learn.save_encoder('ta_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "itfvYW44Usi_",
        "outputId": "6a57a188-d97d-46dd-aea5-d5bee2438c04"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df,test_df=X_test_df, tokenizer=tokenizer, vocab=taen_vocab,text_cols=['text'], label_cols=['label'], bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "BohPonEpUsi_",
        "outputId": "4b79d658-3569-4020-caa4-e8a7301d2568"
      },
      "source": [
        "data_clas.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ10 ‚ñÅ= ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅo k ‚ñÅsir , ‚ñÅena ku ‚ñÅore ‚ñÅsil a ‚ñÅkel vi gal ‚ñÅmattum ‚ñÅtha a ‚ñÅiru ku ‚ñÅin tha ‚ñÅ padat ha ‚ñÅ pathi y um , ‚ñÅun ga ‚ñÅsa a dhi ‚ñÅkala ach a ara tha ‚ñÅ pathi y um , ‚ñÅkel vi -1 : ‚ñÅne eng a ‚ñÅsol dra ‚ñÅma ari ‚ñÅun ga ‚ñÅsa a thi ‚ñÅpengal a ‚ñÅem a a than um ‚ñÅ</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅin tha ‚ñÅnad ag a ‚ñÅkatha l ‚ñÅ , ‚ñÅsa a thi ‚ñÅver i , ‚ñÅit hu ‚ñÅella tha um ‚ñÅvid a ‚ñÅne nga ‚ñÅyar a ‚ñÅvir um puri ngal o ‚ñÅavan gal oda ‚ñÅori gin al ity ‚ñÅa ‚ñÅtheri n ju ka ‚ñÅt ry ‚ñÅpan ung a . . ‚ñÅavan ga ‚ñÅf am il ya ‚ñÅtheri n ju ka ‚ñÅt ry ‚ñÅpan ung a ‚ñÅava</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x bo s ‚ñÅsurya ‚ñÅve sh ti ‚ñÅ ah ‚ñÅcor re c ta ‚ñÅmadi chu ‚ñÅnad akum ‚ñÅpodhu ‚ñÅvar a ‚ñÅte as er ‚ñÅb g m ‚ñÅh m m ‚ñÅse m m ‚ñÅ xxrep ‚ñÅ5 ‚ñÅa ‚ñÅ . . . ‚ñÅ power fu l ‚ñÅdi al o gu es ‚ñÅand ‚ñÅex p res sion s . . . ‚ñÅf d f s . . . ‚ñÅselva ra gh avan</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HLjlamaUsi_"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAjyAoN3Usi_",
        "outputId": "a1a0975b-1bff-4327-fb75-fd5eab61e533"
      },
      "source": [
        "learn.load_encoder('ta_en_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅpun da ‚ñÅmath i ‚ñÅiru ku , e van ‚ñÅla ‚ñÅnadi kal anu ‚ñÅip a ‚ñÅyar u ‚ñÅwat ha ‚ñÅal u tha,‚ñÅx x bo s ‚ñÅsu riya ‚ñÅanna ‚ñÅmas s ‚ñÅne x t ‚ñÅc m ‚ñÅsu riya ‚ñÅanna,‚ñÅx x bo s ‚ñÅre al ly ‚ñÅse ma a ‚ñÅkar thi k ‚ñÅbr o . . ‚ñÅb g m ‚ñÅver a ‚ñÅle vel,‚ñÅx x bo s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ?,‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅb g m ‚ñÅ asu su al ‚ñÅtheri kka ‚ñÅvit aru ‚ñÅsam ‚ñÅc s,‚ñÅx x bo s ‚ñÅpadi pa ‚ñÅmat um ‚ñÅedu th uki d ave ‚ñÅmudiyath u ‚ñÅchi d ambar am ‚ñÅenna ‚ñÅpadi cha ‚ñÅb . e xxunk,‚ñÅx x bo s ‚ñÅvellore ‚ñÅ mavatt am ‚ñÅvanni ya ‚ñÅkul a ‚ñÅk sa 3 n ‚ñÅmo vi e ‚ñÅvatt ri ‚ñÅpara ‚ñÅvayu th u kal,‚ñÅx x bo s ‚ñÅhi ndi ‚ñÅmai ‚ñÅk b ‚ñÅa aye ga ‚ñÅ2. 0 ‚ñÅka ‚ñÅtra il er,‚ñÅx x bo s ‚ñÅtha la ‚ñÅvant ha ‚ñÅpo thum . . ‚ñÅvis ulu ‚ñÅpar akum le ‚ñÅthe ath re ‚ñÅle h . . ‚ñÅter ike ‚ñÅvid rom . . en ni kum ‚ñÅe ppa y um ‚ñÅtha la ‚ñÅmattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅhan ds ome ‚ñÅhu n k ‚ñÅke ri ‚ñÅva a ‚ñÅtha lai va a,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅje ‚ñÅ vo us ‚ñÅai me ‚ñÅbr avo ‚ñÅpo ur ‚ñÅcli p ‚ñÅde ‚ñÅmer de ‚ñÅqu e ‚ñÅj ‚ñÅ xxunk co u te ‚ñÅau ‚ñÅto il ette .,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ .,‚ñÅx x bo s ‚ñÅver a ‚ñÅle vel ‚ñÅb g m ‚ñÅ . . ‚ñÅse m ma ‚ñÅtra il er . ‚ñÅ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅpun da ‚ñÅmath i ‚ñÅiru ku , e van ‚ñÅla ‚ñÅnadi kal anu ‚ñÅip a ‚ñÅyar u ‚ñÅwat ha ‚ñÅal u tha,‚ñÅx x bo s ‚ñÅsu riya ‚ñÅanna ‚ñÅmas s ‚ñÅne x t ‚ñÅc m ‚ñÅsu riya ‚ñÅanna,‚ñÅx x bo s ‚ñÅre al ly ‚ñÅse ma a ‚ñÅkar thi k ‚ñÅbr o . . ‚ñÅb g m ‚ñÅver a ‚ñÅle vel,‚ñÅx x bo s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ?,‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅb g m ‚ñÅ asu su al ‚ñÅtheri kka ‚ñÅvit aru ‚ñÅsam ‚ñÅc s,‚ñÅx x bo s ‚ñÅpadi pa ‚ñÅmat um ‚ñÅedu th uki d ave ‚ñÅmudiyath u ‚ñÅchi d ambar am ‚ñÅenna ‚ñÅpadi cha ‚ñÅb . e xxunk,‚ñÅx x bo s ‚ñÅvellore ‚ñÅ mavatt am ‚ñÅvanni ya ‚ñÅkul a ‚ñÅk sa 3 n ‚ñÅmo vi e ‚ñÅvatt ri ‚ñÅpara ‚ñÅvayu th u kal,‚ñÅx x bo s ‚ñÅhi ndi ‚ñÅmai ‚ñÅk b ‚ñÅa aye ga ‚ñÅ2. 0 ‚ñÅka ‚ñÅtra il er,‚ñÅx x bo s ‚ñÅtha la ‚ñÅvant ha ‚ñÅpo thum . . ‚ñÅvis ulu ‚ñÅpar akum le ‚ñÅthe ath re ‚ñÅle h . . ‚ñÅter ike ‚ñÅvid rom . . en ni kum ‚ñÅe ppa y um ‚ñÅtha la ‚ñÅmattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅhan ds ome ‚ñÅhu n k ‚ñÅke ri ‚ñÅva a ‚ñÅtha lai va a,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅje ‚ñÅ vo us ‚ñÅai me ‚ñÅbr avo ‚ñÅpo ur ‚ñÅcli p ‚ñÅde ‚ñÅmer de ‚ñÅqu e ‚ñÅj ‚ñÅ xxunk co u te ‚ñÅau ‚ñÅto il ette .,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ .,‚ñÅx x bo s ‚ñÅver a ‚ñÅle vel ‚ñÅb g m ‚ñÅ . . ‚ñÅse m ma ‚ñÅtra il er . ‚ñÅ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BAFF0EMUsjA"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Yl7YVfUsjA",
        "outputId": "f08edc4c-b0d2-42a7-fdf4-14586b1ff562"
      },
      "source": [
        "learn.loss_func.func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmdsdYr1UsjA"
      },
      "source": [
        "mcc = MatthewsCorreff()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fVLQLi4UsjA"
      },
      "source": [
        "learn.metrics = [mcc, accuracy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "DRe8ZtvcUsjA",
        "outputId": "ce76f5f0-fa00-4ff0-beca-82c7fbd34260"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.756907</td>\n",
              "      <td>0.746978</td>\n",
              "      <td>0.260864</td>\n",
              "      <td>0.759735</td>\n",
              "      <td>02:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "1Q3kHq-pUsjA",
        "outputId": "dbc32053-9039-44ee-d07c-506310f405a8"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.714599</td>\n",
              "      <td>0.689862</td>\n",
              "      <td>0.359258</td>\n",
              "      <td>0.776788</td>\n",
              "      <td>02:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD21VEJrUsjB"
      },
      "source": [
        "learn.save('ta_en_second-full')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "JP9eH5P8UsjB",
        "outputId": "257e3e77-0892-459a-9357-eb3ba0bf9cd7"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='ta_en_final')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.689207</td>\n",
              "      <td>0.685190</td>\n",
              "      <td>0.398968</td>\n",
              "      <td>0.781878</td>\n",
              "      <td>03:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.690695</td>\n",
              "      <td>0.682075</td>\n",
              "      <td>0.383667</td>\n",
              "      <td>0.781878</td>\n",
              "      <td>03:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.566103</td>\n",
              "      <td>0.666720</td>\n",
              "      <td>0.423357</td>\n",
              "      <td>0.787223</td>\n",
              "      <td>03:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.661854</td>\n",
              "      <td>0.666134</td>\n",
              "      <td>0.429674</td>\n",
              "      <td>0.790150</td>\n",
              "      <td>03:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.583230</td>\n",
              "      <td>0.666931</td>\n",
              "      <td>0.443367</td>\n",
              "      <td>0.789005</td>\n",
              "      <td>03:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.7818783521652222.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with accuracy value: 0.787223219871521.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with accuracy value: 0.7901501655578613.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8_yljAvUsjB",
        "outputId": "8df5d9ca-9f43-4ab4-9e73-81d0b4cf0c99"
      },
      "source": [
        "learn.load('ta_en_final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅpun da ‚ñÅmath i ‚ñÅiru ku , e van ‚ñÅla ‚ñÅnadi kal anu ‚ñÅip a ‚ñÅyar u ‚ñÅwat ha ‚ñÅal u tha,‚ñÅx x bo s ‚ñÅsu riya ‚ñÅanna ‚ñÅmas s ‚ñÅne x t ‚ñÅc m ‚ñÅsu riya ‚ñÅanna,‚ñÅx x bo s ‚ñÅre al ly ‚ñÅse ma a ‚ñÅkar thi k ‚ñÅbr o . . ‚ñÅb g m ‚ñÅver a ‚ñÅle vel,‚ñÅx x bo s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ?,‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅb g m ‚ñÅ asu su al ‚ñÅtheri kka ‚ñÅvit aru ‚ñÅsam ‚ñÅc s,‚ñÅx x bo s ‚ñÅpadi pa ‚ñÅmat um ‚ñÅedu th uki d ave ‚ñÅmudiyath u ‚ñÅchi d ambar am ‚ñÅenna ‚ñÅpadi cha ‚ñÅb . e xxunk,‚ñÅx x bo s ‚ñÅvellore ‚ñÅ mavatt am ‚ñÅvanni ya ‚ñÅkul a ‚ñÅk sa 3 n ‚ñÅmo vi e ‚ñÅvatt ri ‚ñÅpara ‚ñÅvayu th u kal,‚ñÅx x bo s ‚ñÅhi ndi ‚ñÅmai ‚ñÅk b ‚ñÅa aye ga ‚ñÅ2. 0 ‚ñÅka ‚ñÅtra il er,‚ñÅx x bo s ‚ñÅtha la ‚ñÅvant ha ‚ñÅpo thum . . ‚ñÅvis ulu ‚ñÅpar akum le ‚ñÅthe ath re ‚ñÅle h . . ‚ñÅter ike ‚ñÅvid rom . . en ni kum ‚ñÅe ppa y um ‚ñÅtha la ‚ñÅmattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅhan ds ome ‚ñÅhu n k ‚ñÅke ri ‚ñÅva a ‚ñÅtha lai va a,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅje ‚ñÅ vo us ‚ñÅai me ‚ñÅbr avo ‚ñÅpo ur ‚ñÅcli p ‚ñÅde ‚ñÅmer de ‚ñÅqu e ‚ñÅj ‚ñÅ xxunk co u te ‚ñÅau ‚ñÅto il ette .,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ .,‚ñÅx x bo s ‚ñÅver a ‚ñÅle vel ‚ñÅb g m ‚ñÅ . . ‚ñÅse m ma ‚ñÅtra il er . ‚ñÅ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (31432 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅpun da ‚ñÅmath i ‚ñÅiru ku , e van ‚ñÅla ‚ñÅnadi kal anu ‚ñÅip a ‚ñÅyar u ‚ñÅwat ha ‚ñÅal u tha,‚ñÅx x bo s ‚ñÅsu riya ‚ñÅanna ‚ñÅmas s ‚ñÅne x t ‚ñÅc m ‚ñÅsu riya ‚ñÅanna,‚ñÅx x bo s ‚ñÅre al ly ‚ñÅse ma a ‚ñÅkar thi k ‚ñÅbr o . . ‚ñÅb g m ‚ñÅver a ‚ñÅle vel,‚ñÅx x bo s ‚ñÅki ya ‚ñÅye h ‚ñÅmo vi e ‚ñÅhi ndi ‚ñÅme ‚ñÅha i ‚ñÅ ?,‚ñÅx x bo s ‚ñÅ15 ‚ñÅmillion ‚ñÅvarum ‚ñÅnu ‚ñÅsol rav anga ‚ñÅmattum ‚ñÅ like ‚ñÅpann ung a\n",
              "y: CategoryList\n",
              "Offensive_Untargetede,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (7858 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅb g m ‚ñÅ asu su al ‚ñÅtheri kka ‚ñÅvit aru ‚ñÅsam ‚ñÅc s,‚ñÅx x bo s ‚ñÅpadi pa ‚ñÅmat um ‚ñÅedu th uki d ave ‚ñÅmudiyath u ‚ñÅchi d ambar am ‚ñÅenna ‚ñÅpadi cha ‚ñÅb . e xxunk,‚ñÅx x bo s ‚ñÅvellore ‚ñÅ mavatt am ‚ñÅvanni ya ‚ñÅkul a ‚ñÅk sa 3 n ‚ñÅmo vi e ‚ñÅvatt ri ‚ñÅpara ‚ñÅvayu th u kal,‚ñÅx x bo s ‚ñÅhi ndi ‚ñÅmai ‚ñÅk b ‚ñÅa aye ga ‚ñÅ2. 0 ‚ñÅka ‚ñÅtra il er,‚ñÅx x bo s ‚ñÅtha la ‚ñÅvant ha ‚ñÅpo thum . . ‚ñÅvis ulu ‚ñÅpar akum le ‚ñÅthe ath re ‚ñÅle h . . ‚ñÅter ike ‚ñÅvid rom . . en ni kum ‚ñÅe ppa y um ‚ñÅtha la ‚ñÅmattum tha . xxunk\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,not-Tamil,Not_offensive\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (4388 items)\n",
              "x: TextList\n",
              "‚ñÅx x bo s ‚ñÅhan ds ome ‚ñÅhu n k ‚ñÅke ri ‚ñÅva a ‚ñÅtha lai va a,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk,‚ñÅx x bo s ‚ñÅje ‚ñÅ vo us ‚ñÅai me ‚ñÅbr avo ‚ñÅpo ur ‚ñÅcli p ‚ñÅde ‚ñÅmer de ‚ñÅqu e ‚ñÅj ‚ñÅ xxunk co u te ‚ñÅau ‚ñÅto il ette .,‚ñÅx x bo s ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ5 ‚ñÅ . ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxunk ‚ñÅ xxrep ‚ñÅ4 ‚ñÅ .,‚ñÅx x bo s ‚ñÅver a ‚ñÅle vel ‚ñÅb g m ‚ñÅ . . ‚ñÅse m ma ‚ñÅtra il er . ‚ñÅ xxunk\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f739484f9d8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(8000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(8000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "sIpIH18TUsjB",
        "outputId": "0b7d577a-4cd0-4835-868d-9b1b32c12028"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "df_dict = {'query': list(tamil_dev['data']), 'actual_label': list(tamil_dev['label']), 'predicted_label': ['']*tamil_dev.shape[0]}\n",
        "all_nodes = list(set(tamil_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*tamil_dev.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "    \n",
        "df_result = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>actual_label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Handsome hunk  keri vaa thalaivaa</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.916551</td>\n",
              "      <td>0.00724097</td>\n",
              "      <td>0.00865</td>\n",
              "      <td>0.0110568</td>\n",
              "      <td>0.00214555</td>\n",
              "      <td>0.0543557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡Æ§‡ØÜ‡Æ©‡Øç‡Æï‡Ææ‡Æö‡Æø ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æ®‡Ææ‡Æü‡Ææ‡Æ∞‡Øç ‡Æö‡ÆÆ‡ØÅ‡Æ§‡Ææ‡ÆØ‡ÆÆ‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡Ææ‡Æ¥‡Øç...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.815139</td>\n",
              "      <td>0.0541358</td>\n",
              "      <td>0.0150543</td>\n",
              "      <td>0.084791</td>\n",
              "      <td>0.0080838</td>\n",
              "      <td>0.0227958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>je vous aime bravo pour clip de merde que j √©c...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.0453488</td>\n",
              "      <td>0.00458638</td>\n",
              "      <td>0.946284</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.00056139</td>\n",
              "      <td>0.00198686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡Æö‡Æø‡Æ±‡Æ™‡Øç‡Æ™‡ØÅ..... ‡ÆÆ‡Øá‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ©‡Øç‡Æ± ‡Æ™‡Æü‡Øà‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æø‡Æï ‡ÆÖ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.835185</td>\n",
              "      <td>0.0371791</td>\n",
              "      <td>0.00562095</td>\n",
              "      <td>0.100766</td>\n",
              "      <td>0.00728475</td>\n",
              "      <td>0.0139635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vera level BGM .. semma  trailer. ü§û</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.97987</td>\n",
              "      <td>0.0021728</td>\n",
              "      <td>0.000523575</td>\n",
              "      <td>0.0124726</td>\n",
              "      <td>0.00112337</td>\n",
              "      <td>0.00383817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... Offensive_Untargetede\n",
              "0                  Handsome hunk  keri vaa thalaivaa  ...             0.0543557\n",
              "1  ‡Æ§‡ØÜ‡Æ©‡Øç‡Æï‡Ææ‡Æö‡Æø ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æ®‡Ææ‡Æü‡Ææ‡Æ∞‡Øç ‡Æö‡ÆÆ‡ØÅ‡Æ§‡Ææ‡ÆØ‡ÆÆ‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡Ææ‡Æ¥‡Øç...  ...             0.0227958\n",
              "2  je vous aime bravo pour clip de merde que j √©c...  ...            0.00198686\n",
              "3  ‡Æö‡Æø‡Æ±‡Æ™‡Øç‡Æ™‡ØÅ..... ‡ÆÆ‡Øá‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ©‡Øç‡Æ± ‡Æ™‡Æü‡Øà‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æø‡Æï ‡ÆÖ...  ...             0.0139635\n",
              "4                Vera level BGM .. semma  trailer. ü§û  ...            0.00383817\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "8g-xmsqJFNwV",
        "outputId": "097a9b9f-3173-4746-c99c-132723ab9bbe"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "\n",
        "data_lm_2 = TextClasDataBunch.from_df(path='/content',train_df=X_train_df, valid_df=X_val_df,  test_df=tamil_test, tokenizer=tokenizer, vocab=taen_vocab,text_cols='text',label_cols=['label'])\n",
        "learn = text_classifier_learner(data_lm_2, arch=AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ta_en_fine_tuned_enc')\n",
        "learn.load('/content/models/ta_en_final')\n",
        "\n",
        "df_dict = {'query': list(tamil_test['text']), 'predicted_label': ['']*tamil_test.shape[0]}\n",
        "all_nodes = list(set(tamil_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*tamil_test.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "\n",
        "\n",
        "df_result_2 = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result_2.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result_2.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.12.2018 epo trailer pathutu irken ... Semay...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.933539</td>\n",
              "      <td>0.0125657</td>\n",
              "      <td>0.000161656</td>\n",
              "      <td>0.0142688</td>\n",
              "      <td>0.00379991</td>\n",
              "      <td>0.0356647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paka thana poro movie la Enna irukunu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.884475</td>\n",
              "      <td>0.00980871</td>\n",
              "      <td>0.000540717</td>\n",
              "      <td>0.0301754</td>\n",
              "      <td>0.00785153</td>\n",
              "      <td>0.0671488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‚ÄúU kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.108697</td>\n",
              "      <td>0.000490859</td>\n",
              "      <td>0.888975</td>\n",
              "      <td>0.000768708</td>\n",
              "      <td>0.000254336</td>\n",
              "      <td>0.000814123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suriya anna vera level anna mass</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.995826</td>\n",
              "      <td>0.0005907</td>\n",
              "      <td>0.00175378</td>\n",
              "      <td>0.000963272</td>\n",
              "      <td>0.000355577</td>\n",
              "      <td>0.000511215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
              "      <td>Offensive_Targeted_Insult_Individual</td>\n",
              "      <td>0.00735499</td>\n",
              "      <td>0.965543</td>\n",
              "      <td>6.06248e-06</td>\n",
              "      <td>0.0153884</td>\n",
              "      <td>0.00287892</td>\n",
              "      <td>0.00882823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... Offensive_Untargetede\n",
              "0  14.12.2018 epo trailer pathutu irken ... Semay...  ...             0.0356647\n",
              "1              Paka thana poro movie la Enna irukunu  ...             0.0671488\n",
              "2  ‚ÄúU kena tunggu lebih lama lagi untuk tahu saya...  ...           0.000814123\n",
              "3                   Suriya anna vera level anna mass  ...           0.000511215\n",
              "4  suma kaththaatha da sound over a pooda kudaath...  ...            0.00882823\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "PmKrv9bJUeF_",
        "outputId": "d5275dc9-9b3c-4e91-f413-ce0b49952774"
      },
      "source": [
        "df_result_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>not-Tamil</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.12.2018 epo trailer pathutu irken ... Semay...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.933539</td>\n",
              "      <td>0.0125657</td>\n",
              "      <td>0.000161656</td>\n",
              "      <td>0.0142688</td>\n",
              "      <td>0.00379991</td>\n",
              "      <td>0.0356647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Paka thana poro movie la Enna irukunu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.884475</td>\n",
              "      <td>0.00980871</td>\n",
              "      <td>0.000540717</td>\n",
              "      <td>0.0301754</td>\n",
              "      <td>0.00785153</td>\n",
              "      <td>0.0671488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‚ÄúU kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.108697</td>\n",
              "      <td>0.000490859</td>\n",
              "      <td>0.888975</td>\n",
              "      <td>0.000768708</td>\n",
              "      <td>0.000254336</td>\n",
              "      <td>0.000814123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suriya anna vera level anna mass</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.995826</td>\n",
              "      <td>0.0005907</td>\n",
              "      <td>0.00175378</td>\n",
              "      <td>0.000963272</td>\n",
              "      <td>0.000355577</td>\n",
              "      <td>0.000511215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
              "      <td>Offensive_Targeted_Insult_Individual</td>\n",
              "      <td>0.00735499</td>\n",
              "      <td>0.965543</td>\n",
              "      <td>6.06248e-06</td>\n",
              "      <td>0.0153884</td>\n",
              "      <td>0.00287892</td>\n",
              "      <td>0.00882823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4387</th>\n",
              "      <td>‡ÆÆ‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ™‡Øä‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æí‡Æ©‡Øç‡Æ©‡ØÅ ‡ÆÖ‡Æ§‡ØÅ‡Æ≤ ‡Æé‡Æµ‡Æ©‡Øç ‡Æï‡Øà‡ÆØ ‡Æµ‡Æö‡Øç‡Æö...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.804067</td>\n",
              "      <td>0.0462996</td>\n",
              "      <td>0.00572953</td>\n",
              "      <td>0.122385</td>\n",
              "      <td>0.00809177</td>\n",
              "      <td>0.0134272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4388</th>\n",
              "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>0.00732125</td>\n",
              "      <td>0.000576099</td>\n",
              "      <td>0.991246</td>\n",
              "      <td>0.000474777</td>\n",
              "      <td>0.000115585</td>\n",
              "      <td>0.000266283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4389</th>\n",
              "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.455658</td>\n",
              "      <td>0.0601226</td>\n",
              "      <td>0.0147018</td>\n",
              "      <td>0.139337</td>\n",
              "      <td>0.0395907</td>\n",
              "      <td>0.290589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4390</th>\n",
              "      <td>Vijay's all movies look like same.</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.814768</td>\n",
              "      <td>0.104247</td>\n",
              "      <td>0.00771375</td>\n",
              "      <td>0.0489836</td>\n",
              "      <td>0.0128513</td>\n",
              "      <td>0.0114361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4391</th>\n",
              "      <td>Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...</td>\n",
              "      <td>Offensive_Untargetede</td>\n",
              "      <td>0.148166</td>\n",
              "      <td>0.0568848</td>\n",
              "      <td>0.00879186</td>\n",
              "      <td>0.256198</td>\n",
              "      <td>0.0474622</td>\n",
              "      <td>0.482497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4392 rows √ó 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  query  ... Offensive_Untargetede\n",
              "0     14.12.2018 epo trailer pathutu irken ... Semay...  ...             0.0356647\n",
              "1                 Paka thana poro movie la Enna irukunu  ...             0.0671488\n",
              "2     ‚ÄúU kena tunggu lebih lama lagi untuk tahu saya...  ...           0.000814123\n",
              "3                      Suriya anna vera level anna mass  ...           0.000511215\n",
              "4     suma kaththaatha da sound over a pooda kudaath...  ...            0.00882823\n",
              "...                                                 ...  ...                   ...\n",
              "4387  ‡ÆÆ‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ™‡Øä‡Æ£‡Øç‡Æ£‡ØÅ ‡Æ∞‡ØÜ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øá ‡Æí‡Æ©‡Øç‡Æ©‡ØÅ ‡ÆÖ‡Æ§‡ØÅ‡Æ≤ ‡Æé‡Æµ‡Æ©‡Øç ‡Æï‡Øà‡ÆØ ‡Æµ‡Æö‡Øç‡Æö...  ...             0.0134272\n",
              "4388  Babu mele ko ye song sunke kuch yesa feel hua ...  ...           0.000266283\n",
              "4389  asuran= aadukalam+pudupettai+ wada chennai..ye...  ...              0.290589\n",
              "4390                 Vijay's all movies look like same.  ...             0.0114361\n",
              "4391  Eh Idhu 96, yaara emathuringa.. Bangam ji Bang...  ...              0.482497\n",
              "\n",
              "[4392 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZcSRFY-UsjB",
        "outputId": "dd99bec3-569b-46a0-c685-3a1bf7527b57"
      },
      "source": [
        "accuracy_score(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7766636280765725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahTaia5JUsjC",
        "outputId": "09c5cccd-221c-4d63-82a0-b568238e1974"
      },
      "source": [
        "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4116986942218667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjK2zdm6UsjC",
        "outputId": "21f8d292-760a-426b-9107-8a0a89718009"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(df_result['actual_label'], df_result['predicted_label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "                       Not_offensive       0.81      0.96      0.88      3193\n",
            "     Offensive_Targeted_Insult_Group       0.41      0.13      0.20       295\n",
            "Offensive_Targeted_Insult_Individual       0.52      0.26      0.35       307\n",
            "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
            "               Offensive_Untargetede       0.46      0.25      0.32       356\n",
            "                           not-Tamil       0.86      0.70      0.77       172\n",
            "\n",
            "                            accuracy                           0.78      4388\n",
            "                           macro avg       0.51      0.38      0.42      4388\n",
            "                        weighted avg       0.72      0.78      0.73      4388\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeZfZzfOUsjC"
      },
      "source": [
        "df_result.to_excel('taen_ml.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAtMXIzNUr1w"
      },
      "source": [
        "df_result_2.to_excel('taen_ml_test_preds.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf0han8CrxD8"
      },
      "source": [
        "# precision    recall  f1-score   support\n",
        "\n",
        "#                        Not_offensive       0.81      0.96      0.88      3193\n",
        "#      Offensive_Targeted_Insult_Group       0.41      0.13      0.20       295\n",
        "# Offensive_Targeted_Insult_Individual       0.52      0.26      0.35       307\n",
        "#      Offensive_Targeted_Insult_Other       0.00      0.00      0.00        65\n",
        "#                Offensive_Untargetede       0.46      0.25      0.32       356\n",
        "#                            not-Tamil       0.86      0.70      0.77       172\n",
        "\n",
        "#                             accuracy                           0.78      4388\n",
        "#                            macro avg       0.51      0.38      0.42      4388\n",
        "#                         weighted avg       0.72      0.78      0.73      4388"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0o1O5K-fPTv"
      },
      "source": [
        "!mv '/content/models' '/content/drive/MyDrive/AggressionNLP/TamilEnglishResults'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}