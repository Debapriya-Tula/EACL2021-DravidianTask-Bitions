{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kannada_PseudoLabelling AggressionNLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeOfcNmWoXVX"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmVdECMZhXM5"
      },
      "source": [
        "cols=['data','label','index']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyIq8yVorLSn"
      },
      "source": [
        "# Kannada data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXGbeChFqWc5"
      },
      "source": [
        "kannada_train = pd.read_csv('/content/drive/MyDrive/kannada_offensive_train.csv',sep='\\t',names=cols)\n",
        "kannada_dev= pd.read_csv('/content/drive/MyDrive/kannada_offensive_dev.csv',sep='\\t',names=cols)\n",
        "kannada_test = pd.read_csv('/content/drive/MyDrive/kannada_offensive_test.csv',sep='\\t',names=['data'])\n",
        "kannada_train = kannada_train[['data','label']]\n",
        "kannada_dev = kannada_dev[['data','label']]\n",
        "kannada_test = kannada_test[['data']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcktB08pquQV",
        "outputId": "d9e6ed69-127f-4e8f-9144-f9e649beeb5c"
      },
      "source": [
        "kannada_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tik tok alli jagala madtidralla adra baggenu o...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anyone from kerala here</td>\n",
              "      <td>not-Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie rerelease madi plss</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amazon prime alli bittidira....yella manele no...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Guru sure news nanu tik tok dawn lod madeda ya...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data          label\n",
              "0  Tik tok alli jagala madtidralla adra baggenu o...  Not_offensive\n",
              "1                            Anyone from kerala here    not-Kannada\n",
              "2                          Movie rerelease madi plss  Not_offensive\n",
              "3  Amazon prime alli bittidira....yella manele no...  Not_offensive\n",
              "4  Guru sure news nanu tik tok dawn lod madeda ya...  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR7FQUZgq8TJ",
        "outputId": "237d474c-fb62-4b80-c845-25b225bcfbca"
      },
      "source": [
        "kannada_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6217 entries, 0 to 6216\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   data    6217 non-null   object\n",
            " 1   label   6217 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 97.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-IXQZ3kq-M-",
        "outputId": "41463cc1-9ac5-47fb-d7e5-0127a2e546e2"
      },
      "source": [
        "print(len(kannada_train))\n",
        "kannada_train = kannada_train.drop_duplicates()\n",
        "print(len(kannada_train))\n",
        "kannada_train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6217\n",
            "5936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Not_offensive                           3382\n",
              "not-Kannada                             1407\n",
              "Offensive_Targeted_Insult_Individual     486\n",
              "Offensive_Targeted_Insult_Group          327\n",
              "Offensive_Untargetede                    212\n",
              "Offensive_Targeted_Insult_Other          122\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sydvTcZ7rAzc",
        "outputId": "6d15faad-1458-4321-e247-9e194cb73cfb"
      },
      "source": [
        "kannada_train['token_length'] = [len(x.split(\" \")) for x in kannada_train.data]\n",
        "print(max(kannada_train.token_length))\n",
        "print(min(kannada_train.token_length))\n",
        "print(sum(kannada_train.token_length)/len(kannada_train.token_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n",
            "1\n",
            "8.141677897574125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSCgUvtCuENc"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XElKehJjrGiz",
        "outputId": "709a00f8-10d9-4013-d7b5-9ce62eb228cf"
      },
      "source": [
        "!pip install indic-nlp-library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.19.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Installing collected packages: morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ctdevt8AzIl",
        "outputId": "d2e574d2-1726-4124-87c2-25dc47ac9a7e"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 41.40 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSE_pcYviHoc"
      },
      "source": [
        "INDIC_NLP_RESOURCES=r\"/content/indic_nlp_resources\"\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkKukZJkBaIF"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHCiLp9r9Oay"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YneaCz4whVT0",
        "outputId": "66305f8a-8919-41ed-943a-e11f44a5f3a2"
      },
      "source": [
        "mal_lines = []\n",
        "for i in mal_train['data']:\n",
        "  mal_lines.append(i)\n",
        "len(mal_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2k0-lmBuIFG"
      },
      "source": [
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "\n",
        "# input_text=\"‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç. ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‡¥∞‡¥æ‡¥ú‡¥µ‡¥Ø‡¥§‡µç ‡¥Ö‡¥≤‡µç‡¥≤\"\n",
        "# remove_nuktas=False\n",
        "factory=IndicNormalizerFactory()\n",
        "normalizer=factory.get_normalizer(\"ml\")\n",
        "\n",
        "# %%time\n",
        "nor_mal_lines = []\n",
        "for i in range(len(mal_lines)):\n",
        "  nor_mal_line = normalizer.normalize(mal_lines[i])\n",
        "  nor_mal_lines.append(nor_mal_line)\n",
        "# new_mal_lines "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDZWW-d8uqmD",
        "outputId": "1887b1ed-3051-49b6-ab4f-de37e3ab6225"
      },
      "source": [
        "len(nor_mal_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1TWLIlU-6lM"
      },
      "source": [
        "Tokenization word level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL5h8qy52UUD"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "tokenized_mal_lines = []\n",
        "for i in range(len(mal_lines)):\n",
        "  tokenized_mal_line = indic_tokenize.trivial_tokenize(nor_mal_lines[i])\n",
        "  tokenized_mal_lines.append(tokenized_mal_line)\n",
        "# tokenized_mal_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkotkbN75aTV",
        "outputId": "1a37fe4b-e5ac-469b-fe61-971b335652f5"
      },
      "source": [
        "tokenized_mal_lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " 'Royal',\n",
              " 'Mech',\n",
              " '‡¥Ü‡¥ü‡¥æ',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥Æ‡µÄ‡¥∂',\n",
              " '‡¥™‡¥ø‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®',\n",
              " '‡¥Ü‡¥∞‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " '‡¥Ü‡¥£‡µç‡¥ü',\n",
              " '‡¥û‡¥æ‡µª',\n",
              " 'royal',\n",
              " 'Mech',\n",
              " '‡¥Ü‡¥ü‡¥æ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTZdMa7S7THG",
        "outputId": "a39f356a-000d-4191-994e-9e4e5621cb78"
      },
      "source": [
        "mal_lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥§‡¥≤‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥ï‡¥æ‡¥£‡¥æ ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª Royal Mech ‡¥Ü‡¥ü‡¥æ  ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥Æ‡µÄ‡¥∂ ‡¥™‡¥ø‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥® ‡¥Ü‡¥∞‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª ‡¥Ü‡¥£‡µç‡¥ü ‡¥û‡¥æ‡µª royal Mech ‡¥Ü‡¥ü‡¥æ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNJ589jE_3l4",
        "outputId": "f039dd7a-656c-4dfa-9847-3a1f2ba68df3"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "transliterated_mal_lines = []\n",
        "flags=[]\n",
        "for i in range(len(mal_lines)):\n",
        "  transliterated_mal_line = ItransTransliterator.from_itrans(mal_lines[i],'ml')\n",
        "  if(transliterated_mal_line == mal_lines[i]):\n",
        "    flag=1\n",
        "  else:\n",
        "    flag=0\n",
        "  flags.append(flag)\n",
        "  transliterated_mal_lines.append(transliterated_mal_line)\n",
        "transliterated_mal_lines[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¥™‡¥≤‡¥¶‡µá‡¥∂‡¥Ç\\u0d64 ‡¥™‡¥≤ ‡¥≠‡¥æ‡¥∑ ‡¥í‡¥∞‡µá ‡¥í‡¥∞‡µÅ ‡¥∞‡¥æ‡¥ú‡¥æ‡¥µ‡µç  ‡¥Ö‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µÜ  ‡¥∏‡µç‡¥µ‡¥®‡µç‡¥§‡¥Ç ‡¥∞‡¥æ‡¥ú‡¥µ‡¥Ø‡¥§‡µç ‡¥Ö‡¥≤‡µç‡¥≤'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4i9ECuUAa0r",
        "outputId": "eada95f8-3050-46b1-a69b-f2128fb86eec"
      },
      "source": [
        "print('native malayalam sentences: ',sum(flags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "native malayalam sentences:  1298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3GVT_UHDUX3",
        "outputId": "8453beba-0d43-4803-be4c-7aae3588ba4e"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "en_transliterated_mal_lines = []\n",
        "flags=[]\n",
        "for i in range(len(mal_lines)):\n",
        "  en_transliterated_mal_line = ItransTransliterator.to_itrans(mal_lines[i],'ml')\n",
        "  if(en_transliterated_mal_line == mal_lines[i]):\n",
        "    flag=1\n",
        "  else:\n",
        "    flag=0\n",
        "  flags.append(flag)\n",
        "  en_transliterated_mal_lines.append(en_transliterated_mal_line)\n",
        "en_transliterated_mal_lines[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'paladesha.m. pala bhaaSha .ore .oru raajaav  allaat.e  svanta.m raajavayat alla'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whg64WtK3QP",
        "outputId": "a3871dcc-26ab-408d-d665-53e4c41dab02"
      },
      "source": [
        "whole_mal_train = ''\n",
        "for i in range(len(mal_lines)):\n",
        "  whole_mal_train+=str(mal_lines[i])\n",
        "len(whole_mal_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "793979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdZR_pY4Mh5F",
        "outputId": "b191c2d1-4ba6-4513-b370-d8d0acd53229"
      },
      "source": [
        "from indicnlp.langinfo import *\n",
        "\n",
        "lang='ml'\n",
        "vowels = 0\n",
        "for i in range(len(whole_mal_train)):\n",
        "  if(is_vowel(whole_mal_train[i],lang)):\n",
        "    vowels+=1\n",
        "print('Total characters: ',len(whole_mal_train))\n",
        "print('Total vowels: ',vowels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters:  793979\n",
            "Total vowels:  12759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCQ3EF3lrxkE"
      },
      "source": [
        "#ULMFiT Kannada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CwAFQDCrxkF",
        "outputId": "46772537-5c5e-4c74-fac8-d7b8f5337387"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2MB 8.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTPh-_tbrxkG"
      },
      "source": [
        "#reference: https://github.com/goru001/nlp-for-malyalam/blob/master/classification/Malyalam_Classification_Model.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v44aAWj7rxkH"
      },
      "source": [
        "from fastai.text import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq0LyzXjrxkH",
        "outputId": "bd280497-b576-4c32-eb40-af3080ecca67"
      },
      "source": [
        "import fastai, torch\n",
        "fastai.__version__ , torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.0.61', '1.7.0+cu101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lj52oxIrxkH"
      },
      "source": [
        "class KannadaTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lang:str):\n",
        "        self.lang = lang\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.Load(str('/content/drive/MyDrive/AggressionNLP/Kannada/Tokenizer/kannada_lm.model'))\n",
        "        \n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        return self.sp.EncodeAsPieces(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkpDlLB0rxkI"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(str('/content/drive/MyDrive/AggressionNLP/Kannada/Tokenizer/kannada_lm.model'))\n",
        "itos = [sp.IdToPiece(int(i)) for i in range(25000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtNC75cirxkI"
      },
      "source": [
        "# 25,000 is the vocab size that we chose in sentencepiece\n",
        "kannada_vocab = Vocab(itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLd-yj8vrxkI"
      },
      "source": [
        "tokenizer = Tokenizer(tok_func=KannadaTokenizer, lang='kn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPNa91ABrxkJ",
        "outputId": "e2ce78f0-2b3c-4c87-cbed-baa317835263"
      },
      "source": [
        "tokenizer.special_cases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqXZ4yfSrxkJ"
      },
      "source": [
        "label_cols = ['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Mx6pnkoYqxd",
        "outputId": "3e7bbbae-9630-47fb-f2d3-11e6376630da"
      },
      "source": [
        "\n",
        "\n",
        "df_result_2['data']=df_result_2['query']\n",
        "df_result_2['label']=df_result_2['predicted_label']\n",
        "\n",
        "kannada_train_new = pd.concat([kannada_train,df_result_2])\n",
        "kannada_train_new\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>token_length</th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>not-Kannada</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tik tok alli jagala madtidralla adra baggenu o...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anyone from kerala here</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Movie rerelease madi plss</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amazon prime alli bittidira....yella manele no...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Guru sure news nanu tik tok dawn lod madeda ya...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>Startup start maadalu capacity growth maadalu ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Startup start maadalu capacity growth maadalu ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.915989</td>\n",
              "      <td>0.0248174</td>\n",
              "      <td>0.0154094</td>\n",
              "      <td>0.0268336</td>\n",
              "      <td>0.00839248</td>\n",
              "      <td>0.00855798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>Rashmika idanna nodi thi*a urkimbekuü§£ü§£ü§£ü§£ü§£</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rashmika idanna nodi thi*a urkimbekuü§£ü§£ü§£ü§£ü§£</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.533111</td>\n",
              "      <td>0.0660914</td>\n",
              "      <td>0.00268117</td>\n",
              "      <td>0.117238</td>\n",
              "      <td>0.223934</td>\n",
              "      <td>0.0569445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>I love you sir</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I love you sir</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>0.151654</td>\n",
              "      <td>0.000889215</td>\n",
              "      <td>0.83936</td>\n",
              "      <td>0.000788491</td>\n",
              "      <td>0.00710054</td>\n",
              "      <td>0.000207254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>‡≤®‡≥ã‡≤°‡≥ç‡≤§‡≤æ ‡≤π‡≥ã‡≤¶‡≥ç‡≤∞‡≥Ü ‡≤∏‡≤æ‡≤µ‡≤ø‡≤∞‡≤æ‡≤∞‡≥Å lyrical video ‡≤ó‡≤≥‡≥Å</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>‡≤®‡≥ã‡≤°‡≥ç‡≤§‡≤æ ‡≤π‡≥ã‡≤¶‡≥ç‡≤∞‡≥Ü ‡≤∏‡≤æ‡≤µ‡≤ø‡≤∞‡≤æ‡≤∞‡≥Å lyrical video ‡≤ó‡≤≥‡≥Å</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.789148</td>\n",
              "      <td>0.0331043</td>\n",
              "      <td>0.151223</td>\n",
              "      <td>0.0206078</td>\n",
              "      <td>0.000419387</td>\n",
              "      <td>0.00549806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>‡≤∏‡≤ñ‡≤§‡≥ç ‡≤ü‡≥ç‡≤∞‡≥ã‡≤≤‡≥ç ‡≤¨‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç n‡≤¨‡≥ç‡≤∞‡≥Ü‡≥Ç ‡≤à ‡≤ó‡≥á‡≤Æ‡≥ç ‡≤®‡≥á‡≤Æ‡≥ç ‡≤π‡≥á‡≤≥‡≤ø</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>‡≤∏‡≤ñ‡≤§‡≥ç ‡≤ü‡≥ç‡≤∞‡≥ã‡≤≤‡≥ç ‡≤¨‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç n‡≤¨‡≥ç‡≤∞‡≥Ü‡≥Ç ‡≤à ‡≤ó‡≥á‡≤Æ‡≥ç ‡≤®‡≥á‡≤Æ‡≥ç ‡≤π‡≥á‡≤≥‡≤ø</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.852518</td>\n",
              "      <td>0.0916762</td>\n",
              "      <td>4.04558e-05</td>\n",
              "      <td>0.0219246</td>\n",
              "      <td>0.00807388</td>\n",
              "      <td>0.0257665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6714 rows √ó 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  data  ... Offensive_Targeted_Insult_Other\n",
              "0    Tik tok alli jagala madtidralla adra baggenu o...  ...                             NaN\n",
              "1                              Anyone from kerala here  ...                             NaN\n",
              "2                            Movie rerelease madi plss  ...                             NaN\n",
              "3    Amazon prime alli bittidira....yella manele no...  ...                             NaN\n",
              "4    Guru sure news nanu tik tok dawn lod madeda ya...  ...                             NaN\n",
              "..                                                 ...  ...                             ...\n",
              "773  Startup start maadalu capacity growth maadalu ...  ...                      0.00855798\n",
              "774          Rashmika idanna nodi thi*a urkimbekuü§£ü§£ü§£ü§£ü§£  ...                       0.0569445\n",
              "775                                     I love you sir  ...                     0.000207254\n",
              "776           ‡≤®‡≥ã‡≤°‡≥ç‡≤§‡≤æ ‡≤π‡≥ã‡≤¶‡≥ç‡≤∞‡≥Ü ‡≤∏‡≤æ‡≤µ‡≤ø‡≤∞‡≤æ‡≤∞‡≥Å lyrical video ‡≤ó‡≤≥‡≥Å  ...                      0.00549806\n",
              "777         ‡≤∏‡≤ñ‡≤§‡≥ç ‡≤ü‡≥ç‡≤∞‡≥ã‡≤≤‡≥ç ‡≤¨‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç n‡≤¨‡≥ç‡≤∞‡≥Ü‡≥Ç ‡≤à ‡≤ó‡≥á‡≤Æ‡≥ç ‡≤®‡≥á‡≤Æ‡≥ç ‡≤π‡≥á‡≤≥‡≤ø  ...                       0.0257665\n",
              "\n",
              "[6714 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AOGwiDArxkJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(kannada_train_new['data'],kannada_train_new['label'], test_size = 0.2, random_state = 42, stratify=kannada_train_new['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6ositxrxkJ",
        "outputId": "43683163-ec7f-4ab8-de4c-f9b2271746e8"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769        Ultimate Guru tik tok ‡≤Ö‡≤µ‡≤∞ ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‡≤®‡≥á ‡≤π‡≥á‡≤≥‡≥ç‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü‡≥Ü\n",
              "307                            Benki bindangide rasmikage\n",
              "668                             Kesari prasad Jois b f by\n",
              "5183                                 Looks very different\n",
              "2982      Rashmika fans  ND devarkonda fans urkondirtarea\n",
              "                              ...                        \n",
              "4021    @Shreenivas K wrang misteek maadtidya.... kurk...\n",
              "5993    Yake jana ogtila andre bec of telegram app bec...\n",
              "4507                        Great work bro....nKeep it up\n",
              "3351               KEERTHAN KUMAR ‡≤Ö‡≤¶‡≥Å ‡≤í‡≤Ç‡≤¶‡≥ç ‡≤™‡≤¶ ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤®‡≥ã‡≤°‡≥Å\n",
              "6053    @VARAPRASAD K K nin Amman thulle shaata bekaad...\n",
              "Name: data, Length: 5371, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOAo7B6PrxkK"
      },
      "source": [
        "X_train_df = pd.concat([X_train, y_train], axis=1, keys=['text', 'label'])\n",
        "X_val_df = pd.concat([X_val, y_val], axis=1, keys=['text', 'label'])\n",
        "X_test_df = pd.concat([kannada_dev['data'], kannada_dev['label']], axis=1, keys=['text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY7wbhWPrxkK"
      },
      "source": [
        "# X_train_df['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "DGOIAuvMrxkK",
        "outputId": "34c49abd-e6f8-4509-bec0-e41e82fa16cb"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=kannada_vocab,text_cols='text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "yNXP-4vDrxkK",
        "outputId": "3e80f073-0f14-48a6-c587-51585e9c5d4a"
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>fer ent ‚ñÅx x b os &lt;unk&gt; ‚ñÅr ash mi ka ‚ñÅf ans &lt;unk&gt; ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a ‚ñÅx x b os ‚ñÅ‡≤π‡≥å‡≤¶‡≥Å ‚ñÅ‡≤∏‡≤∞‡≥ç ‚ñÅ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤§‡≥ç‡≤• ‡≤æ ‡≤Æ ‚ñÅ‡≤á‡≤®‡≥ç‡≤®‡≥Ç ‚ñÅ‡≤¨‡≤¶‡≥Å‡≤ï ‡≤ø‡≤¶‡≥ç‡≤¶‡≤æ‡≤®‡≥Ü ‚ñÅx x b os ‚ñÅ‡≤®‡≤Æ‡≥ç‡≤Æ ‡≤¶‡≥á‡≤∂ ‚ñÅ‡≤¶ ‚ñÅ‡≤ï‡≤§‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‡≥Ü ‚ñÅ‡≤ï‡≤£ ‡≥ã ‡≤™‡≥ç‡≤™ ‚ñÅx x b os ‚ñÅ &lt;unk&gt; v en ki &lt;unk&gt; &lt;unk&gt; d v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>‚ñÅ‡≤Æ‡≤æ‡≤§‡≥ç‡≤∞ . . . ‚ñÅ‡≤π‡≥Å ‡≤∂‡≤æ ‡≤∞‡≥ç . . ‚ñÅ‡≤¨‡≤æ ‡≤∞‡≥ã . . ‚ñÅd um ‚ñÅ‡≤á ‡≤¶‡≥ç‡≤∞‡≥Ü ‚ñÅ‡≤Æ‡≥Ü ‡≤ú‡≥Ü ‡≤∏‡≥ç‡≤ü‡≤ø‡≤ï‡≥ç ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅ‡≤π ‡≤§‡≥ç‡≤∞‡≤æ ‚ñÅ‡≤§‡≥Å ‡≤≤‡≥ç‡≤≤ ‡≤∞‡≥Ü ‚ñÅ ‡≤¶‡≥Ü ‡≤Ç‡≤ó‡≥ç ‡≤§‡≤ø ‡≤®‡≤ø ‚ñÅ‡≤Ö‡≤∑‡≥ç‡≤ü‡≥á ‚ñÅ‡≤Æ‡≤ó ‡≤®‡≥á ‚ñÅ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‚ñÅ‡≤Ö ‡≤µ‡≥ç‡≤µ ‚ñÅ‡≤π‡≤æ ‡≤¶ ‡≤∞‡≤ó‡≤ø ‡≤§‡≥ç‡≤§‡≤ø ‚ñÅx x b os &lt;unk&gt; ‚ñÅd ub b &lt;unk&gt; ‚ñÅf ull ‚ñÅm ov ie ‚ñÅin ‚ñÅ te lu gu ‚ñÅx x b os</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>&lt;unk&gt; ‚ñÅs ry ‚ñÅb ro ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅ‡≤•‡≤ø‡≤Ø‡≥á‡≤ü‡≤∞‡≥ç ‚ñÅ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤®‡≥ã‡≤° ‡≥ã ‡≤ï‡≥Ü ‚ñÅ‡≤ï‡≤∞‡≥ã ‡≤® ‚ñÅ‡≤é ‡≤´‡≥Ü ‡≤ï‡≥ç‡≤ü‡≥ç ‚ñÅ‡≤ï‡≥ä‡≤° ‡≥ç ‡≤§‡≤æ ‚ñÅ‡≤á‡≤¶‡≥Ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅp l &lt;unk&gt; ‚ñÅ‡≤°‡≥à‡≤∞‡≥Ü‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç ‚ñÅ‡≤¨‡≥ç‡≤Ø‡≤æ‡≤Ç‡≤ï‡≥ç ‚ñÅ‡≤Ö ‡≤ï‡≥å ‡≤Ç‡≤ü‡≥ç ‚ñÅ‡≤®‡≤Ç‡≤¨‡≤∞‡≥ç ‚ñÅ‡≤ï‡≥ä‡≤° ‡≤ø ‚ñÅ‡≤® ‡≤®‡≥ç ‚ñÅ‡≤ü‡≤ø‡≤ï‡≥Ü‡≤ü‡≥ç ‚ñÅ‡≤¶‡≥Å ‡≤°‡≥ç ‚ñÅ‡≤π‡≤æ‡≤ï ‡≥ç‡≤§‡≤ø ‡≤®‡≤ø ‚ñÅx x b os &lt;unk&gt; ‚ñÅc ur i ous ity ‚ñÅ thumb a ‚ñÅ &lt;unk&gt; a ast hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>‚ñÅ7 ‚ñÅ . &lt;unk&gt; vi ch and ran ‚ñÅ av ra ‚ñÅa a ‚ñÅ ha ad ug ala ‚ñÅh ab ba ‚ñÅn en apa y it u ‚ñÅx x re p ‚ñÅ5 ‚ñÅ . &lt;unk&gt; ‚ñÅb l ock b us ter ‚ñÅ &lt;unk&gt; as n ‚ñÅx x b os ‚ñÅ‡≤°‡≤ø ‚ñÅ‡≤¨‡≤æ‡≤∏‡≥ç ‚ñÅ‡≤Ö‡≤≠‡≤ø‡≤Æ‡≤æ‡≤®‡≤ø ‡≤ó‡≤≥ ‚ñÅ‡≤ï‡≤°‡≥Ü‡≤Ø‡≤ø‡≤Ç‡≤¶ ‚ñÅall ‚ñÅthe ‚ñÅbe st ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅx x b os ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>b os ‚ñÅma y &lt;unk&gt; ‚ñÅg od ‚ñÅb less ‚ñÅyou &lt;unk&gt; ‚ñÅs han kar ‚ñÅx x b os &lt;unk&gt; ‚ñÅn ay an appa ' s ‚ñÅ book ‚ñÅ? ? ‚ñÅx x b os ‚ñÅ &lt;unk&gt; a n il &lt;unk&gt; ‚ñÅa ‚ñÅ hu ‚ñÅ ni am man ‚ñÅk al s k o du ‚ñÅ ke y du ‚ñÅk ol ve ‚ñÅ ba a vi ‚ñÅma di ‚ñÅk al s thi ni</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPCPREe5xZ6b"
      },
      "source": [
        "awd_lstm_config = awd_lstm_lm_config.copy()\n",
        "awd_lstm_config['n_hid'] = 1150\n",
        "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, config=awd_lstm_config, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV_gON-MrxkL"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel/models.zip' -d '/content/drive/MyDrive/AggressionNLP/TamilPretrainedLanguageModel'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqPWbg05rxkL",
        "outputId": "e4629a7f-a01e-4dca-bb70-8fdb488a5169"
      },
      "source": [
        "# Loading the pretrained language model on kannada wikipedia\n",
        "learn.load('/content/drive/MyDrive/AggressionNLP/Kannada/Pretrained Language Model /ULMFiT/third_kn_lm', with_opt=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (5371 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x b os <unk> <unk> l t im ate <unk> ru ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤µ‡≤∞ ‚ñÅ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‚ñÅ‡≤®‡≥á ‚ñÅ‡≤π‡≥á‡≤≥ ‡≥ç ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‡≥Ü,‚ñÅx x b os <unk> ‚ñÅb en ki ‚ñÅb ind ang ide ‚ñÅ ras mi k age,‚ñÅx x b os <unk> ‚ñÅk es ari ‚ñÅp ras ad <unk> <unk> o is ‚ñÅb ‚ñÅf ‚ñÅby,‚ñÅx x b os <unk> ‚ñÅl o ok s ‚ñÅvery ‚ñÅd if fer ent,‚ñÅx x b os <unk> ‚ñÅr ash mi ka ‚ñÅf ans <unk> ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (1343 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x b os ‚ñÅ‡≤Ö‡≤™‡≥ç‡≤™‡≤ü ‚ñÅ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚ñÅ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‚ñÅ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç,‚ñÅx x b os ‚ñÅ‡≤®‡≤®‡≤ó‡≥Ü ‚ñÅ‡≤Æ‡≤π‡≤æ‡≤≠‡≤æ‡≤∞‡≤§ ‚ñÅ‡≤Ö‡≤Ç‡≤¶‡≤∞‡≥Ü ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤®‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn ‡≤Æ‡≤π‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤¨‡≤∞‡≥Å‡≤µ ‚ñÅ‡≤™‡≤æ‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å,‚ñÅx x b os <unk> ‚ñÅt og ari ‚ñÅt ip pa ‚ñÅ ke li ‚ñÅt um ba ‚ñÅs ant os h ‚ñÅ ay it a ‚ñÅm att e ‚ñÅ old ‚ñÅis ‚ñÅg old ‚ñÅ ant ar all l ‚ñÅa du ‚ñÅ ni <unk> a ‚ñÅ ay it a,‚ñÅx x b os <unk> ‚ñÅw hy ‚ñÅonly ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤®‡≥ç‡≤® ‡≥ã ‚ñÅ‡≤§‡≥Å ‡≤ï‡≤æ ‡≤≤‡≤ø ‚ñÅ‡≤® ‚ñÅ‡≤ö‡≥à‡≤®‡≤æ ‚ñÅ‡≤ó‡≥Ü ‚ñÅ‡≤ï‡≤≥‡≤ø‡≤∏ ‡≤ø ‚ñÅ‡≤Ö ‡≤µ‡≥ç ‡≤≥‡≥Å ‚ñÅ‡≤ï‡≥Ç‡≤° ‚ñÅ‡≤ö‡≥à‡≤®‡≥Ä‡≤∏‡≥ç ‚ñÅ ‡≤¨‡≥ç‡≤∞‡≥Ä‡≤°‡≥ç ‚ñÅ‡≤á ‡≤∞‡≥ç ‡≤¨‡≥á‡≤ï‡≥Å,‚ñÅx x b os <unk> <unk> ‚ñÅmy ‚ñÅgo d ‚ñÅ su per o ‚ñÅ su per\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (777 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x b os ‚ñÅ100 ‚ñÅ da ys ‚ñÅp ak ka,‚ñÅx x b os <unk> per ‚ñÅs ir,‚ñÅx x b os <unk> ‚ñÅh and s ‚ñÅup,‚ñÅx x b os <unk> ‚ñÅs ari ‚ñÅn iv u ‚ñÅv ide o ‚ñÅ na ‚ñÅ ro ast ‚ñÅma di ‚ñÅ ad re ‚ñÅm ad va ga ‚ñÅp ub g ‚ñÅat ava ‚ñÅf re e ‚ñÅf ire ‚ñÅg ame s ‚ñÅh ak ond o ‚ñÅm ad be di ‚ñÅa ‚ñÅg ame s ‚ñÅk ood a <unk>,‚ñÅx x b os <unk> ‚ñÅk r ish ana ‚ñÅsh apa ‚ñÅt att el ee be k u\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(25000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1150, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1150, 1150, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1150, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2b32bca620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (5371 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x b os <unk> <unk> l t im ate <unk> ru ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤µ‡≤∞ ‚ñÅ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‚ñÅ‡≤®‡≥á ‚ñÅ‡≤π‡≥á‡≤≥ ‡≥ç ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‡≥Ü,‚ñÅx x b os <unk> ‚ñÅb en ki ‚ñÅb ind ang ide ‚ñÅ ras mi k age,‚ñÅx x b os <unk> ‚ñÅk es ari ‚ñÅp ras ad <unk> <unk> o is ‚ñÅb ‚ñÅf ‚ñÅby,‚ñÅx x b os <unk> ‚ñÅl o ok s ‚ñÅvery ‚ñÅd if fer ent,‚ñÅx x b os <unk> ‚ñÅr ash mi ka ‚ñÅf ans <unk> ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (1343 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x b os ‚ñÅ‡≤Ö‡≤™‡≥ç‡≤™‡≤ü ‚ñÅ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚ñÅ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‚ñÅ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç,‚ñÅx x b os ‚ñÅ‡≤®‡≤®‡≤ó‡≥Ü ‚ñÅ‡≤Æ‡≤π‡≤æ‡≤≠‡≤æ‡≤∞‡≤§ ‚ñÅ‡≤Ö‡≤Ç‡≤¶‡≤∞‡≥Ü ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤®‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn ‡≤Æ‡≤π‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤¨‡≤∞‡≥Å‡≤µ ‚ñÅ‡≤™‡≤æ‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å,‚ñÅx x b os <unk> ‚ñÅt og ari ‚ñÅt ip pa ‚ñÅ ke li ‚ñÅt um ba ‚ñÅs ant os h ‚ñÅ ay it a ‚ñÅm att e ‚ñÅ old ‚ñÅis ‚ñÅg old ‚ñÅ ant ar all l ‚ñÅa du ‚ñÅ ni <unk> a ‚ñÅ ay it a,‚ñÅx x b os <unk> ‚ñÅw hy ‚ñÅonly ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤®‡≥ç‡≤® ‡≥ã ‚ñÅ‡≤§‡≥Å ‡≤ï‡≤æ ‡≤≤‡≤ø ‚ñÅ‡≤® ‚ñÅ‡≤ö‡≥à‡≤®‡≤æ ‚ñÅ‡≤ó‡≥Ü ‚ñÅ‡≤ï‡≤≥‡≤ø‡≤∏ ‡≤ø ‚ñÅ‡≤Ö ‡≤µ‡≥ç ‡≤≥‡≥Å ‚ñÅ‡≤ï‡≥Ç‡≤° ‚ñÅ‡≤ö‡≥à‡≤®‡≥Ä‡≤∏‡≥ç ‚ñÅ ‡≤¨‡≥ç‡≤∞‡≥Ä‡≤°‡≥ç ‚ñÅ‡≤á ‡≤∞‡≥ç ‡≤¨‡≥á‡≤ï‡≥Å,‚ñÅx x b os <unk> <unk> ‚ñÅmy ‚ñÅgo d ‚ñÅ su per o ‚ñÅ su per\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (777 items)\n",
              "x: LMTextList\n",
              "‚ñÅx x b os ‚ñÅ100 ‚ñÅ da ys ‚ñÅp ak ka,‚ñÅx x b os <unk> per ‚ñÅs ir,‚ñÅx x b os <unk> ‚ñÅh and s ‚ñÅup,‚ñÅx x b os <unk> ‚ñÅs ari ‚ñÅn iv u ‚ñÅv ide o ‚ñÅ na ‚ñÅ ro ast ‚ñÅma di ‚ñÅ ad re ‚ñÅm ad va ga ‚ñÅp ub g ‚ñÅat ava ‚ñÅf re e ‚ñÅf ire ‚ñÅg ame s ‚ñÅh ak ond o ‚ñÅm ad be di ‚ñÅa ‚ñÅg ame s ‚ñÅk ood a <unk>,‚ñÅx x b os <unk> ‚ñÅk r ish ana ‚ñÅsh apa ‚ñÅt att el ee be k u\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(25000, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1150, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1150, 1150, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1150, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2b32bca620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNYW97SkrxkL"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "J0TWrjRSrxkL",
        "outputId": "ab21d6f2-9631-40c0-94f8-00894b1f095b"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.503750</td>\n",
              "      <td>4.087892</td>\n",
              "      <td>0.272495</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDENO_NrxkM"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yBbnK2korxkM",
        "outputId": "3fbfcaa1-51da-4b46-8735-949d7c7042b9"
      },
      "source": [
        "learn.fit_one_cycle(5, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.971847</td>\n",
              "      <td>3.834475</td>\n",
              "      <td>0.305010</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.759426</td>\n",
              "      <td>3.588091</td>\n",
              "      <td>0.343130</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.559414</td>\n",
              "      <td>3.482368</td>\n",
              "      <td>0.360218</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.397767</td>\n",
              "      <td>3.445689</td>\n",
              "      <td>0.365055</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.290018</td>\n",
              "      <td>3.440943</td>\n",
              "      <td>0.366915</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5J5_pQSrxkM"
      },
      "source": [
        "learn.save_encoder('kn_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gT6VX5MorxkM",
        "outputId": "bd20841f-a0dc-428b-fa2f-a20a081cce71"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df(path='/content', train_df=X_train_df, valid_df=X_val_df, test_df=X_test_df, tokenizer=tokenizer, vocab=kannada_vocab,text_cols=['text'], label_cols=['label'], bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "-1ZxPs6VrxkM",
        "outputId": "5e5466f7-dd77-4c6e-9400-dc382b420275"
      },
      "source": [
        "data_clas.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x b os ‚ñÅs . g . ‚ñÅma th apa ti ‚ñÅt x ‚ñÅf d x ff x t &lt;unk&gt; x x x &lt;unk&gt; s r f ‚ñÅa ‚ñÅ su ‚ñÅ &lt;unk&gt; h ‚ñÅit ‚ñÅdo es n ' t &lt;unk&gt; ‚ñÅs g ‚ñÅit ‚ñÅt s c &lt;unk&gt; d c g c x x d f c ‚ñÅ ea ts ‚ñÅa ‚ñÅc &lt;unk&gt; &lt;unk&gt; ‚ñÅ su ite ‚ñÅd r ‚ñÅ</td>\n",
              "      <td>not-Kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x b os &lt;unk&gt; ‚ñÅd iv ‚ñÅm ov ie ‚ñÅno di ‚ñÅ thumb a ‚ñÅk us hi ‚ñÅa it hu ‚ñÅ y ak and re ‚ñÅhe n ‚ñÅma k lu ‚ñÅ &lt;unk&gt; e v ank e ‚ñÅat har ava da ‚ñÅm ov ie ‚ñÅ thumb a ‚ñÅ ad bu th ava g it hu ‚ñÅd ia ‚ñÅ ond ‚ñÅs ala ‚ñÅno di di ni ‚ñÅb t ‚ñÅn ang e</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x b os ‚ñÅ &lt;unk&gt; t &lt;unk&gt; ro l l &lt;unk&gt; ‚ñÅm o n &lt;unk&gt; st &lt;unk&gt; er &lt;unk&gt; k &lt;unk&gt; an &lt;unk&gt; na &lt;unk&gt; da ‚ñÅ &lt;unk&gt; v ish al ‚ñÅsh et ty ‚ñÅ &lt;unk&gt; v in od k al man i ‚ñÅ &lt;unk&gt; i ta ly &lt;unk&gt; ‚ñÅd a vi ‚ñÅ low d an &lt;unk&gt; ‚ñÅl o ve &lt;unk&gt; &lt;unk&gt; ‚ñÅc and y ‚ñÅ‡≤Ö‡≤Ç‡≤§ ‡≤æ ‚ñÅb l</td>\n",
              "      <td>Offensive_Targeted_Insult_Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x b os ‚ñÅ &lt;unk&gt; u n ity ‚ñÅof &lt;unk&gt; ‚ñÅn am ‚ñÅde sh ad alli ‚ñÅpo or ‚ñÅpeople ‚ñÅhe e c ch ide . . y ak and re ‚ñÅc ast e ‚ñÅsystem ‚ñÅ sa lu va g i ‚ñÅ av ar ‚ñÅh att ir ‚ñÅpro per ty ‚ñÅhe c ch ide ‚ñÅ kar an ‚ñÅ ava ru ‚ñÅh ind e ‚ñÅc ast e ‚ñÅsystem ‚ñÅme le ‚ñÅ</td>\n",
              "      <td>Offensive_Targeted_Insult_Individual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>‚ñÅx x b os ‚ñÅ‡≤®‡≤Æ‡≥ç‡≤Æ ‚ñÅ‡≤¶‡≥á‡≤∂‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤∏‡≥ç‡≤µ‡≤≤‡≥ç‡≤™ ‚ñÅ‡≤ú‡≤® ‚ñÅ‡≤¶‡≥á‡≤∂‡≤¶ ‚ñÅ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‚ñÅ‡≤Ø‡≥ã‡≤ö‡≤®‡≥Ü ‚ñÅ‡≤Æ‡≤æ‡≤° ‡≥ã ‡≤¶‡≥Å ‚ñÅ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‚ñÅ . ‚ñÅ‡≤¨‡≤ï‡≥Ü‡≤ü‡≥ç ‚ñÅ‡≤π‡≤ø‡≤°‡≤ø‡≤Ø ‡≥ã ‚ñÅ‡≤ï‡≥Ü‡≤≤‡≤∏ ‚ñÅ‡≤ö ‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø ‚ñÅ‡≤Æ‡≤æ‡≤° ‡≥ç ‡≤§‡≤æ‡≤∞‡≥Ü ‚ñÅ‡≤Ö‡≤£‡≥ç‡≤£‡≤æ ‚ñÅ‡≤Ö‡≤¶‡≤ï‡≥ç‡≤ï‡≥Ü ‚ñÅ‡≤π‡≥Ä‡≤ó‡≥Ü ‡≤≤‡≥ç‡≤≤ ‚ñÅ‡≤Æ‡≤æ‡≤° ‡≥ç ‡≤§‡≤æ‡≤∞‡≥Ü ‚ñÅ‡≤Ö‡≤µ‡≤∞‡≥Å ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn d esh ak k ag i ‚ñÅ &lt;unk&gt; ee va ‚ñÅk ot ta ‚ñÅa a ‚ñÅ y od har ig in ta ‚ñÅe ‚ñÅt al ent ‚ñÅ ank</td>\n",
              "      <td>Offensive_Untargetede</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuXeC7wqy_Yb"
      },
      "source": [
        "del awd_lstm_config['tie_weights']\n",
        "del awd_lstm_config['out_bias']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5_j_7qzrxkM"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5, config=awd_lstm_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qVgK8IdrxkN",
        "outputId": "6c8249bd-6878-4c13-9420-a0f8b2009c28"
      },
      "source": [
        "learn.load_encoder('kn_fine_tuned_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5371 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os <unk> <unk> l t im ate <unk> ru ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤µ‡≤∞ ‚ñÅ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‚ñÅ‡≤®‡≥á ‚ñÅ‡≤π‡≥á‡≤≥ ‡≥ç ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‡≥Ü,‚ñÅx x b os <unk> ‚ñÅb en ki ‚ñÅb ind ang ide ‚ñÅ ras mi k age,‚ñÅx x b os <unk> ‚ñÅk es ari ‚ñÅp ras ad <unk> <unk> o is ‚ñÅb ‚ñÅf ‚ñÅby,‚ñÅx x b os <unk> ‚ñÅl o ok s ‚ñÅvery ‚ñÅd if fer ent,‚ñÅx x b os <unk> ‚ñÅr ash mi ka ‚ñÅf ans <unk> ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a\n",
              "y: CategoryList\n",
              "Not_offensive,Offensive_Targeted_Insult_Individual,not-Kannada,not-Kannada,Offensive_Targeted_Insult_Group\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (1343 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ‡≤Ö‡≤™‡≥ç‡≤™‡≤ü ‚ñÅ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚ñÅ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‚ñÅ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç,‚ñÅx x b os ‚ñÅ‡≤®‡≤®‡≤ó‡≥Ü ‚ñÅ‡≤Æ‡≤π‡≤æ‡≤≠‡≤æ‡≤∞‡≤§ ‚ñÅ‡≤Ö‡≤Ç‡≤¶‡≤∞‡≥Ü ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤®‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn ‡≤Æ‡≤π‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤¨‡≤∞‡≥Å‡≤µ ‚ñÅ‡≤™‡≤æ‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å,‚ñÅx x b os <unk> ‚ñÅt og ari ‚ñÅt ip pa ‚ñÅ ke li ‚ñÅt um ba ‚ñÅs ant os h ‚ñÅ ay it a ‚ñÅm att e ‚ñÅ old ‚ñÅis ‚ñÅg old ‚ñÅ ant ar all l ‚ñÅa du ‚ñÅ ni <unk> a ‚ñÅ ay it a,‚ñÅx x b os <unk> ‚ñÅw hy ‚ñÅonly ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤®‡≥ç‡≤® ‡≥ã ‚ñÅ‡≤§‡≥Å ‡≤ï‡≤æ ‡≤≤‡≤ø ‚ñÅ‡≤® ‚ñÅ‡≤ö‡≥à‡≤®‡≤æ ‚ñÅ‡≤ó‡≥Ü ‚ñÅ‡≤ï‡≤≥‡≤ø‡≤∏ ‡≤ø ‚ñÅ‡≤Ö ‡≤µ‡≥ç ‡≤≥‡≥Å ‚ñÅ‡≤ï‡≥Ç‡≤° ‚ñÅ‡≤ö‡≥à‡≤®‡≥Ä‡≤∏‡≥ç ‚ñÅ ‡≤¨‡≥ç‡≤∞‡≥Ä‡≤°‡≥ç ‚ñÅ‡≤á ‡≤∞‡≥ç ‡≤¨‡≥á‡≤ï‡≥Å,‚ñÅx x b os <unk> <unk> ‚ñÅmy ‚ñÅgo d ‚ñÅ su per o ‚ñÅ su per\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,not-Kannada\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (777 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ100 ‚ñÅ da ys ‚ñÅp ak ka,‚ñÅx x b os <unk> per ‚ñÅs ir,‚ñÅx x b os <unk> ‚ñÅh and s ‚ñÅup,‚ñÅx x b os <unk> ‚ñÅs ari ‚ñÅn iv u ‚ñÅv ide o ‚ñÅ na ‚ñÅ ro ast ‚ñÅma di ‚ñÅ ad re ‚ñÅm ad va ga ‚ñÅp ub g ‚ñÅat ava ‚ñÅf re e ‚ñÅf ire ‚ñÅg ame s ‚ñÅh ak ond o ‚ñÅm ad be di ‚ñÅa ‚ñÅg ame s ‚ñÅk ood a <unk>,‚ñÅx x b os <unk> ‚ñÅk r ish ana ‚ñÅsh apa ‚ñÅt att el ee be k u\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1150, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1150, 1150, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1150, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2b32bca620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5371 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os <unk> <unk> l t im ate <unk> ru ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤µ‡≤∞ ‚ñÅ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‚ñÅ‡≤®‡≥á ‚ñÅ‡≤π‡≥á‡≤≥ ‡≥ç ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‡≥Ü,‚ñÅx x b os <unk> ‚ñÅb en ki ‚ñÅb ind ang ide ‚ñÅ ras mi k age,‚ñÅx x b os <unk> ‚ñÅk es ari ‚ñÅp ras ad <unk> <unk> o is ‚ñÅb ‚ñÅf ‚ñÅby,‚ñÅx x b os <unk> ‚ñÅl o ok s ‚ñÅvery ‚ñÅd if fer ent,‚ñÅx x b os <unk> ‚ñÅr ash mi ka ‚ñÅf ans <unk> ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a\n",
              "y: CategoryList\n",
              "Not_offensive,Offensive_Targeted_Insult_Individual,not-Kannada,not-Kannada,Offensive_Targeted_Insult_Group\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (1343 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ‡≤Ö‡≤™‡≥ç‡≤™‡≤ü ‚ñÅ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚ñÅ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‚ñÅ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç,‚ñÅx x b os ‚ñÅ‡≤®‡≤®‡≤ó‡≥Ü ‚ñÅ‡≤Æ‡≤π‡≤æ‡≤≠‡≤æ‡≤∞‡≤§ ‚ñÅ‡≤Ö‡≤Ç‡≤¶‡≤∞‡≥Ü ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤®‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn ‡≤Æ‡≤π‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤¨‡≤∞‡≥Å‡≤µ ‚ñÅ‡≤™‡≤æ‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å,‚ñÅx x b os <unk> ‚ñÅt og ari ‚ñÅt ip pa ‚ñÅ ke li ‚ñÅt um ba ‚ñÅs ant os h ‚ñÅ ay it a ‚ñÅm att e ‚ñÅ old ‚ñÅis ‚ñÅg old ‚ñÅ ant ar all l ‚ñÅa du ‚ñÅ ni <unk> a ‚ñÅ ay it a,‚ñÅx x b os <unk> ‚ñÅw hy ‚ñÅonly ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤®‡≥ç‡≤® ‡≥ã ‚ñÅ‡≤§‡≥Å ‡≤ï‡≤æ ‡≤≤‡≤ø ‚ñÅ‡≤® ‚ñÅ‡≤ö‡≥à‡≤®‡≤æ ‚ñÅ‡≤ó‡≥Ü ‚ñÅ‡≤ï‡≤≥‡≤ø‡≤∏ ‡≤ø ‚ñÅ‡≤Ö ‡≤µ‡≥ç ‡≤≥‡≥Å ‚ñÅ‡≤ï‡≥Ç‡≤° ‚ñÅ‡≤ö‡≥à‡≤®‡≥Ä‡≤∏‡≥ç ‚ñÅ ‡≤¨‡≥ç‡≤∞‡≥Ä‡≤°‡≥ç ‚ñÅ‡≤á ‡≤∞‡≥ç ‡≤¨‡≥á‡≤ï‡≥Å,‚ñÅx x b os <unk> <unk> ‚ñÅmy ‚ñÅgo d ‚ñÅ su per o ‚ñÅ su per\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,not-Kannada\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (777 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ100 ‚ñÅ da ys ‚ñÅp ak ka,‚ñÅx x b os <unk> per ‚ñÅs ir,‚ñÅx x b os <unk> ‚ñÅh and s ‚ñÅup,‚ñÅx x b os <unk> ‚ñÅs ari ‚ñÅn iv u ‚ñÅv ide o ‚ñÅ na ‚ñÅ ro ast ‚ñÅma di ‚ñÅ ad re ‚ñÅm ad va ga ‚ñÅp ub g ‚ñÅat ava ‚ñÅf re e ‚ñÅf ire ‚ñÅg ame s ‚ñÅh ak ond o ‚ñÅm ad be di ‚ñÅa ‚ñÅg ame s ‚ñÅk ood a <unk>,‚ñÅx x b os <unk> ‚ñÅk r ish ana ‚ñÅsh apa ‚ñÅt att el ee be k u\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1150, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1150, 1150, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1150, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2b32bca620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z8Yc11ErxkN"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uACcQR1CrxkN",
        "outputId": "25b31e11-7c8a-4d88-bfcf-9569f5471b25"
      },
      "source": [
        "learn.loss_func.func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhRzcJ4lrxkN"
      },
      "source": [
        "mcc = MatthewsCorreff()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J3RRsn7rxkN"
      },
      "source": [
        "learn.metrics = [mcc, accuracy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "Gnf7yzxQrxkN",
        "outputId": "f244e4f8-9457-4e1c-c07a-ddf678b4e281"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.014194</td>\n",
              "      <td>0.857088</td>\n",
              "      <td>0.413971</td>\n",
              "      <td>0.679821</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "bZDRiPM-rxkO",
        "outputId": "7be94492-844e-4f0d-b603-5809093b3d18"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.879197</td>\n",
              "      <td>0.827571</td>\n",
              "      <td>0.472780</td>\n",
              "      <td>0.701415</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqguzDgCrxkO"
      },
      "source": [
        "learn.save('kn_second-full')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "F55P9OkxrxkO",
        "outputId": "409af3c0-824c-41f3-f669-f17efcdfe7bc"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='kn_final')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>matthews_correff</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.787874</td>\n",
              "      <td>0.798698</td>\n",
              "      <td>0.510456</td>\n",
              "      <td>0.721519</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.823923</td>\n",
              "      <td>0.807420</td>\n",
              "      <td>0.498890</td>\n",
              "      <td>0.718541</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.698181</td>\n",
              "      <td>0.793908</td>\n",
              "      <td>0.529772</td>\n",
              "      <td>0.734177</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.552280</td>\n",
              "      <td>0.803737</td>\n",
              "      <td>0.533151</td>\n",
              "      <td>0.728965</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.425914</td>\n",
              "      <td>0.814373</td>\n",
              "      <td>0.535807</td>\n",
              "      <td>0.725987</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.7215189933776855.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with accuracy value: 0.7341772317886353.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HLBy6j3rxkO",
        "outputId": "70855929-40f2-4239-e32f-b1ed47e1e1d9"
      },
      "source": [
        "learn.load('kn_final')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5371 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os <unk> <unk> l t im ate <unk> ru ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤µ‡≤∞ ‚ñÅ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‚ñÅ‡≤®‡≥á ‚ñÅ‡≤π‡≥á‡≤≥ ‡≥ç ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‡≥Ü,‚ñÅx x b os <unk> ‚ñÅb en ki ‚ñÅb ind ang ide ‚ñÅ ras mi k age,‚ñÅx x b os <unk> ‚ñÅk es ari ‚ñÅp ras ad <unk> <unk> o is ‚ñÅb ‚ñÅf ‚ñÅby,‚ñÅx x b os <unk> ‚ñÅl o ok s ‚ñÅvery ‚ñÅd if fer ent,‚ñÅx x b os <unk> ‚ñÅr ash mi ka ‚ñÅf ans <unk> ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a\n",
              "y: CategoryList\n",
              "Not_offensive,Offensive_Targeted_Insult_Individual,not-Kannada,not-Kannada,Offensive_Targeted_Insult_Group\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (1343 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ‡≤Ö‡≤™‡≥ç‡≤™‡≤ü ‚ñÅ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚ñÅ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‚ñÅ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç,‚ñÅx x b os ‚ñÅ‡≤®‡≤®‡≤ó‡≥Ü ‚ñÅ‡≤Æ‡≤π‡≤æ‡≤≠‡≤æ‡≤∞‡≤§ ‚ñÅ‡≤Ö‡≤Ç‡≤¶‡≤∞‡≥Ü ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤®‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn ‡≤Æ‡≤π‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤¨‡≤∞‡≥Å‡≤µ ‚ñÅ‡≤™‡≤æ‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å,‚ñÅx x b os <unk> ‚ñÅt og ari ‚ñÅt ip pa ‚ñÅ ke li ‚ñÅt um ba ‚ñÅs ant os h ‚ñÅ ay it a ‚ñÅm att e ‚ñÅ old ‚ñÅis ‚ñÅg old ‚ñÅ ant ar all l ‚ñÅa du ‚ñÅ ni <unk> a ‚ñÅ ay it a,‚ñÅx x b os <unk> ‚ñÅw hy ‚ñÅonly ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤®‡≥ç‡≤® ‡≥ã ‚ñÅ‡≤§‡≥Å ‡≤ï‡≤æ ‡≤≤‡≤ø ‚ñÅ‡≤® ‚ñÅ‡≤ö‡≥à‡≤®‡≤æ ‚ñÅ‡≤ó‡≥Ü ‚ñÅ‡≤ï‡≤≥‡≤ø‡≤∏ ‡≤ø ‚ñÅ‡≤Ö ‡≤µ‡≥ç ‡≤≥‡≥Å ‚ñÅ‡≤ï‡≥Ç‡≤° ‚ñÅ‡≤ö‡≥à‡≤®‡≥Ä‡≤∏‡≥ç ‚ñÅ ‡≤¨‡≥ç‡≤∞‡≥Ä‡≤°‡≥ç ‚ñÅ‡≤á ‡≤∞‡≥ç ‡≤¨‡≥á‡≤ï‡≥Å,‚ñÅx x b os <unk> <unk> ‚ñÅmy ‚ñÅgo d ‚ñÅ su per o ‚ñÅ su per\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,not-Kannada\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (777 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ100 ‚ñÅ da ys ‚ñÅp ak ka,‚ñÅx x b os <unk> per ‚ñÅs ir,‚ñÅx x b os <unk> ‚ñÅh and s ‚ñÅup,‚ñÅx x b os <unk> ‚ñÅs ari ‚ñÅn iv u ‚ñÅv ide o ‚ñÅ na ‚ñÅ ro ast ‚ñÅma di ‚ñÅ ad re ‚ñÅm ad va ga ‚ñÅp ub g ‚ñÅat ava ‚ñÅf re e ‚ñÅf ire ‚ñÅg ame s ‚ñÅh ak ond o ‚ñÅm ad be di ‚ñÅa ‚ñÅg ame s ‚ñÅk ood a <unk>,‚ñÅx x b os <unk> ‚ñÅk r ish ana ‚ñÅsh apa ‚ñÅt att el ee be k u\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1150, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1150, 1150, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1150, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f2b32bca620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5371 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os <unk> <unk> l t im ate <unk> ru ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤µ‡≤∞ ‚ñÅ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø ‚ñÅ‡≤®‡≥á ‚ñÅ‡≤π‡≥á‡≤≥ ‡≥ç ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü ‡≥Ü,‚ñÅx x b os <unk> ‚ñÅb en ki ‚ñÅb ind ang ide ‚ñÅ ras mi k age,‚ñÅx x b os <unk> ‚ñÅk es ari ‚ñÅp ras ad <unk> <unk> o is ‚ñÅb ‚ñÅf ‚ñÅby,‚ñÅx x b os <unk> ‚ñÅl o ok s ‚ñÅvery ‚ñÅd if fer ent,‚ñÅx x b os <unk> ‚ñÅr ash mi ka ‚ñÅf ans <unk> ‚ñÅn d ‚ñÅde v ar k on da ‚ñÅf ans ‚ñÅ ur k ond ir ta re a\n",
              "y: CategoryList\n",
              "Not_offensive,Offensive_Targeted_Insult_Individual,not-Kannada,not-Kannada,Offensive_Targeted_Insult_Group\n",
              "Path: /content;\n",
              "\n",
              "Valid: LabelList (1343 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ‡≤Ö‡≤™‡≥ç‡≤™‡≤ü ‚ñÅ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚ñÅ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞ ‚ñÅ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç,‚ñÅx x b os ‚ñÅ‡≤®‡≤®‡≤ó‡≥Ü ‚ñÅ‡≤Æ‡≤π‡≤æ‡≤≠‡≤æ‡≤∞‡≤§ ‚ñÅ‡≤Ö‡≤Ç‡≤¶‡≤∞‡≥Ü ‚ñÅ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤®‡≥Ü ‚ñÅ‡≤á‡≤∑‡≥ç‡≤ü ‚ñÅx x re p ‚ñÅ4 ‚ñÅ . ‚ñÅn ‡≤Æ‡≤π‡≤æ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‚ñÅ‡≤¨‡≤∞‡≥Å‡≤µ ‚ñÅ‡≤™‡≤æ‡≤§‡≥ç‡≤∞‡≤ó‡≤≥‡≥Å,‚ñÅx x b os <unk> ‚ñÅt og ari ‚ñÅt ip pa ‚ñÅ ke li ‚ñÅt um ba ‚ñÅs ant os h ‚ñÅ ay it a ‚ñÅm att e ‚ñÅ old ‚ñÅis ‚ñÅg old ‚ñÅ ant ar all l ‚ñÅa du ‚ñÅ ni <unk> a ‚ñÅ ay it a,‚ñÅx x b os <unk> ‚ñÅw hy ‚ñÅonly ‚ñÅt ik ‚ñÅto k ‚ñÅ‡≤Ö‡≤®‡≥ç‡≤® ‡≥ã ‚ñÅ‡≤§‡≥Å ‡≤ï‡≤æ ‡≤≤‡≤ø ‚ñÅ‡≤® ‚ñÅ‡≤ö‡≥à‡≤®‡≤æ ‚ñÅ‡≤ó‡≥Ü ‚ñÅ‡≤ï‡≤≥‡≤ø‡≤∏ ‡≤ø ‚ñÅ‡≤Ö ‡≤µ‡≥ç ‡≤≥‡≥Å ‚ñÅ‡≤ï‡≥Ç‡≤° ‚ñÅ‡≤ö‡≥à‡≤®‡≥Ä‡≤∏‡≥ç ‚ñÅ ‡≤¨‡≥ç‡≤∞‡≥Ä‡≤°‡≥ç ‚ñÅ‡≤á ‡≤∞‡≥ç ‡≤¨‡≥á‡≤ï‡≥Å,‚ñÅx x b os <unk> <unk> ‚ñÅmy ‚ñÅgo d ‚ñÅ su per o ‚ñÅ su per\n",
              "y: CategoryList\n",
              "Not_offensive,Not_offensive,Not_offensive,Not_offensive,not-Kannada\n",
              "Path: /content;\n",
              "\n",
              "Test: LabelList (777 items)\n",
              "x: TextList\n",
              "‚ñÅx x b os ‚ñÅ100 ‚ñÅ da ys ‚ñÅp ak ka,‚ñÅx x b os <unk> per ‚ñÅs ir,‚ñÅx x b os <unk> ‚ñÅh and s ‚ñÅup,‚ñÅx x b os <unk> ‚ñÅs ari ‚ñÅn iv u ‚ñÅv ide o ‚ñÅ na ‚ñÅ ro ast ‚ñÅma di ‚ñÅ ad re ‚ñÅm ad va ga ‚ñÅp ub g ‚ñÅat ava ‚ñÅf re e ‚ñÅf ire ‚ñÅg ame s ‚ñÅh ak ond o ‚ñÅm ad be di ‚ñÅa ‚ñÅg ame s ‚ñÅk ood a <unk>,‚ñÅx x b os <unk> ‚ñÅk r ish ana ‚ñÅsh apa ‚ñÅt att el ee be k u\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: /content, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(25000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1150, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1150, 1150, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1150, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f2b32bca620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(25000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(25000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 1150, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.05, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "pfFhKp4hrxkO",
        "outputId": "37d5cbe2-3116-477f-a710-160d2989fea9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "df_dict = {'query': list(kannada_dev['data']), 'actual_label': list(kannada_dev['label']), 'predicted_label': ['']*kannada_dev.shape[0]}\n",
        "all_nodes = list(set(kannada_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*kannada_dev.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "    \n",
        "df_result = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>actual_label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>not-Kannada</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100 days pakka</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.852287</td>\n",
              "      <td>0.00753121</td>\n",
              "      <td>0.124471</td>\n",
              "      <td>0.00718047</td>\n",
              "      <td>0.00414496</td>\n",
              "      <td>0.00438587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Super sir</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>0.280574</td>\n",
              "      <td>0.00280587</td>\n",
              "      <td>0.711139</td>\n",
              "      <td>0.00289403</td>\n",
              "      <td>0.000856695</td>\n",
              "      <td>0.00173078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hands up</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>0.184626</td>\n",
              "      <td>0.00318407</td>\n",
              "      <td>0.79233</td>\n",
              "      <td>0.0155709</td>\n",
              "      <td>0.00133632</td>\n",
              "      <td>0.00295273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sari nivu video na roast madi adre madvaga pub...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.695987</td>\n",
              "      <td>0.131891</td>\n",
              "      <td>0.00300003</td>\n",
              "      <td>0.0516119</td>\n",
              "      <td>0.0787795</td>\n",
              "      <td>0.0387309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Krishana  shapa tatteleebeku</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.832997</td>\n",
              "      <td>0.0378039</td>\n",
              "      <td>0.0180197</td>\n",
              "      <td>0.0777569</td>\n",
              "      <td>0.00757892</td>\n",
              "      <td>0.0258441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... Offensive_Targeted_Insult_Other\n",
              "0                                     100 days pakka  ...                      0.00438587\n",
              "1                                          Super sir  ...                      0.00173078\n",
              "2                                           Hands up  ...                      0.00295273\n",
              "3  Sari nivu video na roast madi adre madvaga pub...  ...                       0.0387309\n",
              "4                       Krishana  shapa tatteleebeku  ...                       0.0258441\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "qT2JEUz5WnNm",
        "outputId": "674d44a5-2f91-4e96-c52f-18e5a80b177b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "\n",
        "data_lm_2 = TextClasDataBunch.from_df(path='/content',train_df=X_train_df, valid_df=X_val_df,  test_df=kannada_test, tokenizer=tokenizer, vocab=kannada_vocab,text_cols='text',label_cols=['label'])\n",
        "learn = text_classifier_learner(data_lm_2, arch=AWD_LSTM, drop_mult=0.5, config=awd_lstm_config)\n",
        "learn.load_encoder('kn_fine_tuned_enc')\n",
        "learn.load('/content/models/kn_final')\n",
        "\n",
        "df_dict = {'query': list(kannada_test['text']), 'predicted_label': ['']*kannada_test.shape[0]}\n",
        "all_nodes = list(set(kannada_train['label']))\n",
        "for node in all_nodes:\n",
        "    df_dict[node] = ['']*kannada_test.shape[0]\n",
        "    \n",
        "i2c = {}\n",
        "for key, value in learn.data.c2i.items():\n",
        "    i2c[value] = key\n",
        "\n",
        "\n",
        "df_result_2 = pd.DataFrame(df_dict)\n",
        "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
        "for index, row in df_result_2.iterrows():\n",
        "    for node in all_nodes:\n",
        "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
        "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
        "df_result_2.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>Not_offensive</th>\n",
              "      <th>Offensive_Targeted_Insult_Group</th>\n",
              "      <th>not-Kannada</th>\n",
              "      <th>Offensive_Untargetede</th>\n",
              "      <th>Offensive_Targeted_Insult_Individual</th>\n",
              "      <th>Offensive_Targeted_Insult_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡≤ú‡≥à ‡≤Æ‡≥ã‡≤∞‡≤ø ‡≤ú‡≥à ‡≤∞‡≥ã‡≤ó‡≤ø ‡≤á‡≤∏‡≥ç‡≤≤‡≤æ‡≤Ç ‡≤∏‡≤æ‡≤Ø‡≤ø‡≤∏‡≤ø ‡≤á‡≤¶‡≥Ü ‡≤á‡≤µ‡≤∞ ‡≤ó‡≥Å‡≤∞‡≤ø</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.996637</td>\n",
              "      <td>0.00120533</td>\n",
              "      <td>8.02004e-05</td>\n",
              "      <td>0.000545592</td>\n",
              "      <td>0.00133549</td>\n",
              "      <td>0.00019684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anna nim e vedio nodinu mathe chaina apps use ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.764424</td>\n",
              "      <td>0.0825607</td>\n",
              "      <td>0.00363173</td>\n",
              "      <td>0.05075</td>\n",
              "      <td>0.0744912</td>\n",
              "      <td>0.0241424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Super anna yenu thappila yela sari agi hellidi...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0.950983</td>\n",
              "      <td>0.0154205</td>\n",
              "      <td>0.00290209</td>\n",
              "      <td>0.0128787</td>\n",
              "      <td>0.0130254</td>\n",
              "      <td>0.00478979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super sir super super super super</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>0.445994</td>\n",
              "      <td>0.00323717</td>\n",
              "      <td>0.548967</td>\n",
              "      <td>0.000799711</td>\n",
              "      <td>0.000251789</td>\n",
              "      <td>0.000749716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AGT-KELU (KANNADA RAP 2019)</td>\n",
              "      <td>not-Kannada</td>\n",
              "      <td>0.110652</td>\n",
              "      <td>0.0046298</td>\n",
              "      <td>0.870419</td>\n",
              "      <td>0.00735278</td>\n",
              "      <td>0.00489435</td>\n",
              "      <td>0.0020528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               query  ... Offensive_Targeted_Insult_Other\n",
              "0         ‡≤ú‡≥à ‡≤Æ‡≥ã‡≤∞‡≤ø ‡≤ú‡≥à ‡≤∞‡≥ã‡≤ó‡≤ø ‡≤á‡≤∏‡≥ç‡≤≤‡≤æ‡≤Ç ‡≤∏‡≤æ‡≤Ø‡≤ø‡≤∏‡≤ø ‡≤á‡≤¶‡≥Ü ‡≤á‡≤µ‡≤∞ ‡≤ó‡≥Å‡≤∞‡≤ø  ...                      0.00019684\n",
              "1  Anna nim e vedio nodinu mathe chaina apps use ...  ...                       0.0241424\n",
              "2  Super anna yenu thappila yela sari agi hellidi...  ...                      0.00478979\n",
              "3                  Super sir super super super super  ...                     0.000749716\n",
              "4                        AGT-KELU (KANNADA RAP 2019)  ...                       0.0020528\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYTX01UJrxkP",
        "outputId": "62f34880-7591-44bf-f6e7-94c27fe1a199"
      },
      "source": [
        "accuracy_score(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6988416988416989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8adLQ47qrxkP",
        "outputId": "9e4fbae6-8a7f-4189-ccb2-feb7e508657a"
      },
      "source": [
        "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4853800728585681"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEn0Vt5DrxkP",
        "outputId": "5374476a-1686-41ae-d7d0-5d9bc12c7870"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(df_result['actual_label'], df_result['predicted_label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                      precision    recall  f1-score   support\n",
            "\n",
            "                       Not_offensive       0.71      0.84      0.77       426\n",
            "     Offensive_Targeted_Insult_Group       0.52      0.24      0.33        45\n",
            "Offensive_Targeted_Insult_Individual       0.75      0.45      0.57        66\n",
            "     Offensive_Targeted_Insult_Other       0.15      0.12      0.14        16\n",
            "               Offensive_Untargetede       0.00      0.00      0.00        33\n",
            "                         not-Kannada       0.72      0.75      0.74       191\n",
            "\n",
            "                            accuracy                           0.70       777\n",
            "                           macro avg       0.48      0.40      0.42       777\n",
            "                        weighted avg       0.66      0.70      0.67       777\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6_d_3Z5Zyu_"
      },
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "                       Not_offensive       0.71      0.84      0.77       426\n",
        "     Offensive_Targeted_Insult_Group       0.52      0.24      0.33        45\n",
        "Offensive_Targeted_Insult_Individual       0.75      0.45      0.57        66\n",
        "     Offensive_Targeted_Insult_Other       0.15      0.12      0.14        16\n",
        "               Offensive_Untargetede       0.00      0.00      0.00        33\n",
        "                         not-Kannada       0.72      0.75      0.74       191\n",
        "\n",
        "                            accuracy                           0.70       777\n",
        "                           macro avg       0.48      0.40      0.42       777\n",
        "                        weighted avg       0.66      0.70      0.67       777"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRSAuDyFrxkP"
      },
      "source": [
        "df_result.to_excel('kan_ml.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i19SJOYrxkP"
      },
      "source": [
        "df_result_2.to_excel('kan_ml_test_preds.xlsx', index=False,encoding='utf-16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2mA_uHQYnwS"
      },
      "source": [
        "!mv '/content/models' '/content/drive/MyDrive/AggressionNLP/Kannada Results'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng1dZsOQaah1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}